{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"./Data/rate_train.csv\", low_memory=False)\n",
    "ratings_test = pd.read_csv(\"./Data/Ground_truth/groundtruth_0.3.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.Node_Id.unique()\n",
    "model_train = ratings_train.Model_Id.unique()\n",
    "datasets_test = ratings_test.dataset.unique()\n",
    "model_test = ratings_test.model.unique()\n",
    "meta_models = pd.read_csv(\"./Data/model_v.csv\",low_memory=False)\n",
    "models = meta_models.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=models)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]\n",
    "data_model_test_matrix = data_model_test_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"./Data/dataset_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.dataset_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,(\"v1\",\"v2\",\"v3\",\"v4\",\"v5\")]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对dataframe的数据进行标准化\n",
    "scaled_data = scaler.fit_transform(meta_datasets)\n",
    "# 将标准化后的数据转换为dataframe，并保留原始索引\n",
    "scaled_df = pd.DataFrame(scaled_data, index=meta_datasets.index, columns=meta_datasets.columns)\n",
    "meta_dataset_similarity = cosine_similarity(scaled_df.values.tolist())\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity,index=datasets,columns=datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "KNN sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           v1        v2        v3        v4        v5\n0    0.008156  0.001922  0.059339  0.002252 -0.019061\n1   -0.071854  0.041016  0.135472 -0.024235 -0.111402\n2   -0.071854  0.041016  0.135472 -0.024235 -0.111402\n3   -0.071854  0.041016  0.135472 -0.024235 -0.111402\n4   -0.071854  0.041016  0.135472 -0.024235 -0.111402\n..        ...       ...       ...       ...       ...\n284  0.040722  0.087765  0.104818 -0.007502 -0.050698\n285  0.045504  0.019537  0.134035 -0.021794  0.050458\n286  0.045504  0.019537  0.134035 -0.021794  0.050458\n287  0.045504  0.019537  0.134035 -0.021794  0.050458\n288  0.045504  0.019537  0.134035 -0.021794  0.050458\n\n[289 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>v3</th>\n      <th>v4</th>\n      <th>v5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.008156</td>\n      <td>0.001922</td>\n      <td>0.059339</td>\n      <td>0.002252</td>\n      <td>-0.019061</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.071854</td>\n      <td>0.041016</td>\n      <td>0.135472</td>\n      <td>-0.024235</td>\n      <td>-0.111402</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.071854</td>\n      <td>0.041016</td>\n      <td>0.135472</td>\n      <td>-0.024235</td>\n      <td>-0.111402</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.071854</td>\n      <td>0.041016</td>\n      <td>0.135472</td>\n      <td>-0.024235</td>\n      <td>-0.111402</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.071854</td>\n      <td>0.041016</td>\n      <td>0.135472</td>\n      <td>-0.024235</td>\n      <td>-0.111402</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>0.040722</td>\n      <td>0.087765</td>\n      <td>0.104818</td>\n      <td>-0.007502</td>\n      <td>-0.050698</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>0.045504</td>\n      <td>0.019537</td>\n      <td>0.134035</td>\n      <td>-0.021794</td>\n      <td>0.050458</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>0.045504</td>\n      <td>0.019537</td>\n      <td>0.134035</td>\n      <td>-0.021794</td>\n      <td>0.050458</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>0.045504</td>\n      <td>0.019537</td>\n      <td>0.134035</td>\n      <td>-0.021794</td>\n      <td>0.050458</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>0.045504</td>\n      <td>0.019537</td>\n      <td>0.134035</td>\n      <td>-0.021794</td>\n      <td>0.050458</td>\n    </tr>\n  </tbody>\n</table>\n<p>289 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_func(ratings, user1, user2):\n",
    "    # 找到两个用户共同评分的物品，并将这些评分放入一个向量中\n",
    "    u1_ratings = ratings.loc[user1].dropna()\n",
    "    u2_ratings = ratings.loc[user2].dropna()\n",
    "\n",
    "    common_items = np.intersect1d(u1_ratings.index, u2_ratings.index).tolist()\n",
    "    u1_common_ratings = u1_ratings.loc[common_items]\n",
    "    u2_common_ratings = u2_ratings.loc[common_items]\n",
    "\n",
    "    # 计算两个向量之间的余弦相似度\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cos_sim = np.dot(u1_common_ratings, u2_common_ratings) / (np.linalg.norm(u1_common_ratings) * np.linalg.norm(u2_common_ratings))\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_bipartite_adjacency_matrix(rating_matrix):\n",
    "    n_users, n_items = rating_matrix.shape\n",
    "    adjacency_matrix = np.zeros((n_users + n_items, n_users + n_items))\n",
    "    adjacency_matrix[:n_users, n_users:] = rating_matrix\n",
    "    adjacency_matrix[n_users:, :n_users] = rating_matrix.T\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix(adjacency, lambda_):\n",
    "    n = adjacency.shape[0]\n",
    "    I = np.eye(n)\n",
    "    # 将 NaN 视为 0\n",
    "    adjacency = np.nan_to_num(adjacency)\n",
    "    try:\n",
    "        P = np.linalg.inv(I - lambda_ * adjacency)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"矩阵不可逆，无法计算传播矩阵\")\n",
    "        return None\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix_withWalkLength(adjacency_matrix, max_walk_length):\n",
    "    adjacency_matrix = np.nan_to_num(adjacency_matrix)\n",
    "    propagation_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "    sum_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "\n",
    "    for _ in range(max_walk_length):\n",
    "        propagation_matrix = propagation_matrix @ adjacency_matrix\n",
    "        sum_matrix += propagation_matrix\n",
    "\n",
    "    return sum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算二分图邻接矩阵\n",
    "bipartite_adjacency_matrix = create_bipartite_adjacency_matrix(data_model_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "propagation_maxLength = propagation_matrix_withWalkLength(bipartite_adjacency_matrix, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取用户-商品传播矩阵和商品-用户传播矩阵\n",
    "n_users = data_model_train_matrix.shape[0]\n",
    "user_item_propagation = propagation_maxLength[:n_users, n_users:]\n",
    "item_user_propagation = propagation_maxLength[n_users:, :n_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算 Random Walk Kernel\n",
    "random_walk_kernel = np.dot(user_item_propagation, item_user_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel_matrix):\n",
    "    diagonal_elements = np.diag(kernel_matrix)\n",
    "    normalized_kernel_matrix = np.divide(kernel_matrix, np.sqrt(np.outer(diagonal_elements, diagonal_elements)))\n",
    "    return normalized_kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = normalize_kernel(random_walk_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = pd.DataFrame(normalized_kernel,index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.5\n",
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        # rating_based_sim = cosine_similarity_func(data_model_train_matrix,i,j)\n",
    "        if normalized_kernel.loc[i][j] != 0 and meta_dataset_similarity.loc[i][j] != 0:\n",
    "            dataset_similarity.loc[i][j] = lambda_ * normalized_kernel.loc[i][j] + (1-lambda_) * meta_dataset_similarity.loc[i][j]\n",
    "        else:\n",
    "            dataset_similarity.loc[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         29        14        28        16        17        13   \\\n0         1.0  0.407055  0.407038  0.407037  0.407037  0.407053  0.407054   \n29   0.407055       1.0  0.999994  0.999993  0.999993       1.0       1.0   \n14   0.407038  0.999994       1.0       1.0       1.0  0.999996  0.999995   \n28   0.407037  0.999993       1.0       1.0       1.0  0.999995  0.999994   \n16   0.407037  0.999993       1.0       1.0       1.0  0.999995  0.999994   \n..        ...       ...       ...       ...       ...       ...       ...   \n281  0.328948    0.3485  0.348465  0.348462  0.348462  0.348495  0.348498   \n288  0.816564  0.522713  0.522696  0.522694  0.522695  0.522711  0.522712   \n286  0.816564  0.522714  0.522698  0.522696  0.522696  0.522712  0.522713   \n287  0.816564  0.522713  0.522696  0.522694  0.522694  0.522711  0.522712   \n285  0.816564  0.522713  0.522696  0.522694  0.522695  0.522711  0.522712   \n\n          12        10        38   ...       275       274       279  \\\n0    0.407054  0.407055  0.407054  ...  0.375823  0.375834   0.37583   \n29        1.0       1.0       1.0  ...  0.293156  0.293173  0.293166   \n14   0.999995  0.999994  0.999995  ...  0.293115  0.293138  0.293128   \n28   0.999994  0.999993  0.999994  ...  0.293111  0.293135  0.293125   \n16   0.999994  0.999994  0.999994  ...  0.293112  0.293135  0.293126   \n..        ...       ...       ...  ...       ...       ...       ...   \n281  0.348498  0.348499  0.348498  ...  0.971586  0.971588  0.971588   \n288  0.522712  0.522713  0.522712  ...   0.48045  0.480461  0.480457   \n286  0.522713  0.522713  0.522713  ...  0.480448   0.48046  0.480455   \n287  0.522712  0.522712  0.522712  ...  0.480451  0.480461  0.480457   \n285  0.522712  0.522713  0.522712  ...   0.48045  0.480461  0.480457   \n\n          278       280       281       288       286       287       285  \n0    0.375839  0.328952  0.328948  0.816564  0.816564  0.816564  0.816564  \n29    0.29318  0.348507    0.3485  0.522713  0.522714  0.522713  0.522713  \n14   0.293149  0.348476  0.348465  0.522696  0.522698  0.522696  0.522696  \n28   0.293146  0.348473  0.348462  0.522694  0.522696  0.522694  0.522694  \n16   0.293146  0.348473  0.348462  0.522695  0.522696  0.522694  0.522695  \n..        ...       ...       ...       ...       ...       ...       ...  \n281  0.971587       1.0       1.0  0.533015  0.533014  0.533015  0.533015  \n288  0.480465  0.533019  0.533015       1.0       1.0       1.0       1.0  \n286  0.480464  0.533018  0.533014       1.0       1.0       1.0       1.0  \n287  0.480466   0.53302  0.533015       1.0       1.0       1.0       1.0  \n285  0.480465  0.533019  0.533015       1.0       1.0       1.0       1.0  \n\n[249 rows x 249 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>29</th>\n      <th>14</th>\n      <th>28</th>\n      <th>16</th>\n      <th>17</th>\n      <th>13</th>\n      <th>12</th>\n      <th>10</th>\n      <th>38</th>\n      <th>...</th>\n      <th>275</th>\n      <th>274</th>\n      <th>279</th>\n      <th>278</th>\n      <th>280</th>\n      <th>281</th>\n      <th>288</th>\n      <th>286</th>\n      <th>287</th>\n      <th>285</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.407055</td>\n      <td>0.407038</td>\n      <td>0.407037</td>\n      <td>0.407037</td>\n      <td>0.407053</td>\n      <td>0.407054</td>\n      <td>0.407054</td>\n      <td>0.407055</td>\n      <td>0.407054</td>\n      <td>...</td>\n      <td>0.375823</td>\n      <td>0.375834</td>\n      <td>0.37583</td>\n      <td>0.375839</td>\n      <td>0.328952</td>\n      <td>0.328948</td>\n      <td>0.816564</td>\n      <td>0.816564</td>\n      <td>0.816564</td>\n      <td>0.816564</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.407055</td>\n      <td>1.0</td>\n      <td>0.999994</td>\n      <td>0.999993</td>\n      <td>0.999993</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.293156</td>\n      <td>0.293173</td>\n      <td>0.293166</td>\n      <td>0.29318</td>\n      <td>0.348507</td>\n      <td>0.3485</td>\n      <td>0.522713</td>\n      <td>0.522714</td>\n      <td>0.522713</td>\n      <td>0.522713</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.407038</td>\n      <td>0.999994</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999996</td>\n      <td>0.999995</td>\n      <td>0.999995</td>\n      <td>0.999994</td>\n      <td>0.999995</td>\n      <td>...</td>\n      <td>0.293115</td>\n      <td>0.293138</td>\n      <td>0.293128</td>\n      <td>0.293149</td>\n      <td>0.348476</td>\n      <td>0.348465</td>\n      <td>0.522696</td>\n      <td>0.522698</td>\n      <td>0.522696</td>\n      <td>0.522696</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.407037</td>\n      <td>0.999993</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999995</td>\n      <td>0.999994</td>\n      <td>0.999994</td>\n      <td>0.999993</td>\n      <td>0.999994</td>\n      <td>...</td>\n      <td>0.293111</td>\n      <td>0.293135</td>\n      <td>0.293125</td>\n      <td>0.293146</td>\n      <td>0.348473</td>\n      <td>0.348462</td>\n      <td>0.522694</td>\n      <td>0.522696</td>\n      <td>0.522694</td>\n      <td>0.522694</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.407037</td>\n      <td>0.999993</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999995</td>\n      <td>0.999994</td>\n      <td>0.999994</td>\n      <td>0.999994</td>\n      <td>0.999994</td>\n      <td>...</td>\n      <td>0.293112</td>\n      <td>0.293135</td>\n      <td>0.293126</td>\n      <td>0.293146</td>\n      <td>0.348473</td>\n      <td>0.348462</td>\n      <td>0.522695</td>\n      <td>0.522696</td>\n      <td>0.522694</td>\n      <td>0.522695</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>0.328948</td>\n      <td>0.3485</td>\n      <td>0.348465</td>\n      <td>0.348462</td>\n      <td>0.348462</td>\n      <td>0.348495</td>\n      <td>0.348498</td>\n      <td>0.348498</td>\n      <td>0.348499</td>\n      <td>0.348498</td>\n      <td>...</td>\n      <td>0.971586</td>\n      <td>0.971588</td>\n      <td>0.971588</td>\n      <td>0.971587</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.533015</td>\n      <td>0.533014</td>\n      <td>0.533015</td>\n      <td>0.533015</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>0.816564</td>\n      <td>0.522713</td>\n      <td>0.522696</td>\n      <td>0.522694</td>\n      <td>0.522695</td>\n      <td>0.522711</td>\n      <td>0.522712</td>\n      <td>0.522712</td>\n      <td>0.522713</td>\n      <td>0.522712</td>\n      <td>...</td>\n      <td>0.48045</td>\n      <td>0.480461</td>\n      <td>0.480457</td>\n      <td>0.480465</td>\n      <td>0.533019</td>\n      <td>0.533015</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>0.816564</td>\n      <td>0.522714</td>\n      <td>0.522698</td>\n      <td>0.522696</td>\n      <td>0.522696</td>\n      <td>0.522712</td>\n      <td>0.522713</td>\n      <td>0.522713</td>\n      <td>0.522713</td>\n      <td>0.522713</td>\n      <td>...</td>\n      <td>0.480448</td>\n      <td>0.48046</td>\n      <td>0.480455</td>\n      <td>0.480464</td>\n      <td>0.533018</td>\n      <td>0.533014</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>0.816564</td>\n      <td>0.522713</td>\n      <td>0.522696</td>\n      <td>0.522694</td>\n      <td>0.522694</td>\n      <td>0.522711</td>\n      <td>0.522712</td>\n      <td>0.522712</td>\n      <td>0.522712</td>\n      <td>0.522712</td>\n      <td>...</td>\n      <td>0.480451</td>\n      <td>0.480461</td>\n      <td>0.480457</td>\n      <td>0.480466</td>\n      <td>0.53302</td>\n      <td>0.533015</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>0.816564</td>\n      <td>0.522713</td>\n      <td>0.522696</td>\n      <td>0.522694</td>\n      <td>0.522695</td>\n      <td>0.522711</td>\n      <td>0.522712</td>\n      <td>0.522712</td>\n      <td>0.522713</td>\n      <td>0.522712</td>\n      <td>...</td>\n      <td>0.48045</td>\n      <td>0.480461</td>\n      <td>0.480457</td>\n      <td>0.480465</td>\n      <td>0.533019</td>\n      <td>0.533015</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>249 rows × 249 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ratings(rating_matrix, user_similarity_matrix, k=5):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "    rating_matrix - 评分矩阵，DataFrame格式，其中NaN表示未评分\n",
    "    user_similarity_matrix - 用户相似度矩阵，DataFrame格式\n",
    "    k - 最近邻的数量，默认为5\n",
    "\n",
    "    输出：\n",
    "    prediction_matrix - 预测矩阵，DataFrame格式\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化预测矩阵\n",
    "    prediction_matrix = rating_matrix.copy()\n",
    "\n",
    "    # 对于评分矩阵中的每个NaN值，使用K最近邻的方法预测评分\n",
    "    for i in rating_matrix.index:\n",
    "        for j in rating_matrix.columns:\n",
    "            if np.isnan(rating_matrix.loc[i][j]):\n",
    "                # 获取第i个用户的相似度值，并在相似度矩阵中找到K个最相似的用户\n",
    "                similarity_values = user_similarity_matrix.loc[i].sort_values(ascending=False)[1:k+1]\n",
    "\n",
    "                # 计算加权平均评分\n",
    "                weighted_sum = 0\n",
    "                similarity_sum = 0\n",
    "                for index, value in similarity_values.items():\n",
    "                    user_rating = rating_matrix.loc[index][j]\n",
    "                    if not np.isnan(user_rating):\n",
    "                        weighted_sum += value * user_rating\n",
    "                        similarity_sum += value\n",
    "\n",
    "                # 如果存在至少一个相似用户对该物品进行了评分，则计算预测评分\n",
    "                if similarity_sum != 0:\n",
    "                    prediction_matrix.loc[i][j] = weighted_sum / similarity_sum\n",
    "                else:\n",
    "                    # 如果没有相似用户评分，则使用当前用户的平均评分作为预测值\n",
    "                    prediction_matrix.loc[i][j] = rating_matrix.loc[i].mean()\n",
    "\n",
    "    return prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def predict(rating_matrix, similarity_matrix):\n",
    "    \"\"\"\n",
    "    根据评分矩阵和相似度矩阵预测评分。\n",
    "\n",
    "    参数：\n",
    "    rating_matrix (pd.DataFrame)：评分矩阵，包含NaN值\n",
    "    similarity_matrix (numpy.array)：相似度矩阵\n",
    "\n",
    "    返回：\n",
    "    pd.DataFrame：预测评分矩阵\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取评分矩阵的均值（忽略NaN值）\n",
    "    mean_rating = rating_matrix.mean(axis=1).values\n",
    "\n",
    "    # 将评分矩阵中的NaN值替换为0\n",
    "    rating_matrix_nan_to_zero = rating_matrix.fillna(0).values\n",
    "\n",
    "    # 减去均值，得到归一化的评分矩阵\n",
    "    normalized_rating_matrix = rating_matrix_nan_to_zero - mean_rating[:, np.newaxis]\n",
    "\n",
    "    # 计算预测评分\n",
    "    predicted_ratings = mean_rating[:, np.newaxis] + np.dot(similarity_matrix, normalized_rating_matrix) / np.abs(similarity_matrix).sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 将预测评分数组转换为DataFrame\n",
    "    predicted_ratings_df = pd.DataFrame(predicted_ratings, index=rating_matrix.index, columns=rating_matrix.columns)\n",
    "\n",
    "    return predicted_ratings_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\byy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "model_prediction_train = predict(data_model_train_matrix,dataset_similarity)\n",
    "model_prediction_train = pd.DataFrame(model_prediction_train,index=datasets_train,columns=models).sort_index().sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          289       290       291       292       293       294       295  \\\n0   -0.082269 -0.184046 -0.030986 -0.175057 -0.037754  -0.17521 -0.039279   \n1    0.305123  0.201733  0.376778  0.212056  0.371962  0.211863  0.370885   \n2     0.51611  0.412714  0.587769  0.423037  0.582952  0.422844  0.581875   \n3    0.521253  0.417857  0.592912   0.42818  0.588095  0.427988  0.587018   \n4    0.595254  0.491858  0.666913  0.502181  0.662096  0.501988  0.661019   \n..        ...       ...       ...       ...       ...       ...       ...   \n281  0.056794 -0.034994  0.086712 -0.028549  0.081906 -0.029207  0.080947   \n285 -0.058225 -0.155677 -0.016742 -0.147935 -0.021772 -0.148252 -0.022854   \n286 -0.057151 -0.154603 -0.015668 -0.146861 -0.020697 -0.147179  -0.02178   \n287 -0.057359 -0.154811 -0.015876 -0.147069 -0.020906 -0.147386 -0.021988   \n288 -0.057936 -0.155388 -0.016453 -0.147646 -0.021483 -0.147964 -0.022565   \n\n          296       297       298  ...       741       742       743  \\\n0   -0.175727 -0.039234 -0.175727  ...  -0.41069 -0.410893 -0.410769   \n1    0.211384  0.370871  0.211384  ... -0.026367 -0.026512 -0.026417   \n2    0.422365  0.581861  0.422366  ...  0.184613  0.184468  0.184563   \n3    0.427509  0.587004  0.427509  ...  0.189757  0.189611  0.189707   \n4    0.501509  0.661005  0.501509  ...  0.263757  0.263612  0.263707   \n..        ...       ...       ...  ...       ...       ...       ...   \n281 -0.031096  0.080312 -0.031096  ... -0.183321 -0.183529 -0.183399   \n285 -0.149097 -0.023093 -0.149097  ... -0.337706 -0.337974 -0.337814   \n286 -0.148023 -0.022019 -0.148023  ... -0.336632   -0.3369  -0.33674   \n287 -0.148231 -0.022227 -0.148231  ...  -0.33684 -0.337108 -0.336948   \n288 -0.148808 -0.022804 -0.148808  ... -0.337417 -0.337685 -0.337525   \n\n          744       745       746       747       748       749       750  \n0   -0.411444 -0.411241 -0.411444 -0.411647 -0.411798 -0.411647 -0.411798  \n1   -0.026999 -0.026854 -0.026999 -0.027308 -0.027412 -0.027308 -0.027412  \n2    0.183981  0.184126  0.183981  0.183672  0.183568  0.183672  0.183568  \n3    0.189124   0.18927  0.189124  0.188816  0.188712  0.188816  0.188712  \n4    0.263125   0.26327  0.263125  0.262816  0.262712  0.262816  0.262712  \n..        ...       ...       ...       ...       ...       ...       ...  \n281 -0.185332 -0.185124 -0.185332 -0.185858 -0.185966 -0.185858 -0.185966  \n285 -0.338853 -0.338585 -0.338853 -0.339283 -0.339464 -0.339283 -0.339464  \n286 -0.337779 -0.337511 -0.337779 -0.338209 -0.338391 -0.338209 -0.338391  \n287 -0.337987 -0.337719 -0.337987 -0.338417 -0.338598 -0.338417 -0.338598  \n288 -0.338564 -0.338296 -0.338564 -0.338994 -0.339175 -0.338994 -0.339175  \n\n[249 rows x 462 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>...</th>\n      <th>741</th>\n      <th>742</th>\n      <th>743</th>\n      <th>744</th>\n      <th>745</th>\n      <th>746</th>\n      <th>747</th>\n      <th>748</th>\n      <th>749</th>\n      <th>750</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.082269</td>\n      <td>-0.184046</td>\n      <td>-0.030986</td>\n      <td>-0.175057</td>\n      <td>-0.037754</td>\n      <td>-0.17521</td>\n      <td>-0.039279</td>\n      <td>-0.175727</td>\n      <td>-0.039234</td>\n      <td>-0.175727</td>\n      <td>...</td>\n      <td>-0.41069</td>\n      <td>-0.410893</td>\n      <td>-0.410769</td>\n      <td>-0.411444</td>\n      <td>-0.411241</td>\n      <td>-0.411444</td>\n      <td>-0.411647</td>\n      <td>-0.411798</td>\n      <td>-0.411647</td>\n      <td>-0.411798</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.305123</td>\n      <td>0.201733</td>\n      <td>0.376778</td>\n      <td>0.212056</td>\n      <td>0.371962</td>\n      <td>0.211863</td>\n      <td>0.370885</td>\n      <td>0.211384</td>\n      <td>0.370871</td>\n      <td>0.211384</td>\n      <td>...</td>\n      <td>-0.026367</td>\n      <td>-0.026512</td>\n      <td>-0.026417</td>\n      <td>-0.026999</td>\n      <td>-0.026854</td>\n      <td>-0.026999</td>\n      <td>-0.027308</td>\n      <td>-0.027412</td>\n      <td>-0.027308</td>\n      <td>-0.027412</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.51611</td>\n      <td>0.412714</td>\n      <td>0.587769</td>\n      <td>0.423037</td>\n      <td>0.582952</td>\n      <td>0.422844</td>\n      <td>0.581875</td>\n      <td>0.422365</td>\n      <td>0.581861</td>\n      <td>0.422366</td>\n      <td>...</td>\n      <td>0.184613</td>\n      <td>0.184468</td>\n      <td>0.184563</td>\n      <td>0.183981</td>\n      <td>0.184126</td>\n      <td>0.183981</td>\n      <td>0.183672</td>\n      <td>0.183568</td>\n      <td>0.183672</td>\n      <td>0.183568</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.521253</td>\n      <td>0.417857</td>\n      <td>0.592912</td>\n      <td>0.42818</td>\n      <td>0.588095</td>\n      <td>0.427988</td>\n      <td>0.587018</td>\n      <td>0.427509</td>\n      <td>0.587004</td>\n      <td>0.427509</td>\n      <td>...</td>\n      <td>0.189757</td>\n      <td>0.189611</td>\n      <td>0.189707</td>\n      <td>0.189124</td>\n      <td>0.18927</td>\n      <td>0.189124</td>\n      <td>0.188816</td>\n      <td>0.188712</td>\n      <td>0.188816</td>\n      <td>0.188712</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.595254</td>\n      <td>0.491858</td>\n      <td>0.666913</td>\n      <td>0.502181</td>\n      <td>0.662096</td>\n      <td>0.501988</td>\n      <td>0.661019</td>\n      <td>0.501509</td>\n      <td>0.661005</td>\n      <td>0.501509</td>\n      <td>...</td>\n      <td>0.263757</td>\n      <td>0.263612</td>\n      <td>0.263707</td>\n      <td>0.263125</td>\n      <td>0.26327</td>\n      <td>0.263125</td>\n      <td>0.262816</td>\n      <td>0.262712</td>\n      <td>0.262816</td>\n      <td>0.262712</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>0.056794</td>\n      <td>-0.034994</td>\n      <td>0.086712</td>\n      <td>-0.028549</td>\n      <td>0.081906</td>\n      <td>-0.029207</td>\n      <td>0.080947</td>\n      <td>-0.031096</td>\n      <td>0.080312</td>\n      <td>-0.031096</td>\n      <td>...</td>\n      <td>-0.183321</td>\n      <td>-0.183529</td>\n      <td>-0.183399</td>\n      <td>-0.185332</td>\n      <td>-0.185124</td>\n      <td>-0.185332</td>\n      <td>-0.185858</td>\n      <td>-0.185966</td>\n      <td>-0.185858</td>\n      <td>-0.185966</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>-0.058225</td>\n      <td>-0.155677</td>\n      <td>-0.016742</td>\n      <td>-0.147935</td>\n      <td>-0.021772</td>\n      <td>-0.148252</td>\n      <td>-0.022854</td>\n      <td>-0.149097</td>\n      <td>-0.023093</td>\n      <td>-0.149097</td>\n      <td>...</td>\n      <td>-0.337706</td>\n      <td>-0.337974</td>\n      <td>-0.337814</td>\n      <td>-0.338853</td>\n      <td>-0.338585</td>\n      <td>-0.338853</td>\n      <td>-0.339283</td>\n      <td>-0.339464</td>\n      <td>-0.339283</td>\n      <td>-0.339464</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>-0.057151</td>\n      <td>-0.154603</td>\n      <td>-0.015668</td>\n      <td>-0.146861</td>\n      <td>-0.020697</td>\n      <td>-0.147179</td>\n      <td>-0.02178</td>\n      <td>-0.148023</td>\n      <td>-0.022019</td>\n      <td>-0.148023</td>\n      <td>...</td>\n      <td>-0.336632</td>\n      <td>-0.3369</td>\n      <td>-0.33674</td>\n      <td>-0.337779</td>\n      <td>-0.337511</td>\n      <td>-0.337779</td>\n      <td>-0.338209</td>\n      <td>-0.338391</td>\n      <td>-0.338209</td>\n      <td>-0.338391</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>-0.057359</td>\n      <td>-0.154811</td>\n      <td>-0.015876</td>\n      <td>-0.147069</td>\n      <td>-0.020906</td>\n      <td>-0.147386</td>\n      <td>-0.021988</td>\n      <td>-0.148231</td>\n      <td>-0.022227</td>\n      <td>-0.148231</td>\n      <td>...</td>\n      <td>-0.33684</td>\n      <td>-0.337108</td>\n      <td>-0.336948</td>\n      <td>-0.337987</td>\n      <td>-0.337719</td>\n      <td>-0.337987</td>\n      <td>-0.338417</td>\n      <td>-0.338598</td>\n      <td>-0.338417</td>\n      <td>-0.338598</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>-0.057936</td>\n      <td>-0.155388</td>\n      <td>-0.016453</td>\n      <td>-0.147646</td>\n      <td>-0.021483</td>\n      <td>-0.147964</td>\n      <td>-0.022565</td>\n      <td>-0.148808</td>\n      <td>-0.022804</td>\n      <td>-0.148808</td>\n      <td>...</td>\n      <td>-0.337417</td>\n      <td>-0.337685</td>\n      <td>-0.337525</td>\n      <td>-0.338564</td>\n      <td>-0.338296</td>\n      <td>-0.338564</td>\n      <td>-0.338994</td>\n      <td>-0.339175</td>\n      <td>-0.338994</td>\n      <td>-0.339175</td>\n    </tr>\n  </tbody>\n</table>\n<p>249 rows × 462 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_test = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "12.504194974899292"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_train = time.time()\n",
    "Training_time = end_time_train - start_time_train\n",
    "Training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_sim_index(index):\n",
    "    row1 = meta_dataset_similarity.loc[index]\n",
    "    row1_max_index = row1[row1 == row1.max()].index[0]\n",
    "    return row1_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index\n",
    "    index_row = index_row.values.tolist()\n",
    "    return index_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in datasets_test:\n",
    "    for model in model_test:\n",
    "        dataset_sim_list = Find_Top_k(dataset,meta_dataset_similarity)[1:]\n",
    "        # 仅保留存在于 model_prediction_train 的索引\n",
    "        valid_indices = [idx for idx in dataset_sim_list if idx in model_prediction_train.index][:15]\n",
    "        model_prediction_test.loc[dataset][model] = model_prediction_train.loc[valid_indices][model].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[271, 270, 269, 281, 280, 266, 265, 264, 263, 262, 255, 256, 268, 276, 279]"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "9.567063570022583"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if data_model_test_matrix.loc[i][j] == 0:\n",
    "            model_prediction_test.loc[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns={\"dataset\",\"model\",\"f1_score\",\"groundtruth_f1_score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if model_prediction_test.loc[i][j] is not None:\n",
    "            f1_score = model_prediction_test.loc[i][j]\n",
    "            groundtruth_f1_score = data_model_test_matrix.loc[i][j]\n",
    "            result = result.append([{'dataset':i,'model':j,'f1_score':f1_score,'groundtruth_f1_score':groundtruth_f1_score}],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      f1_score  groundtruth_f1_score dataset model\n0     0.376168              0.300000      93   463\n1     0.371448              0.300000      93   465\n2     0.593886              0.909091      93   363\n3     0.540648              0.303030      93   367\n4     0.528509              0.303030      93   369\n...        ...                   ...     ...   ...\n8207  0.235397              0.908689     283   307\n8208  0.555389              0.882246     283   317\n8209  0.570036              0.885276     283   315\n8210  0.048590              0.751981     283   303\n8211  0.048470              0.752451     283   305\n\n[8212 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1_score</th>\n      <th>groundtruth_f1_score</th>\n      <th>dataset</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.376168</td>\n      <td>0.300000</td>\n      <td>93</td>\n      <td>463</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.371448</td>\n      <td>0.300000</td>\n      <td>93</td>\n      <td>465</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.593886</td>\n      <td>0.909091</td>\n      <td>93</td>\n      <td>363</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.540648</td>\n      <td>0.303030</td>\n      <td>93</td>\n      <td>367</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.528509</td>\n      <td>0.303030</td>\n      <td>93</td>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8207</th>\n      <td>0.235397</td>\n      <td>0.908689</td>\n      <td>283</td>\n      <td>307</td>\n    </tr>\n    <tr>\n      <th>8208</th>\n      <td>0.555389</td>\n      <td>0.882246</td>\n      <td>283</td>\n      <td>317</td>\n    </tr>\n    <tr>\n      <th>8209</th>\n      <td>0.570036</td>\n      <td>0.885276</td>\n      <td>283</td>\n      <td>315</td>\n    </tr>\n    <tr>\n      <th>8210</th>\n      <td>0.048590</td>\n      <td>0.751981</td>\n      <td>283</td>\n      <td>303</td>\n    </tr>\n    <tr>\n      <th>8211</th>\n      <td>0.048470</td>\n      <td>0.752451</td>\n      <td>283</td>\n      <td>305</td>\n    </tr>\n  </tbody>\n</table>\n<p>8212 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"../Peak_Finding/Output/Dataset_RandomWalk/Full_Dataset_RandomWalk@6@15.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}