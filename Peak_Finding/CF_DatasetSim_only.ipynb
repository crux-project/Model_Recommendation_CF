{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"./Data/rate_train.csv\", low_memory=False)\n",
    "ratings_test = pd.read_csv(\"./Data/Ground_truth/groundtruth_0.3.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.Node_Id.unique()\n",
    "model_train = ratings_train.Model_Id.unique()\n",
    "datasets_test = ratings_test.dataset.unique()\n",
    "model_test = ratings_test.model.unique()\n",
    "meta_models = pd.read_csv(\"./Data/model_v.csv\",low_memory=False)\n",
    "models = meta_models.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=models)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]\n",
    "data_model_test_matrix = data_model_test_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"./Data/dataset_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.dataset_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,(\"v1\",\"v2\",\"v3\",\"v4\",\"v5\")]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对dataframe的数据进行标准化\n",
    "scaled_data = scaler.fit_transform(meta_datasets)\n",
    "# 将标准化后的数据转换为dataframe，并保留原始索引\n",
    "scaled_df = pd.DataFrame(scaled_data, index=meta_datasets.index, columns=meta_datasets.columns)\n",
    "meta_dataset_similarity = cosine_similarity(scaled_df.values.tolist())\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity,index=datasets,columns=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_func(ratings, user1, user2):\n",
    "    # 找到两个用户共同评分的物品，并将这些评分放入一个向量中\n",
    "    u1_ratings = ratings.loc[user1].dropna()\n",
    "    u2_ratings = ratings.loc[user2].dropna()\n",
    "\n",
    "    common_items = np.intersect1d(u1_ratings.index, u2_ratings.index).tolist()\n",
    "    u1_common_ratings = u1_ratings.loc[common_items]\n",
    "    u2_common_ratings = u2_ratings.loc[common_items]\n",
    "\n",
    "    # 计算两个向量之间的余弦相似度\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cos_sim = np.dot(u1_common_ratings, u2_common_ratings) / (np.linalg.norm(u1_common_ratings) * np.linalg.norm(u2_common_ratings))\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.5\n",
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        rating_based_sim = cosine_similarity_func(data_model_train_matrix,i,j)\n",
    "        if rating_based_sim != 0 and meta_dataset_similarity.loc[i][j] != 0:\n",
    "            dataset_similarity.loc[i][j] = lambda_ * rating_based_sim + (1-lambda_) * meta_dataset_similarity.loc[i][j]\n",
    "        else:\n",
    "            dataset_similarity.loc[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         29        14        28        16        17        13   \\\n0         1.0  0.098566  0.124857  0.126701  0.115517   0.13293  0.117093   \n29   0.098566       1.0  0.965814  0.966359  0.964421  0.982425  0.983555   \n14   0.124857  0.965814       1.0  0.997489  0.997701  0.962465  0.960072   \n28   0.126701  0.966359  0.997489       1.0  0.998165  0.963593   0.95976   \n16   0.115517  0.964421  0.997701  0.998165       1.0  0.962431  0.959373   \n..        ...       ...       ...       ...       ...       ...       ...   \n281 -0.055886  0.303703  0.326409  0.326415  0.328386  0.291435  0.290603   \n288  0.812771   0.21184  0.236114  0.237872  0.227722  0.244641  0.229842   \n286  0.811758  0.211555  0.235179  0.237363  0.227057  0.243541  0.228608   \n287  0.811325  0.211022  0.233865  0.236095   0.22589  0.243167    0.2284   \n285  0.813003  0.209916  0.234571  0.236248  0.225871  0.242597  0.227536   \n\n          12        10        38   ...       275       274       279  \\\n0    0.122764  0.111825  0.109823  ... -0.021234 -0.009148 -0.013077   \n29   0.982679  0.989046  0.995141  ...  0.244419  0.248923  0.249456   \n14   0.960677  0.981173  0.965994  ...  0.267301  0.270609  0.271789   \n28    0.96041  0.980392  0.966075  ...  0.267282  0.269679   0.26991   \n16   0.960092  0.979771  0.964312  ...  0.270424  0.271086   0.27273   \n..        ...       ...       ...  ...       ...       ...       ...   \n281  0.289715  0.313903  0.300455  ...  0.965017  0.966005  0.968387   \n288  0.235642  0.224502   0.22247  ...   0.08152   0.09323  0.089813   \n286  0.234369  0.223552  0.221961  ...  0.081978  0.093668  0.090225   \n287  0.234479  0.222974  0.221513  ...  0.083567  0.094867  0.091803   \n285  0.233323  0.222571  0.220498  ...  0.080662   0.09195  0.088953   \n\n          278       280       281       288       286       287       285  \n0   -0.004733 -0.042583 -0.055886  0.812771  0.811758  0.811325  0.813003  \n29   0.246419  0.295208  0.303703   0.21184  0.211555  0.211022  0.209916  \n14    0.26721  0.314695  0.326409  0.236114  0.235179  0.233865  0.234571  \n28   0.268026  0.317083  0.326415  0.237872  0.237363  0.236095  0.236248  \n16   0.268462  0.316068  0.328386  0.227722  0.227057   0.22589  0.225871  \n..        ...       ...       ...       ...       ...       ...       ...  \n281  0.962835  0.992795       1.0  0.145295  0.144876  0.145889  0.144497  \n288  0.097427  0.156297  0.145295       1.0  0.999436  0.999152  0.999744  \n286  0.097384  0.156139  0.144876  0.999436       1.0  0.999835  0.999073  \n287  0.098052  0.156498  0.145889  0.999152  0.999835       1.0  0.998646  \n285  0.095786  0.155713  0.144497  0.999744  0.999073  0.998646       1.0  \n\n[249 rows x 249 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>29</th>\n      <th>14</th>\n      <th>28</th>\n      <th>16</th>\n      <th>17</th>\n      <th>13</th>\n      <th>12</th>\n      <th>10</th>\n      <th>38</th>\n      <th>...</th>\n      <th>275</th>\n      <th>274</th>\n      <th>279</th>\n      <th>278</th>\n      <th>280</th>\n      <th>281</th>\n      <th>288</th>\n      <th>286</th>\n      <th>287</th>\n      <th>285</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.098566</td>\n      <td>0.124857</td>\n      <td>0.126701</td>\n      <td>0.115517</td>\n      <td>0.13293</td>\n      <td>0.117093</td>\n      <td>0.122764</td>\n      <td>0.111825</td>\n      <td>0.109823</td>\n      <td>...</td>\n      <td>-0.021234</td>\n      <td>-0.009148</td>\n      <td>-0.013077</td>\n      <td>-0.004733</td>\n      <td>-0.042583</td>\n      <td>-0.055886</td>\n      <td>0.812771</td>\n      <td>0.811758</td>\n      <td>0.811325</td>\n      <td>0.813003</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.098566</td>\n      <td>1.0</td>\n      <td>0.965814</td>\n      <td>0.966359</td>\n      <td>0.964421</td>\n      <td>0.982425</td>\n      <td>0.983555</td>\n      <td>0.982679</td>\n      <td>0.989046</td>\n      <td>0.995141</td>\n      <td>...</td>\n      <td>0.244419</td>\n      <td>0.248923</td>\n      <td>0.249456</td>\n      <td>0.246419</td>\n      <td>0.295208</td>\n      <td>0.303703</td>\n      <td>0.21184</td>\n      <td>0.211555</td>\n      <td>0.211022</td>\n      <td>0.209916</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.124857</td>\n      <td>0.965814</td>\n      <td>1.0</td>\n      <td>0.997489</td>\n      <td>0.997701</td>\n      <td>0.962465</td>\n      <td>0.960072</td>\n      <td>0.960677</td>\n      <td>0.981173</td>\n      <td>0.965994</td>\n      <td>...</td>\n      <td>0.267301</td>\n      <td>0.270609</td>\n      <td>0.271789</td>\n      <td>0.26721</td>\n      <td>0.314695</td>\n      <td>0.326409</td>\n      <td>0.236114</td>\n      <td>0.235179</td>\n      <td>0.233865</td>\n      <td>0.234571</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.126701</td>\n      <td>0.966359</td>\n      <td>0.997489</td>\n      <td>1.0</td>\n      <td>0.998165</td>\n      <td>0.963593</td>\n      <td>0.95976</td>\n      <td>0.96041</td>\n      <td>0.980392</td>\n      <td>0.966075</td>\n      <td>...</td>\n      <td>0.267282</td>\n      <td>0.269679</td>\n      <td>0.26991</td>\n      <td>0.268026</td>\n      <td>0.317083</td>\n      <td>0.326415</td>\n      <td>0.237872</td>\n      <td>0.237363</td>\n      <td>0.236095</td>\n      <td>0.236248</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.115517</td>\n      <td>0.964421</td>\n      <td>0.997701</td>\n      <td>0.998165</td>\n      <td>1.0</td>\n      <td>0.962431</td>\n      <td>0.959373</td>\n      <td>0.960092</td>\n      <td>0.979771</td>\n      <td>0.964312</td>\n      <td>...</td>\n      <td>0.270424</td>\n      <td>0.271086</td>\n      <td>0.27273</td>\n      <td>0.268462</td>\n      <td>0.316068</td>\n      <td>0.328386</td>\n      <td>0.227722</td>\n      <td>0.227057</td>\n      <td>0.22589</td>\n      <td>0.225871</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>-0.055886</td>\n      <td>0.303703</td>\n      <td>0.326409</td>\n      <td>0.326415</td>\n      <td>0.328386</td>\n      <td>0.291435</td>\n      <td>0.290603</td>\n      <td>0.289715</td>\n      <td>0.313903</td>\n      <td>0.300455</td>\n      <td>...</td>\n      <td>0.965017</td>\n      <td>0.966005</td>\n      <td>0.968387</td>\n      <td>0.962835</td>\n      <td>0.992795</td>\n      <td>1.0</td>\n      <td>0.145295</td>\n      <td>0.144876</td>\n      <td>0.145889</td>\n      <td>0.144497</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>0.812771</td>\n      <td>0.21184</td>\n      <td>0.236114</td>\n      <td>0.237872</td>\n      <td>0.227722</td>\n      <td>0.244641</td>\n      <td>0.229842</td>\n      <td>0.235642</td>\n      <td>0.224502</td>\n      <td>0.22247</td>\n      <td>...</td>\n      <td>0.08152</td>\n      <td>0.09323</td>\n      <td>0.089813</td>\n      <td>0.097427</td>\n      <td>0.156297</td>\n      <td>0.145295</td>\n      <td>1.0</td>\n      <td>0.999436</td>\n      <td>0.999152</td>\n      <td>0.999744</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>0.811758</td>\n      <td>0.211555</td>\n      <td>0.235179</td>\n      <td>0.237363</td>\n      <td>0.227057</td>\n      <td>0.243541</td>\n      <td>0.228608</td>\n      <td>0.234369</td>\n      <td>0.223552</td>\n      <td>0.221961</td>\n      <td>...</td>\n      <td>0.081978</td>\n      <td>0.093668</td>\n      <td>0.090225</td>\n      <td>0.097384</td>\n      <td>0.156139</td>\n      <td>0.144876</td>\n      <td>0.999436</td>\n      <td>1.0</td>\n      <td>0.999835</td>\n      <td>0.999073</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>0.811325</td>\n      <td>0.211022</td>\n      <td>0.233865</td>\n      <td>0.236095</td>\n      <td>0.22589</td>\n      <td>0.243167</td>\n      <td>0.2284</td>\n      <td>0.234479</td>\n      <td>0.222974</td>\n      <td>0.221513</td>\n      <td>...</td>\n      <td>0.083567</td>\n      <td>0.094867</td>\n      <td>0.091803</td>\n      <td>0.098052</td>\n      <td>0.156498</td>\n      <td>0.145889</td>\n      <td>0.999152</td>\n      <td>0.999835</td>\n      <td>1.0</td>\n      <td>0.998646</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>0.813003</td>\n      <td>0.209916</td>\n      <td>0.234571</td>\n      <td>0.236248</td>\n      <td>0.225871</td>\n      <td>0.242597</td>\n      <td>0.227536</td>\n      <td>0.233323</td>\n      <td>0.222571</td>\n      <td>0.220498</td>\n      <td>...</td>\n      <td>0.080662</td>\n      <td>0.09195</td>\n      <td>0.088953</td>\n      <td>0.095786</td>\n      <td>0.155713</td>\n      <td>0.144497</td>\n      <td>0.999744</td>\n      <td>0.999073</td>\n      <td>0.998646</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>249 rows × 249 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(rating_matrix, similarity_matrix):\n",
    "    \"\"\"\n",
    "    根据评分矩阵和相似度矩阵预测评分。\n",
    "\n",
    "    参数：\n",
    "    rating_matrix (pd.DataFrame)：评分矩阵，包含NaN值\n",
    "    similarity_matrix (numpy.array)：相似度矩阵\n",
    "\n",
    "    返回：\n",
    "    pd.DataFrame：预测评分矩阵\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取评分矩阵的均值（忽略NaN值）\n",
    "    mean_rating = rating_matrix.mean(axis=1).values\n",
    "\n",
    "    # 将评分矩阵中的NaN值替换为0\n",
    "    rating_matrix_nan_to_zero = rating_matrix.fillna(0).values\n",
    "\n",
    "    # 减去均值，得到归一化的评分矩阵\n",
    "    normalized_rating_matrix = rating_matrix_nan_to_zero - mean_rating[:, np.newaxis]\n",
    "\n",
    "    # 计算预测评分\n",
    "    predicted_ratings = mean_rating[:, np.newaxis] + np.dot(similarity_matrix, normalized_rating_matrix) / np.abs(similarity_matrix).sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 将预测评分数组转换为DataFrame\n",
    "    predicted_ratings_df = pd.DataFrame(predicted_ratings, index=rating_matrix.index, columns=rating_matrix.columns)\n",
    "\n",
    "    return predicted_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ratings(rating_matrix, user_similarity_matrix, k=5):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "    rating_matrix - 评分矩阵，DataFrame格式，其中NaN表示未评分\n",
    "    user_similarity_matrix - 用户相似度矩阵，DataFrame格式\n",
    "    k - 最近邻的数量，默认为5\n",
    "\n",
    "    输出：\n",
    "    prediction_matrix - 预测矩阵，DataFrame格式\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化预测矩阵\n",
    "    prediction_matrix = rating_matrix.copy()\n",
    "\n",
    "    # 对于评分矩阵中的每个NaN值，使用K最近邻的方法预测评分\n",
    "    for i in rating_matrix.index:\n",
    "        for j in rating_matrix.columns:\n",
    "            if np.isnan(rating_matrix.loc[i][j]):\n",
    "                # 获取第i个用户的相似度值，并在相似度矩阵中找到K个最相似的用户\n",
    "                similarity_values = user_similarity_matrix.loc[i].sort_values(ascending=False)[1:k+1]\n",
    "\n",
    "                # 计算加权平均评分\n",
    "                weighted_sum = 0\n",
    "                similarity_sum = 0\n",
    "                for index, value in similarity_values.items():\n",
    "                    user_rating = rating_matrix.loc[index][j]\n",
    "                    if not np.isnan(user_rating):\n",
    "                        weighted_sum += value * user_rating\n",
    "                        similarity_sum += value\n",
    "\n",
    "                # 如果存在至少一个相似用户对该物品进行了评分，则计算预测评分\n",
    "                if similarity_sum != 0:\n",
    "                    prediction_matrix.loc[i][j] = weighted_sum / similarity_sum\n",
    "                else:\n",
    "                    # 如果没有相似用户评分，则使用当前用户的平均评分作为预测值\n",
    "                    prediction_matrix.loc[i][j] = rating_matrix.loc[i].mean()\n",
    "\n",
    "    return prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_train = predict_ratings(data_model_train_matrix,dataset_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_train = pd.DataFrame(model_prediction_train,index=datasets_train,columns=models).sort_index().sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_test = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "56.85710620880127"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_time = end_time_train - start_time_train\n",
    "Training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Metadata Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_sim_index(index):\n",
    "    row1 = meta_dataset_similarity.loc[index]\n",
    "    row1_max_index = row1[row1 == row1.max()].index[0]\n",
    "    return row1_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index\n",
    "    index_row = index_row.values.tolist()\n",
    "    return index_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in datasets_test:\n",
    "    for model in model_test:\n",
    "        dataset_sim_list = Find_Top_k(dataset,meta_dataset_similarity)[1:]\n",
    "        # 仅保留存在于 model_prediction_train 的索引\n",
    "        valid_indices = [idx for idx in dataset_sim_list if idx in model_prediction_train.index][:15]\n",
    "        model_prediction_test.loc[dataset][model] = model_prediction_train.loc[valid_indices][model].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[271, 270, 269, 281, 280, 266, 265, 264, 263, 262, 255, 256, 268, 276, 279]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "9.989575147628784"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if data_model_test_matrix.loc[i][j] == 0:\n",
    "            model_prediction_test.loc[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns={\"dataset\",\"model\",\"f1_score\",\"groundtruth_f1_score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if model_prediction_test.loc[i][j] is not None:\n",
    "            f1_score = model_prediction_test.loc[i][j]\n",
    "            groundtruth_f1_score = data_model_test_matrix.loc[i][j]\n",
    "            result = result.append([{'dataset':i,'model':j,'f1_score':f1_score,'groundtruth_f1_score':groundtruth_f1_score}],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     model dataset  groundtruth_f1_score  f1_score\n0      463      93              0.300000  0.356665\n1      465      93              0.300000  0.350868\n2      363      93              0.909091  0.544820\n3      367      93              0.303030  0.623460\n4      369      93              0.303030  0.613331\n...    ...     ...                   ...       ...\n8207   307     283              0.908689  0.684266\n8208   317     283              0.882246  0.676334\n8209   315     283              0.885276  0.678318\n8210   303     283              0.751981  0.595143\n8211   305     283              0.752451  0.594892\n\n[8212 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dataset</th>\n      <th>groundtruth_f1_score</th>\n      <th>f1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>463</td>\n      <td>93</td>\n      <td>0.300000</td>\n      <td>0.356665</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>465</td>\n      <td>93</td>\n      <td>0.300000</td>\n      <td>0.350868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>363</td>\n      <td>93</td>\n      <td>0.909091</td>\n      <td>0.544820</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>367</td>\n      <td>93</td>\n      <td>0.303030</td>\n      <td>0.623460</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>369</td>\n      <td>93</td>\n      <td>0.303030</td>\n      <td>0.613331</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8207</th>\n      <td>307</td>\n      <td>283</td>\n      <td>0.908689</td>\n      <td>0.684266</td>\n    </tr>\n    <tr>\n      <th>8208</th>\n      <td>317</td>\n      <td>283</td>\n      <td>0.882246</td>\n      <td>0.676334</td>\n    </tr>\n    <tr>\n      <th>8209</th>\n      <td>315</td>\n      <td>283</td>\n      <td>0.885276</td>\n      <td>0.678318</td>\n    </tr>\n    <tr>\n      <th>8210</th>\n      <td>303</td>\n      <td>283</td>\n      <td>0.751981</td>\n      <td>0.595143</td>\n    </tr>\n    <tr>\n      <th>8211</th>\n      <td>305</td>\n      <td>283</td>\n      <td>0.752451</td>\n      <td>0.594892</td>\n    </tr>\n  </tbody>\n</table>\n<p>8212 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"../Peak_Finding/Output/Dataset_only/Full_Dataset_only@15.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}