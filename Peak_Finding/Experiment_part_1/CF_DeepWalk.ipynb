{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import random\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings= pd.read_csv(\"./Data/ratings.csv\", low_memory=False)\n",
    "train_data = pd.read_csv(\"./Data/train_data.csv\",low_memory=False)\n",
    "test_data = pd.read_csv(\"./Data/test_data.csv\",low_memory=False)\n",
    "# train_data, test_data = train_test_split(ratings, test_size=0.3, random_state=42)\n",
    "# # 保存训练集为csv文件\n",
    "# train_data.to_csv('./Data/train_data.csv',index=False)\n",
    "# # 保存测试集为csv文件\n",
    "# test_data.to_csv('./Data/test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ratings.dataset_id.unique()\n",
    "models = ratings.model_id.unique()\n",
    "datasets_train = train_data.dataset_id.unique()\n",
    "model_train = train_data.model_id.unique()\n",
    "datasets_test = test_data.dataset_id.unique()\n",
    "model_test = test_data.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=model_train)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in train_data.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in test_data.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_graph_from_df(df):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for user in df.index:\n",
    "        for item in df.columns:\n",
    "            rating = df.loc[user, item]\n",
    "            if not np.isnan(rating):\n",
    "                G.add_edge(user, item, weight=rating)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def deepwalk(G, walk_length=1, num_walks=1, embed_size=32):\n",
    "    walks = []\n",
    "    for node in G.nodes():\n",
    "        if G.degree(node) == 0:\n",
    "            continue\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]\n",
    "                cur_nbrs = list(G.neighbors(cur))\n",
    "                walk.append(np.random.choice(cur_nbrs))\n",
    "            walks.append([str(node) for node in walk])\n",
    "\n",
    "    model = Word2Vec(walks, vector_size=embed_size, window=5, min_count=0, sg=1, workers=4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weighted_walks(G, walk_length=10, num_walks=1,embed_size=32):\n",
    "    walks = []\n",
    "    nodes = list(G.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walk = [node]\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if neighbors:\n",
    "                    # The probability of the next step is proportional to the weight of the edge\n",
    "                    weights = [G[cur][neighbor]['weight'] for neighbor in neighbors]\n",
    "                    probabilities = weights / np.sum(weights)\n",
    "                    next_node = np.random.choice(neighbors, p=probabilities)\n",
    "                    walk.append(next_node)\n",
    "                else:\n",
    "                    break\n",
    "            walks.append([str(node) for node in walk])\n",
    "    model = Word2Vec(walks, vector_size=embed_size, window=5, min_count=0, sg=1, workers=4)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_similarity_matrix(model, user_nodes):\n",
    "    embeddings = np.array([model.wv.get_vector(str(user)) for user in user_nodes])\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    return pd.DataFrame(similarity_matrix, index=user_nodes, columns=user_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 创建图\n",
    "G = create_graph_from_df(data_model_train_matrix)\n",
    "\n",
    "# 执行DeepWalk算法\n",
    "model = generate_weighted_walks(G)\n",
    "\n",
    "# 获取用户相似性矩阵\n",
    "user_nodes = data_model_train_matrix.index.tolist()\n",
    "similarity_matrix = get_similarity_matrix(model, user_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48</th>\n",
       "      <th>14</th>\n",
       "      <th>60</th>\n",
       "      <th>237</th>\n",
       "      <th>250</th>\n",
       "      <th>246</th>\n",
       "      <th>51</th>\n",
       "      <th>1</th>\n",
       "      <th>74</th>\n",
       "      <th>248</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>149</th>\n",
       "      <th>85</th>\n",
       "      <th>128</th>\n",
       "      <th>229</th>\n",
       "      <th>205</th>\n",
       "      <th>71</th>\n",
       "      <th>109</th>\n",
       "      <th>59</th>\n",
       "      <th>76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993330</td>\n",
       "      <td>0.994590</td>\n",
       "      <td>0.900500</td>\n",
       "      <td>0.980520</td>\n",
       "      <td>0.986121</td>\n",
       "      <td>0.993900</td>\n",
       "      <td>0.992663</td>\n",
       "      <td>0.992556</td>\n",
       "      <td>0.992176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>0.993086</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.995027</td>\n",
       "      <td>0.992860</td>\n",
       "      <td>0.993438</td>\n",
       "      <td>0.993336</td>\n",
       "      <td>0.994063</td>\n",
       "      <td>0.992770</td>\n",
       "      <td>0.992508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.993330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>0.898781</td>\n",
       "      <td>0.981719</td>\n",
       "      <td>0.985850</td>\n",
       "      <td>0.994083</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.991624</td>\n",
       "      <td>0.989979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992623</td>\n",
       "      <td>0.996407</td>\n",
       "      <td>0.991163</td>\n",
       "      <td>0.994449</td>\n",
       "      <td>0.992729</td>\n",
       "      <td>0.994636</td>\n",
       "      <td>0.991232</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.990439</td>\n",
       "      <td>0.992939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.994590</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900396</td>\n",
       "      <td>0.988415</td>\n",
       "      <td>0.985840</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.993226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993758</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>0.992452</td>\n",
       "      <td>0.994694</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>0.995201</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.992929</td>\n",
       "      <td>0.993154</td>\n",
       "      <td>0.993360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.900500</td>\n",
       "      <td>0.898781</td>\n",
       "      <td>0.900396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882757</td>\n",
       "      <td>0.887775</td>\n",
       "      <td>0.894688</td>\n",
       "      <td>0.907678</td>\n",
       "      <td>0.898911</td>\n",
       "      <td>0.895489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900657</td>\n",
       "      <td>0.890126</td>\n",
       "      <td>0.903924</td>\n",
       "      <td>0.901481</td>\n",
       "      <td>0.897331</td>\n",
       "      <td>0.902817</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.888221</td>\n",
       "      <td>0.899857</td>\n",
       "      <td>0.889990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.980520</td>\n",
       "      <td>0.981719</td>\n",
       "      <td>0.988415</td>\n",
       "      <td>0.882757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976027</td>\n",
       "      <td>0.984558</td>\n",
       "      <td>0.983652</td>\n",
       "      <td>0.982994</td>\n",
       "      <td>0.982726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985228</td>\n",
       "      <td>0.982062</td>\n",
       "      <td>0.980744</td>\n",
       "      <td>0.981215</td>\n",
       "      <td>0.982576</td>\n",
       "      <td>0.983794</td>\n",
       "      <td>0.980530</td>\n",
       "      <td>0.986487</td>\n",
       "      <td>0.979403</td>\n",
       "      <td>0.982077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.993438</td>\n",
       "      <td>0.994636</td>\n",
       "      <td>0.995201</td>\n",
       "      <td>0.902817</td>\n",
       "      <td>0.983794</td>\n",
       "      <td>0.983902</td>\n",
       "      <td>0.994345</td>\n",
       "      <td>0.993483</td>\n",
       "      <td>0.993549</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992691</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.993546</td>\n",
       "      <td>0.994230</td>\n",
       "      <td>0.994502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993144</td>\n",
       "      <td>0.991506</td>\n",
       "      <td>0.991801</td>\n",
       "      <td>0.995462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.993336</td>\n",
       "      <td>0.991232</td>\n",
       "      <td>0.991272</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.980530</td>\n",
       "      <td>0.984502</td>\n",
       "      <td>0.995623</td>\n",
       "      <td>0.994401</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>0.993803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991759</td>\n",
       "      <td>0.992317</td>\n",
       "      <td>0.995043</td>\n",
       "      <td>0.993818</td>\n",
       "      <td>0.990010</td>\n",
       "      <td>0.993144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>0.990889</td>\n",
       "      <td>0.990662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.994063</td>\n",
       "      <td>0.992444</td>\n",
       "      <td>0.992929</td>\n",
       "      <td>0.888221</td>\n",
       "      <td>0.986487</td>\n",
       "      <td>0.983813</td>\n",
       "      <td>0.992265</td>\n",
       "      <td>0.994038</td>\n",
       "      <td>0.992619</td>\n",
       "      <td>0.991258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.991912</td>\n",
       "      <td>0.990813</td>\n",
       "      <td>0.991917</td>\n",
       "      <td>0.992025</td>\n",
       "      <td>0.991506</td>\n",
       "      <td>0.991420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>0.992227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.992770</td>\n",
       "      <td>0.990439</td>\n",
       "      <td>0.993154</td>\n",
       "      <td>0.899857</td>\n",
       "      <td>0.979403</td>\n",
       "      <td>0.979481</td>\n",
       "      <td>0.994660</td>\n",
       "      <td>0.991557</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.992279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989088</td>\n",
       "      <td>0.993107</td>\n",
       "      <td>0.991181</td>\n",
       "      <td>0.990629</td>\n",
       "      <td>0.992078</td>\n",
       "      <td>0.991801</td>\n",
       "      <td>0.990889</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.992508</td>\n",
       "      <td>0.992939</td>\n",
       "      <td>0.993360</td>\n",
       "      <td>0.889990</td>\n",
       "      <td>0.982077</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.992691</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.991326</td>\n",
       "      <td>0.993839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991731</td>\n",
       "      <td>0.995429</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>0.991742</td>\n",
       "      <td>0.994452</td>\n",
       "      <td>0.995462</td>\n",
       "      <td>0.990662</td>\n",
       "      <td>0.992227</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          48        14        60        237       250       246       51   \\\n",
       "48   1.000000  0.993330  0.994590  0.900500  0.980520  0.986121  0.993900   \n",
       "14   0.993330  1.000000  0.992685  0.898781  0.981719  0.985850  0.994083   \n",
       "60   0.994590  0.992685  1.000000  0.900396  0.988415  0.985840  0.993139   \n",
       "237  0.900500  0.898781  0.900396  1.000000  0.882757  0.887775  0.894688   \n",
       "250  0.980520  0.981719  0.988415  0.882757  1.000000  0.976027  0.984558   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "205  0.993438  0.994636  0.995201  0.902817  0.983794  0.983902  0.994345   \n",
       "71   0.993336  0.991232  0.991272  0.908691  0.980530  0.984502  0.995623   \n",
       "109  0.994063  0.992444  0.992929  0.888221  0.986487  0.983813  0.992265   \n",
       "59   0.992770  0.990439  0.993154  0.899857  0.979403  0.979481  0.994660   \n",
       "76   0.992508  0.992939  0.993360  0.889990  0.982077  0.983218  0.992691   \n",
       "\n",
       "          1         74        248  ...       50        149       85   \\\n",
       "48   0.992663  0.992556  0.992176  ...  0.994697  0.993086  0.994355   \n",
       "14   0.994545  0.991624  0.989979  ...  0.992623  0.996407  0.991163   \n",
       "60   0.994015  0.992701  0.993226  ...  0.993758  0.993650  0.992452   \n",
       "237  0.907678  0.898911  0.895489  ...  0.900657  0.890126  0.903924   \n",
       "250  0.983652  0.982994  0.982726  ...  0.985228  0.982062  0.980744   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "205  0.993483  0.993549  0.994162  ...  0.992691  0.995050  0.993546   \n",
       "71   0.994401  0.993493  0.993803  ...  0.991759  0.992317  0.995043   \n",
       "109  0.994038  0.992619  0.991258  ...  0.993711  0.991912  0.990813   \n",
       "59   0.991557  0.989949  0.992279  ...  0.989088  0.993107  0.991181   \n",
       "76   0.994413  0.991326  0.993839  ...  0.991731  0.995429  0.991947   \n",
       "\n",
       "          128       229       205       71        109       59        76   \n",
       "48   0.995027  0.992860  0.993438  0.993336  0.994063  0.992770  0.992508  \n",
       "14   0.994449  0.992729  0.994636  0.991232  0.992444  0.990439  0.992939  \n",
       "60   0.994694  0.995147  0.995201  0.991272  0.992929  0.993154  0.993360  \n",
       "237  0.901481  0.897331  0.902817  0.908691  0.888221  0.899857  0.889990  \n",
       "250  0.981215  0.982576  0.983794  0.980530  0.986487  0.979403  0.982077  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "205  0.994230  0.994502  1.000000  0.993144  0.991506  0.991801  0.995462  \n",
       "71   0.993818  0.990010  0.993144  1.000000  0.991420  0.990889  0.990662  \n",
       "109  0.991917  0.992025  0.991506  0.991420  1.000000  0.990859  0.992227  \n",
       "59   0.990629  0.992078  0.991801  0.990889  0.990859  1.000000  0.993730  \n",
       "76   0.991742  0.994452  0.995462  0.990662  0.992227  0.993730  1.000000  \n",
       "\n",
       "[289 rows x 289 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train).sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        dataset_similarity.loc[i][j] = similarity_matrix.loc[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98951</td>\n",
       "      <td>0.988842</td>\n",
       "      <td>0.98698</td>\n",
       "      <td>0.98737</td>\n",
       "      <td>0.986735</td>\n",
       "      <td>0.990386</td>\n",
       "      <td>0.987238</td>\n",
       "      <td>0.986405</td>\n",
       "      <td>0.986196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975112</td>\n",
       "      <td>0.987875</td>\n",
       "      <td>0.986671</td>\n",
       "      <td>0.989368</td>\n",
       "      <td>0.983222</td>\n",
       "      <td>0.960405</td>\n",
       "      <td>0.934319</td>\n",
       "      <td>0.970912</td>\n",
       "      <td>0.975678</td>\n",
       "      <td>0.954783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98951</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994801</td>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.992265</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>0.99511</td>\n",
       "      <td>0.991536</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>0.993653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988778</td>\n",
       "      <td>0.995975</td>\n",
       "      <td>0.992429</td>\n",
       "      <td>0.991993</td>\n",
       "      <td>0.986599</td>\n",
       "      <td>0.971868</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>0.982699</td>\n",
       "      <td>0.95651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.988842</td>\n",
       "      <td>0.994801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>0.994841</td>\n",
       "      <td>0.996102</td>\n",
       "      <td>0.989963</td>\n",
       "      <td>0.991585</td>\n",
       "      <td>0.991039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985172</td>\n",
       "      <td>0.993351</td>\n",
       "      <td>0.992087</td>\n",
       "      <td>0.991796</td>\n",
       "      <td>0.988492</td>\n",
       "      <td>0.970975</td>\n",
       "      <td>0.955456</td>\n",
       "      <td>0.979991</td>\n",
       "      <td>0.976786</td>\n",
       "      <td>0.958329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98698</td>\n",
       "      <td>0.994094</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986893</td>\n",
       "      <td>0.991879</td>\n",
       "      <td>0.995973</td>\n",
       "      <td>0.991907</td>\n",
       "      <td>0.991556</td>\n",
       "      <td>0.990413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.991547</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.990647</td>\n",
       "      <td>0.987274</td>\n",
       "      <td>0.977493</td>\n",
       "      <td>0.953694</td>\n",
       "      <td>0.971023</td>\n",
       "      <td>0.978768</td>\n",
       "      <td>0.953422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98737</td>\n",
       "      <td>0.992265</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>0.986893</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.992966</td>\n",
       "      <td>0.987197</td>\n",
       "      <td>0.991581</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982651</td>\n",
       "      <td>0.991513</td>\n",
       "      <td>0.993541</td>\n",
       "      <td>0.992034</td>\n",
       "      <td>0.98485</td>\n",
       "      <td>0.971011</td>\n",
       "      <td>0.955592</td>\n",
       "      <td>0.980192</td>\n",
       "      <td>0.982766</td>\n",
       "      <td>0.963604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.960405</td>\n",
       "      <td>0.971868</td>\n",
       "      <td>0.970975</td>\n",
       "      <td>0.977493</td>\n",
       "      <td>0.971011</td>\n",
       "      <td>0.969346</td>\n",
       "      <td>0.977726</td>\n",
       "      <td>0.96887</td>\n",
       "      <td>0.970288</td>\n",
       "      <td>0.971146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966969</td>\n",
       "      <td>0.972939</td>\n",
       "      <td>0.977286</td>\n",
       "      <td>0.969668</td>\n",
       "      <td>0.96739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965254</td>\n",
       "      <td>0.941535</td>\n",
       "      <td>0.964211</td>\n",
       "      <td>0.927476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.934319</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.955456</td>\n",
       "      <td>0.953694</td>\n",
       "      <td>0.955592</td>\n",
       "      <td>0.957763</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.953577</td>\n",
       "      <td>0.953299</td>\n",
       "      <td>0.953425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.958181</td>\n",
       "      <td>0.965485</td>\n",
       "      <td>0.94841</td>\n",
       "      <td>0.96394</td>\n",
       "      <td>0.965254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.938565</td>\n",
       "      <td>0.949816</td>\n",
       "      <td>0.912479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.970912</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>0.979991</td>\n",
       "      <td>0.971023</td>\n",
       "      <td>0.980192</td>\n",
       "      <td>0.973527</td>\n",
       "      <td>0.976881</td>\n",
       "      <td>0.97195</td>\n",
       "      <td>0.978863</td>\n",
       "      <td>0.976383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966015</td>\n",
       "      <td>0.973781</td>\n",
       "      <td>0.97373</td>\n",
       "      <td>0.977017</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.941535</td>\n",
       "      <td>0.938565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959967</td>\n",
       "      <td>0.936275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.975678</td>\n",
       "      <td>0.982699</td>\n",
       "      <td>0.976786</td>\n",
       "      <td>0.978768</td>\n",
       "      <td>0.982766</td>\n",
       "      <td>0.97919</td>\n",
       "      <td>0.983552</td>\n",
       "      <td>0.98426</td>\n",
       "      <td>0.984243</td>\n",
       "      <td>0.980684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971454</td>\n",
       "      <td>0.984769</td>\n",
       "      <td>0.984688</td>\n",
       "      <td>0.976728</td>\n",
       "      <td>0.980358</td>\n",
       "      <td>0.964211</td>\n",
       "      <td>0.949816</td>\n",
       "      <td>0.959967</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.954783</td>\n",
       "      <td>0.95651</td>\n",
       "      <td>0.958329</td>\n",
       "      <td>0.953422</td>\n",
       "      <td>0.963604</td>\n",
       "      <td>0.953306</td>\n",
       "      <td>0.960224</td>\n",
       "      <td>0.948094</td>\n",
       "      <td>0.946808</td>\n",
       "      <td>0.945782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944876</td>\n",
       "      <td>0.957634</td>\n",
       "      <td>0.963139</td>\n",
       "      <td>0.955437</td>\n",
       "      <td>0.942438</td>\n",
       "      <td>0.927476</td>\n",
       "      <td>0.912479</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.946137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0           1   0.98951  0.988842   0.98698   0.98737  0.986735  0.990386   \n",
       "1     0.98951         1  0.994801  0.994094  0.992265  0.993884   0.99511   \n",
       "2    0.988842  0.994801         1  0.995117  0.991939  0.994841  0.996102   \n",
       "3     0.98698  0.994094  0.995117         1  0.986893  0.991879  0.995973   \n",
       "4     0.98737  0.992265  0.991939  0.986893         1  0.989978  0.992966   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "284  0.960405  0.971868  0.970975  0.977493  0.971011  0.969346  0.977726   \n",
       "285  0.934319  0.960584  0.955456  0.953694  0.955592  0.957763  0.956757   \n",
       "286  0.970912  0.978977  0.979991  0.971023  0.980192  0.973527  0.976881   \n",
       "287  0.975678  0.982699  0.976786  0.978768  0.982766   0.97919  0.983552   \n",
       "288  0.954783   0.95651  0.958329  0.953422  0.963604  0.953306  0.960224   \n",
       "\n",
       "          7         8         9    ...       279       280       281  \\\n",
       "0    0.987238  0.986405  0.986196  ...  0.975112  0.987875  0.986671   \n",
       "1    0.991536  0.992832  0.993653  ...  0.988778  0.995975  0.992429   \n",
       "2    0.989963  0.991585  0.991039  ...  0.985172  0.993351  0.992087   \n",
       "3    0.991907  0.991556  0.990413  ...  0.984915  0.991547  0.991474   \n",
       "4    0.987197  0.991581  0.990458  ...  0.982651  0.991513  0.993541   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "284   0.96887  0.970288  0.971146  ...  0.966969  0.972939  0.977286   \n",
       "285  0.953577  0.953299  0.953425  ...  0.949749  0.958181  0.965485   \n",
       "286   0.97195  0.978863  0.976383  ...  0.966015  0.973781   0.97373   \n",
       "287   0.98426  0.984243  0.980684  ...  0.971454  0.984769  0.984688   \n",
       "288  0.948094  0.946808  0.945782  ...  0.944876  0.957634  0.963139   \n",
       "\n",
       "          282       283       284       285       286       287       288  \n",
       "0    0.989368  0.983222  0.960405  0.934319  0.970912  0.975678  0.954783  \n",
       "1    0.991993  0.986599  0.971868  0.960584  0.978977  0.982699   0.95651  \n",
       "2    0.991796  0.988492  0.970975  0.955456  0.979991  0.976786  0.958329  \n",
       "3    0.990647  0.987274  0.977493  0.953694  0.971023  0.978768  0.953422  \n",
       "4    0.992034   0.98485  0.971011  0.955592  0.980192  0.982766  0.963604  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "284  0.969668   0.96739         1  0.965254  0.941535  0.964211  0.927476  \n",
       "285   0.94841   0.96394  0.965254         1  0.938565  0.949816  0.912479  \n",
       "286  0.977017  0.969028  0.941535  0.938565         1  0.959967  0.936275  \n",
       "287  0.976728  0.980358  0.964211  0.949816  0.959967         1  0.946137  \n",
       "288  0.955437  0.942438  0.927476  0.912479  0.936275  0.946137         1  \n",
       "\n",
       "[289 rows x 289 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def positive_similarity_ratio(similarity_matrix):\n",
    "    # Count the number of positive similarities\n",
    "    num_positive_similarities = (similarity_matrix > 0).sum().sum()\n",
    "\n",
    "    # Count the total number of similarities\n",
    "    total_similarities = similarity_matrix.size\n",
    "\n",
    "    # Compute the ratio of positive similarities\n",
    "    ratio = num_positive_similarities / total_similarities\n",
    "\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_similarity_ratio(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0927438735961914"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_train - start_time_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_ref = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def predict(ratings, similarity):\n",
    "    mean_user_rating = ratings.fillna(0).mean(axis=1)\n",
    "    ratings_diff = (ratings - mean_user_rating[:, np.newaxis]).fillna(0)\n",
    "    pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "     # 只替换NaN值\n",
    "    df_nan = ratings.isnull()\n",
    "    pred = pd.DataFrame(pred).where(df_nan, ratings)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yiyang\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Yiyang\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "user_prediction = predict(data_model_train_matrix,dataset_similarity.fillna(0)).sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>...</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.00384615</td>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.00384615</td>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.00384615</td>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.00384615</td>\n",
       "      <td>0.409715</td>\n",
       "      <td>0.00384615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290521</td>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.290843</td>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.290715</td>\n",
       "      <td>0.29022</td>\n",
       "      <td>0.290245</td>\n",
       "      <td>0.00767754</td>\n",
       "      <td>0.290105</td>\n",
       "      <td>0.00767754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.349279</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.345978</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226785</td>\n",
       "      <td>0.226758</td>\n",
       "      <td>0.227111</td>\n",
       "      <td>0.227126</td>\n",
       "      <td>0.226981</td>\n",
       "      <td>0.226486</td>\n",
       "      <td>0.226516</td>\n",
       "      <td>0.226355</td>\n",
       "      <td>0.226372</td>\n",
       "      <td>0.227422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37037</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27845</td>\n",
       "      <td>0.278423</td>\n",
       "      <td>0.278774</td>\n",
       "      <td>0.278791</td>\n",
       "      <td>0.278644</td>\n",
       "      <td>0.278151</td>\n",
       "      <td>0.278179</td>\n",
       "      <td>0.278021</td>\n",
       "      <td>0.278036</td>\n",
       "      <td>0.279086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.168896</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0623717</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.0387466</td>\n",
       "      <td>0.039098</td>\n",
       "      <td>0.0391122</td>\n",
       "      <td>0.0389692</td>\n",
       "      <td>0.0384717</td>\n",
       "      <td>0.0385028</td>\n",
       "      <td>0.0383426</td>\n",
       "      <td>0.0383607</td>\n",
       "      <td>0.0394107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134568</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.0494415</td>\n",
       "      <td>0.049793</td>\n",
       "      <td>0.0498145</td>\n",
       "      <td>0.0496636</td>\n",
       "      <td>0.0491696</td>\n",
       "      <td>0.0491964</td>\n",
       "      <td>0.0490397</td>\n",
       "      <td>0.0490531</td>\n",
       "      <td>0.050104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.0168067</td>\n",
       "      <td>0.00338409</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.00338409</td>\n",
       "      <td>0.38918</td>\n",
       "      <td>0.296876</td>\n",
       "      <td>0.395822</td>\n",
       "      <td>0.00338409</td>\n",
       "      <td>0.392507</td>\n",
       "      <td>0.00338409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.273233</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.0234506</td>\n",
       "      <td>0.273895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.325385</td>\n",
       "      <td>0.0034904</td>\n",
       "      <td>0.0104348</td>\n",
       "      <td>0.0034904</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.0034904</td>\n",
       "      <td>0.362735</td>\n",
       "      <td>0.0034904</td>\n",
       "      <td>0.359363</td>\n",
       "      <td>0.0034904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.240213</td>\n",
       "      <td>0.240563</td>\n",
       "      <td>0.240577</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.239968</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.240873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.210219</td>\n",
       "      <td>0.00339559</td>\n",
       "      <td>0.412674</td>\n",
       "      <td>0.303164</td>\n",
       "      <td>0.39847</td>\n",
       "      <td>0.306227</td>\n",
       "      <td>0.0168919</td>\n",
       "      <td>0.302647</td>\n",
       "      <td>0.40175</td>\n",
       "      <td>0.30271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282658</td>\n",
       "      <td>0.0168919</td>\n",
       "      <td>0.0168919</td>\n",
       "      <td>0.283004</td>\n",
       "      <td>0.0168919</td>\n",
       "      <td>0.282363</td>\n",
       "      <td>0.282388</td>\n",
       "      <td>0.0135364</td>\n",
       "      <td>0.0135364</td>\n",
       "      <td>0.283293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.244541</td>\n",
       "      <td>0.232077</td>\n",
       "      <td>0.351939</td>\n",
       "      <td>0.242416</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>0.00347222</td>\n",
       "      <td>0.34438</td>\n",
       "      <td>0.00347222</td>\n",
       "      <td>0.341086</td>\n",
       "      <td>0.00347222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.0172414</td>\n",
       "      <td>0.0172414</td>\n",
       "      <td>0.222111</td>\n",
       "      <td>0.0172414</td>\n",
       "      <td>0.0138169</td>\n",
       "      <td>0.0138169</td>\n",
       "      <td>0.221501</td>\n",
       "      <td>0.0138169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.0608108</td>\n",
       "      <td>0.0069808</td>\n",
       "      <td>0.402327</td>\n",
       "      <td>0.0034965</td>\n",
       "      <td>0.0173611</td>\n",
       "      <td>0.0034965</td>\n",
       "      <td>0.0173611</td>\n",
       "      <td>0.0034965</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.0034965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272392</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.272735</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.010453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            289         290         291         292         293         294  \\\n",
       "0    0.00767754  0.00384615  0.00767754  0.00384615  0.00767754  0.00384615   \n",
       "1      0.266667    0.307692    0.307692    0.307692    0.307692    0.307692   \n",
       "2       0.37037    0.333333    0.714286    0.363636    0.714286    0.363636   \n",
       "3      0.434783    0.307692    0.168896    0.333333    0.666667   0.0623717   \n",
       "4      0.134568    0.444444    0.833333    0.444444    0.833333    0.444444   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "284   0.0168067  0.00338409    0.013468  0.00338409     0.38918    0.296876   \n",
       "285    0.325385   0.0034904   0.0104348   0.0034904    0.356164   0.0034904   \n",
       "286    0.210219  0.00339559    0.412674    0.303164     0.39847    0.306227   \n",
       "287    0.244541    0.232077    0.351939    0.242416    0.020654  0.00347222   \n",
       "288   0.0608108   0.0069808    0.402327   0.0034965   0.0173611   0.0034965   \n",
       "\n",
       "            295         296       297         298  ...        741         742  \\\n",
       "0    0.00767754  0.00384615  0.409715  0.00384615  ...   0.290521  0.00767754   \n",
       "1      0.349279    0.307692  0.345978    0.307692  ...   0.226785    0.226758   \n",
       "2      0.714286    0.363636  0.714286    0.363636  ...    0.27845    0.278423   \n",
       "3      0.666667    0.333333  0.666667    0.333333  ...   0.038773   0.0387466   \n",
       "4      0.833333    0.444444  0.833333    0.444444  ...   0.049469   0.0494415   \n",
       "..          ...         ...       ...         ...  ...        ...         ...   \n",
       "284    0.395822  0.00338409  0.392507  0.00338409  ...  0.0234506    0.273233   \n",
       "285    0.362735   0.0034904  0.359363   0.0034904  ...   0.017331    0.240213   \n",
       "286   0.0168919    0.302647   0.40175     0.30271  ...   0.282658   0.0168919   \n",
       "287     0.34438  0.00347222  0.341086  0.00347222  ...   0.024055    0.024055   \n",
       "288   0.0173611   0.0034965  0.013913   0.0034965  ...   0.272392    0.013913   \n",
       "\n",
       "           743         744        745        746        747         748  \\\n",
       "0     0.290843  0.00767754   0.290715    0.29022   0.290245  0.00767754   \n",
       "1     0.227111    0.227126   0.226981   0.226486   0.226516    0.226355   \n",
       "2     0.278774    0.278791   0.278644   0.278151   0.278179    0.278021   \n",
       "3     0.039098   0.0391122  0.0389692  0.0384717  0.0385028   0.0383426   \n",
       "4     0.049793   0.0498145  0.0496636  0.0491696  0.0491964   0.0490397   \n",
       "..         ...         ...        ...        ...        ...         ...   \n",
       "284  0.0234506   0.0234506  0.0234506  0.0234506  0.0234506   0.0234506   \n",
       "285   0.240563    0.240577   0.017331   0.017331   0.239968    0.017331   \n",
       "286  0.0168919    0.283004  0.0168919   0.282363   0.282388   0.0135364   \n",
       "287  0.0172414   0.0172414   0.222111  0.0172414  0.0138169   0.0138169   \n",
       "288   0.013913    0.272735   0.013913   0.013913   0.010453    0.010453   \n",
       "\n",
       "           749         750  \n",
       "0     0.290105  0.00767754  \n",
       "1     0.226372    0.227422  \n",
       "2     0.278036    0.279086  \n",
       "3    0.0383607   0.0394107  \n",
       "4    0.0490531    0.050104  \n",
       "..         ...         ...  \n",
       "284  0.0234506    0.273895  \n",
       "285   0.017331    0.240873  \n",
       "286  0.0135364    0.283293  \n",
       "287   0.221501   0.0138169  \n",
       "288   0.010453    0.010453  \n",
       "\n",
       "[289 rows x 462 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_ref = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593940258026123"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_ref - start_time_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = (data_model_test_matrix.fillna(0) != 0) & (user_prediction != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 只选择那些在预测评分和实际评分中都不是 0 的评分\n",
    "prediction = user_prediction[mask].values.flatten()\n",
    "prediction = pd.to_numeric(prediction, errors='coerce')\n",
    "prediction = prediction[~np.isnan(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "actual = data_model_test_matrix.fillna(0)[mask].values.flatten()\n",
    "actual = pd.to_numeric(actual, errors='coerce')\n",
    "actual = actual[~np.isnan(actual)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rmse(prediction, actual):\n",
    "    # 计算 RMSE\n",
    "    return sqrt(mean_squared_error(prediction, actual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_rmse = calculate_rmse(prediction, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34743774996815474"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ndcg(y_true, y_pred, k):\n",
    "    \"\"\"计算 NDCG @k\n",
    "    y_true: 真实的 relevancy 分数（通常为 0 或 1）\n",
    "    y_pred: 预测的 relevancy 分数\n",
    "    k: 截断位置\n",
    "    \"\"\"\n",
    "    # 计算 DCG @k\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    dcg = np.sum(gains / discounts)\n",
    "\n",
    "    # 计算 IDCG @k\n",
    "    ideal_order = np.argsort(y_true)[::-1]\n",
    "    ideal_gains = 2 ** np.take(y_true, ideal_order[:k]) - 1\n",
    "    ideal_discounts = np.log2(np.arange(len(ideal_gains)) + 2)\n",
    "    idcg = np.sum(ideal_gains / ideal_discounts)\n",
    "\n",
    "    # 防止0除问题\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "\n",
    "    # 计算 NDCG @k\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7311252676813786"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(actual, prediction,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
