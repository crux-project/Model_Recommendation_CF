{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import random\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings= pd.read_csv(\"./Data/ratings.csv\", low_memory=False)\n",
    "train_data = pd.read_csv(\"./Data/train_data.csv\",low_memory=False)\n",
    "test_data = pd.read_csv(\"./Data/test_data.csv\",low_memory=False)\n",
    "# train_data, test_data = train_test_split(ratings, test_size=0.3, random_state=42)\n",
    "# # 保存训练集为csv文件\n",
    "# train_data.to_csv('./Data/train_data.csv',index=False)\n",
    "# # 保存测试集为csv文件\n",
    "# test_data.to_csv('./Data/test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ratings.dataset_id.unique()\n",
    "models = ratings.model_id.unique()\n",
    "datasets_train = train_data.dataset_id.unique()\n",
    "model_train = train_data.model_id.unique()\n",
    "datasets_test = test_data.dataset_id.unique()\n",
    "model_test = test_data.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=model_train)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in train_data.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in test_data.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_func(ratings, user1, user2):\n",
    "    # 找到两个用户共同评分的物品，并将这些评分放入一个向量中\n",
    "    u1_ratings = ratings.loc[user1].dropna()\n",
    "    u2_ratings = ratings.loc[user2].dropna()\n",
    "\n",
    "    common_items = np.intersect1d(u1_ratings.index, u2_ratings.index).tolist()\n",
    "    u1_common_ratings = u1_ratings.loc[common_items]\n",
    "    u2_common_ratings = u2_ratings.loc[common_items]\n",
    "\n",
    "    # 计算两个向量之间的余弦相似度\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cos_sim = np.dot(u1_common_ratings, u2_common_ratings) / (np.linalg.norm(u1_common_ratings) * np.linalg.norm(u2_common_ratings))\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_bipartite_adjacency_matrix(rating_matrix):\n",
    "    n_users, n_items = rating_matrix.shape\n",
    "    adjacency_matrix = np.zeros((n_users + n_items, n_users + n_items))\n",
    "    adjacency_matrix[:n_users, n_users:] = rating_matrix\n",
    "    adjacency_matrix[n_users:, :n_users] = rating_matrix.T\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix(adjacency, lambda_):\n",
    "    n = adjacency.shape[0]\n",
    "    I = np.eye(n)\n",
    "    # 将 NaN 视为 0\n",
    "    adjacency = np.nan_to_num(adjacency)\n",
    "    try:\n",
    "        P = np.linalg.inv(I - lambda_ * adjacency)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"矩阵不可逆，无法计算传播矩阵\")\n",
    "        return None\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix_withWalkLength(adjacency_matrix, max_walk_length):\n",
    "    adjacency_matrix = np.nan_to_num(adjacency_matrix)\n",
    "    propagation_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "    sum_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "\n",
    "    for _ in range(max_walk_length):\n",
    "        propagation_matrix = propagation_matrix @ adjacency_matrix\n",
    "        sum_matrix += propagation_matrix\n",
    "\n",
    "    return sum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算二分图邻接矩阵\n",
    "bipartite_adjacency_matrix = create_bipartite_adjacency_matrix(data_model_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "propagation_maxLength = propagation_matrix_withWalkLength(bipartite_adjacency_matrix, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取用户-商品传播矩阵和商品-用户传播矩阵\n",
    "n_users = data_model_train_matrix.shape[0]\n",
    "user_item_propagation = propagation_maxLength[:n_users, n_users:]\n",
    "item_user_propagation = propagation_maxLength[n_users:, :n_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#计算 Random Walk Kernel\n",
    "random_walk_kernel = np.dot(user_item_propagation, item_user_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel_matrix):\n",
    "    # 计算矩阵的最小值和最大值\n",
    "    min_val = np.min(kernel_matrix)\n",
    "    max_val = np.max(kernel_matrix)\n",
    "\n",
    "    # 防止除数为零的情况\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(kernel_matrix)\n",
    "\n",
    "    # 将矩阵的值缩放到0和1之间\n",
    "    normalized_kernel_matrix = (kernel_matrix - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = normalize_kernel(random_walk_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = pd.DataFrame(normalized_kernel,index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        dataset_similarity.loc[i][j] = normalized_kernel.loc[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "          48        14        60        237       250       246       51   \\\n48   0.761661  0.668796   0.73842  0.084446  0.113163  0.089436  0.690884   \n14   0.668796  0.587112   0.64835   0.07304  0.098301  0.077428  0.606485   \n60    0.73842   0.64835   0.71588  0.081592  0.109445  0.086432  0.669783   \n237  0.084446   0.07304  0.081592  0.001275  0.004802  0.001888  0.075763   \n250  0.113163  0.098301  0.109445  0.004802  0.009397    0.0056  0.101852   \n..        ...       ...       ...       ...       ...       ...       ...   \n205  0.810462  0.711747  0.785749  0.090437  0.120967   0.09574  0.735115   \n71   0.705682  0.619568  0.684124  0.077569  0.104202  0.082195  0.639953   \n109  0.736847  0.646966  0.714355  0.081399  0.109193  0.086228  0.668356   \n59   0.656096  0.575945  0.636031  0.071479  0.096268  0.075785  0.594922   \n76   0.800161  0.702687  0.775759  0.089171  0.119318  0.094407  0.725747   \n\n          1         74        248  ...       50        149       85   \\\n48   0.566702   0.77077  0.097483  ...   0.84292  0.727789  0.808352   \n14   0.497292  0.676762  0.084507  ...  0.740221  0.639015  0.709889   \n60    0.54933  0.747264  0.094236  ...  0.817245  0.705565  0.783703   \n237  0.060502  0.085574  0.002876  ...  0.094437  0.080284  0.090178   \n250  0.081966  0.114634  0.006888  ...  0.126183  0.107739   0.12063   \n..        ...       ...       ...  ...       ...       ...       ...   \n205  0.603187  0.820051  0.104296  ...  0.896737  0.774482  0.860139   \n71   0.524866  0.714047  0.089659  ...  0.780944  0.674295  0.749018   \n109  0.548154  0.745674  0.094017  ...  0.815509  0.704061  0.782035   \n59   0.487801  0.663884  0.082732  ...   0.72615  0.626881   0.69643   \n76   0.595488  0.809617  0.102857  ...  0.885339  0.764637  0.849219   \n\n          128       229       205       71        109       59        76   \n48   0.811829  0.777317  0.810462  0.705682  0.736847  0.656096  0.800161  \n14   0.712872  0.682585  0.711747  0.619568  0.646966  0.575945  0.702687  \n60   0.787089  0.753602  0.785749  0.684124  0.714355  0.636031  0.775759  \n237  0.090618  0.086367  0.090437  0.077569  0.081399  0.071479  0.089171  \n250  0.121207  0.115664  0.120967  0.104202  0.109193  0.096268  0.119318  \n..        ...       ...       ...       ...       ...       ...       ...  \n205  0.863684  0.827139  0.862386  0.750978  0.784076  0.698254  0.851438  \n71   0.752111  0.720231  0.750978  0.653791  0.682664  0.607798  0.741428  \n109  0.785416  0.751997  0.784076  0.682664  0.712832  0.634673  0.774106  \n59   0.699313  0.669636  0.698254  0.607798  0.634673   0.56499  0.689366  \n76   0.852701  0.816633  0.851438  0.741428  0.774106  0.689366  0.840629  \n\n[289 rows x 289 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>48</th>\n      <th>14</th>\n      <th>60</th>\n      <th>237</th>\n      <th>250</th>\n      <th>246</th>\n      <th>51</th>\n      <th>1</th>\n      <th>74</th>\n      <th>248</th>\n      <th>...</th>\n      <th>50</th>\n      <th>149</th>\n      <th>85</th>\n      <th>128</th>\n      <th>229</th>\n      <th>205</th>\n      <th>71</th>\n      <th>109</th>\n      <th>59</th>\n      <th>76</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48</th>\n      <td>0.761661</td>\n      <td>0.668796</td>\n      <td>0.73842</td>\n      <td>0.084446</td>\n      <td>0.113163</td>\n      <td>0.089436</td>\n      <td>0.690884</td>\n      <td>0.566702</td>\n      <td>0.77077</td>\n      <td>0.097483</td>\n      <td>...</td>\n      <td>0.84292</td>\n      <td>0.727789</td>\n      <td>0.808352</td>\n      <td>0.811829</td>\n      <td>0.777317</td>\n      <td>0.810462</td>\n      <td>0.705682</td>\n      <td>0.736847</td>\n      <td>0.656096</td>\n      <td>0.800161</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.668796</td>\n      <td>0.587112</td>\n      <td>0.64835</td>\n      <td>0.07304</td>\n      <td>0.098301</td>\n      <td>0.077428</td>\n      <td>0.606485</td>\n      <td>0.497292</td>\n      <td>0.676762</td>\n      <td>0.084507</td>\n      <td>...</td>\n      <td>0.740221</td>\n      <td>0.639015</td>\n      <td>0.709889</td>\n      <td>0.712872</td>\n      <td>0.682585</td>\n      <td>0.711747</td>\n      <td>0.619568</td>\n      <td>0.646966</td>\n      <td>0.575945</td>\n      <td>0.702687</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>0.73842</td>\n      <td>0.64835</td>\n      <td>0.71588</td>\n      <td>0.081592</td>\n      <td>0.109445</td>\n      <td>0.086432</td>\n      <td>0.669783</td>\n      <td>0.54933</td>\n      <td>0.747264</td>\n      <td>0.094236</td>\n      <td>...</td>\n      <td>0.817245</td>\n      <td>0.705565</td>\n      <td>0.783703</td>\n      <td>0.787089</td>\n      <td>0.753602</td>\n      <td>0.785749</td>\n      <td>0.684124</td>\n      <td>0.714355</td>\n      <td>0.636031</td>\n      <td>0.775759</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>0.084446</td>\n      <td>0.07304</td>\n      <td>0.081592</td>\n      <td>0.001275</td>\n      <td>0.004802</td>\n      <td>0.001888</td>\n      <td>0.075763</td>\n      <td>0.060502</td>\n      <td>0.085574</td>\n      <td>0.002876</td>\n      <td>...</td>\n      <td>0.094437</td>\n      <td>0.080284</td>\n      <td>0.090178</td>\n      <td>0.090618</td>\n      <td>0.086367</td>\n      <td>0.090437</td>\n      <td>0.077569</td>\n      <td>0.081399</td>\n      <td>0.071479</td>\n      <td>0.089171</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>0.113163</td>\n      <td>0.098301</td>\n      <td>0.109445</td>\n      <td>0.004802</td>\n      <td>0.009397</td>\n      <td>0.0056</td>\n      <td>0.101852</td>\n      <td>0.081966</td>\n      <td>0.114634</td>\n      <td>0.006888</td>\n      <td>...</td>\n      <td>0.126183</td>\n      <td>0.107739</td>\n      <td>0.12063</td>\n      <td>0.121207</td>\n      <td>0.115664</td>\n      <td>0.120967</td>\n      <td>0.104202</td>\n      <td>0.109193</td>\n      <td>0.096268</td>\n      <td>0.119318</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>0.810462</td>\n      <td>0.711747</td>\n      <td>0.785749</td>\n      <td>0.090437</td>\n      <td>0.120967</td>\n      <td>0.09574</td>\n      <td>0.735115</td>\n      <td>0.603187</td>\n      <td>0.820051</td>\n      <td>0.104296</td>\n      <td>...</td>\n      <td>0.896737</td>\n      <td>0.774482</td>\n      <td>0.860139</td>\n      <td>0.863684</td>\n      <td>0.827139</td>\n      <td>0.862386</td>\n      <td>0.750978</td>\n      <td>0.784076</td>\n      <td>0.698254</td>\n      <td>0.851438</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.705682</td>\n      <td>0.619568</td>\n      <td>0.684124</td>\n      <td>0.077569</td>\n      <td>0.104202</td>\n      <td>0.082195</td>\n      <td>0.639953</td>\n      <td>0.524866</td>\n      <td>0.714047</td>\n      <td>0.089659</td>\n      <td>...</td>\n      <td>0.780944</td>\n      <td>0.674295</td>\n      <td>0.749018</td>\n      <td>0.752111</td>\n      <td>0.720231</td>\n      <td>0.750978</td>\n      <td>0.653791</td>\n      <td>0.682664</td>\n      <td>0.607798</td>\n      <td>0.741428</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>0.736847</td>\n      <td>0.646966</td>\n      <td>0.714355</td>\n      <td>0.081399</td>\n      <td>0.109193</td>\n      <td>0.086228</td>\n      <td>0.668356</td>\n      <td>0.548154</td>\n      <td>0.745674</td>\n      <td>0.094017</td>\n      <td>...</td>\n      <td>0.815509</td>\n      <td>0.704061</td>\n      <td>0.782035</td>\n      <td>0.785416</td>\n      <td>0.751997</td>\n      <td>0.784076</td>\n      <td>0.682664</td>\n      <td>0.712832</td>\n      <td>0.634673</td>\n      <td>0.774106</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>0.656096</td>\n      <td>0.575945</td>\n      <td>0.636031</td>\n      <td>0.071479</td>\n      <td>0.096268</td>\n      <td>0.075785</td>\n      <td>0.594922</td>\n      <td>0.487801</td>\n      <td>0.663884</td>\n      <td>0.082732</td>\n      <td>...</td>\n      <td>0.72615</td>\n      <td>0.626881</td>\n      <td>0.69643</td>\n      <td>0.699313</td>\n      <td>0.669636</td>\n      <td>0.698254</td>\n      <td>0.607798</td>\n      <td>0.634673</td>\n      <td>0.56499</td>\n      <td>0.689366</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.800161</td>\n      <td>0.702687</td>\n      <td>0.775759</td>\n      <td>0.089171</td>\n      <td>0.119318</td>\n      <td>0.094407</td>\n      <td>0.725747</td>\n      <td>0.595488</td>\n      <td>0.809617</td>\n      <td>0.102857</td>\n      <td>...</td>\n      <td>0.885339</td>\n      <td>0.764637</td>\n      <td>0.849219</td>\n      <td>0.852701</td>\n      <td>0.816633</td>\n      <td>0.851438</td>\n      <td>0.741428</td>\n      <td>0.774106</td>\n      <td>0.689366</td>\n      <td>0.840629</td>\n    </tr>\n  </tbody>\n</table>\n<p>289 rows × 289 columns</p>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.496531963348389"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_train - start_time_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_ref = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def predict(ratings, similarity):\n",
    "    mean_user_rating = ratings.fillna(0).mean(axis=1)\n",
    "    ratings_diff = (ratings - mean_user_rating[:, np.newaxis]).fillna(0)\n",
    "    pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "     # 只替换NaN值\n",
    "    df_nan = ratings.isnull()\n",
    "    pred = pd.DataFrame(pred).where(df_nan, ratings)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_prediction = predict(data_model_train_matrix,dataset_similarity).sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "          289       290       291       292       293       294       295  \\\n0    0.007678  0.003846  0.007678  0.003846  0.007678  0.003846  0.007678   \n1    0.266667  0.307692  0.307692  0.307692  0.307692  0.307692  0.354637   \n2     0.37037  0.333333  0.714286  0.363636  0.714286  0.363636  0.714286   \n3    0.434783  0.307692   0.41369  0.333333  0.666667  0.300144  0.666667   \n4    0.305741  0.444444  0.833333  0.444444  0.833333  0.444444  0.833333   \n..        ...       ...       ...       ...       ...       ...       ...   \n284  0.016807  0.003384  0.013468  0.003384  0.436275  0.300144  0.354637   \n285  0.305741   0.00349  0.010435   0.00349  0.436275   0.00349  0.354637   \n286  0.210219  0.003396   0.41369  0.304029  0.436275  0.300144  0.016892   \n287  0.244541  0.288618   0.41369  0.304029  0.020654  0.003472  0.354637   \n288  0.060811  0.006981   0.41369  0.003497  0.017361  0.003497  0.017361   \n\n          296       297       298  ...       741       742       743  \\\n0    0.003846  0.359447  0.003846  ...         0  0.007678         0   \n1    0.307692  0.359447  0.307692  ...         0         0         0   \n2    0.363636  0.714286  0.363636  ...         0         0         0   \n3    0.333333  0.666667  0.333333  ...         0         0         0   \n4    0.444444  0.833333  0.444444  ...         0         0         0   \n..        ...       ...       ...  ...       ...       ...       ...   \n284  0.003384  0.359447  0.003384  ...  0.023451         0  0.023451   \n285   0.00349  0.359447   0.00349  ...  0.017331         0         0   \n286  0.288288  0.359447  0.297619  ...         0  0.016892  0.016892   \n287  0.003472  0.359447  0.003472  ...  0.024055  0.024055  0.017241   \n288  0.003497  0.013913  0.003497  ...         0  0.013913  0.013913   \n\n          744       745       746       747       748       749       750  \n0    0.007678         0         0         0  0.007678         0  0.007678  \n1           0         0         0         0         0         0         0  \n2           0         0         0         0         0         0         0  \n3           0         0         0         0         0         0         0  \n4           0         0         0         0         0         0         0  \n..        ...       ...       ...       ...       ...       ...       ...  \n284  0.023451  0.023451  0.023451  0.023451  0.023451  0.023451         0  \n285         0  0.017331  0.017331         0  0.017331  0.017331         0  \n286         0  0.016892         0         0  0.013536  0.013536         0  \n287  0.017241         0  0.017241  0.013817  0.013817         0  0.013817  \n288         0  0.013913  0.013913  0.010453  0.010453  0.010453  0.010453  \n\n[289 rows x 462 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>289</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>...</th>\n      <th>741</th>\n      <th>742</th>\n      <th>743</th>\n      <th>744</th>\n      <th>745</th>\n      <th>746</th>\n      <th>747</th>\n      <th>748</th>\n      <th>749</th>\n      <th>750</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.007678</td>\n      <td>0.003846</td>\n      <td>0.007678</td>\n      <td>0.003846</td>\n      <td>0.007678</td>\n      <td>0.003846</td>\n      <td>0.007678</td>\n      <td>0.003846</td>\n      <td>0.359447</td>\n      <td>0.003846</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.007678</td>\n      <td>0</td>\n      <td>0.007678</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.007678</td>\n      <td>0</td>\n      <td>0.007678</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.266667</td>\n      <td>0.307692</td>\n      <td>0.307692</td>\n      <td>0.307692</td>\n      <td>0.307692</td>\n      <td>0.307692</td>\n      <td>0.354637</td>\n      <td>0.307692</td>\n      <td>0.359447</td>\n      <td>0.307692</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.37037</td>\n      <td>0.333333</td>\n      <td>0.714286</td>\n      <td>0.363636</td>\n      <td>0.714286</td>\n      <td>0.363636</td>\n      <td>0.714286</td>\n      <td>0.363636</td>\n      <td>0.714286</td>\n      <td>0.363636</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.434783</td>\n      <td>0.307692</td>\n      <td>0.41369</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.300144</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.305741</td>\n      <td>0.444444</td>\n      <td>0.833333</td>\n      <td>0.444444</td>\n      <td>0.833333</td>\n      <td>0.444444</td>\n      <td>0.833333</td>\n      <td>0.444444</td>\n      <td>0.833333</td>\n      <td>0.444444</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>0.016807</td>\n      <td>0.003384</td>\n      <td>0.013468</td>\n      <td>0.003384</td>\n      <td>0.436275</td>\n      <td>0.300144</td>\n      <td>0.354637</td>\n      <td>0.003384</td>\n      <td>0.359447</td>\n      <td>0.003384</td>\n      <td>...</td>\n      <td>0.023451</td>\n      <td>0</td>\n      <td>0.023451</td>\n      <td>0.023451</td>\n      <td>0.023451</td>\n      <td>0.023451</td>\n      <td>0.023451</td>\n      <td>0.023451</td>\n      <td>0.023451</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>0.305741</td>\n      <td>0.00349</td>\n      <td>0.010435</td>\n      <td>0.00349</td>\n      <td>0.436275</td>\n      <td>0.00349</td>\n      <td>0.354637</td>\n      <td>0.00349</td>\n      <td>0.359447</td>\n      <td>0.00349</td>\n      <td>...</td>\n      <td>0.017331</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.017331</td>\n      <td>0.017331</td>\n      <td>0</td>\n      <td>0.017331</td>\n      <td>0.017331</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>0.210219</td>\n      <td>0.003396</td>\n      <td>0.41369</td>\n      <td>0.304029</td>\n      <td>0.436275</td>\n      <td>0.300144</td>\n      <td>0.016892</td>\n      <td>0.288288</td>\n      <td>0.359447</td>\n      <td>0.297619</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.016892</td>\n      <td>0.016892</td>\n      <td>0</td>\n      <td>0.016892</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.013536</td>\n      <td>0.013536</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>0.244541</td>\n      <td>0.288618</td>\n      <td>0.41369</td>\n      <td>0.304029</td>\n      <td>0.020654</td>\n      <td>0.003472</td>\n      <td>0.354637</td>\n      <td>0.003472</td>\n      <td>0.359447</td>\n      <td>0.003472</td>\n      <td>...</td>\n      <td>0.024055</td>\n      <td>0.024055</td>\n      <td>0.017241</td>\n      <td>0.017241</td>\n      <td>0</td>\n      <td>0.017241</td>\n      <td>0.013817</td>\n      <td>0.013817</td>\n      <td>0</td>\n      <td>0.013817</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>0.060811</td>\n      <td>0.006981</td>\n      <td>0.41369</td>\n      <td>0.003497</td>\n      <td>0.017361</td>\n      <td>0.003497</td>\n      <td>0.017361</td>\n      <td>0.003497</td>\n      <td>0.013913</td>\n      <td>0.003497</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.013913</td>\n      <td>0.013913</td>\n      <td>0</td>\n      <td>0.013913</td>\n      <td>0.013913</td>\n      <td>0.010453</td>\n      <td>0.010453</td>\n      <td>0.010453</td>\n      <td>0.010453</td>\n    </tr>\n  </tbody>\n</table>\n<p>289 rows × 462 columns</p>\n</div>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_ref = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "43.03105163574219"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_ref - start_time_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = (data_model_test_matrix.fillna(0) != 0) & (user_prediction != 0)\n",
    "\n",
    "# 只选择那些在预测评分和实际评分中都不是 0 的评分\n",
    "prediction = user_prediction[mask].values.flatten()\n",
    "prediction = pd.to_numeric(prediction, errors='coerce')\n",
    "prediction = prediction[~np.isnan(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "actual = data_model_test_matrix.fillna(0)[mask].values.flatten()\n",
    "actual = pd.to_numeric(actual, errors='coerce')\n",
    "actual = actual[~np.isnan(actual)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rmse(prediction, actual):\n",
    "    # 计算 RMSE\n",
    "    return sqrt(mean_squared_error(prediction, actual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_rmse = calculate_rmse(prediction, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.4155274420318513"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ndcg(y_true, y_pred, k):\n",
    "    \"\"\"计算 NDCG @k\n",
    "    y_true: 真实的 relevancy 分数（通常为 0 或 1）\n",
    "    y_pred: 预测的 relevancy 分数\n",
    "    k: 截断位置\n",
    "    \"\"\"\n",
    "    # 计算 DCG @k\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    dcg = np.sum(gains / discounts)\n",
    "\n",
    "    # 计算 IDCG @k\n",
    "    ideal_order = np.argsort(y_true)[::-1]\n",
    "    ideal_gains = 2 ** np.take(y_true, ideal_order[:k]) - 1\n",
    "    ideal_discounts = np.log2(np.arange(len(ideal_gains)) + 2)\n",
    "    idcg = np.sum(ideal_gains / ideal_discounts)\n",
    "\n",
    "    # 防止0除问题\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "\n",
    "    # 计算 NDCG @k\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.5618638692322778"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(actual, prediction, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}