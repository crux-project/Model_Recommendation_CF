{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import random\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings= pd.read_csv(\"./Data/rating.csv\", low_memory=False)\n",
    "train_data = pd.read_csv(\"./Data/train_data.csv\",low_memory=False)\n",
    "test_data = pd.read_csv(\"./Data/test_data.csv\",low_memory=False)\n",
    "# train_data, test_data = train_test_split(ratings, test_size=0.3, random_state=42)\n",
    "# # 保存训练集为csv文件\n",
    "# train_data.to_csv('./Data/train_data.csv',index=False)\n",
    "# # 保存测试集为csv文件\n",
    "# test_data.to_csv('./Data/test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ratings.dataset_id.unique()\n",
    "models = ratings.model_id.unique()\n",
    "datasets_train = train_data.dataset_id.unique()\n",
    "model_train = train_data.model_id.unique()\n",
    "datasets_test = test_data.dataset_id.unique()\n",
    "model_test = test_data.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=model_train)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in train_data.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in test_data.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_graph_from_df(df):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for user in df.index:\n",
    "        for item in df.columns:\n",
    "            rating = df.loc[user, item]\n",
    "            if not np.isnan(rating):\n",
    "                G.add_edge(user, item, weight=rating)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def deepwalk(G, walk_length=6, num_walks=1, embed_size=32):\n",
    "    walks = []\n",
    "    for node in G.nodes():\n",
    "        if G.degree(node) == 0:\n",
    "            continue\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]\n",
    "                cur_nbrs = list(G.neighbors(cur))\n",
    "                walk.append(np.random.choice(cur_nbrs))\n",
    "            walks.append([str(node) for node in walk])\n",
    "    model = Word2Vec(walks, vector_size=embed_size, window=5, min_count=0, sg=1, workers=4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weighted_walks(G, walk_length=10, num_walks=1,embed_size=32):\n",
    "    walks = []\n",
    "    nodes = list(G.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        np.random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walk = [node]\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if neighbors:\n",
    "                    # 下一步的概率与边的权重成比例\n",
    "                    weights = [G[cur][neighbor]['weight'] for neighbor in neighbors]\n",
    "                    probabilities = weights / np.sum(weights)\n",
    "                    next_node = np.random.choice(neighbors, p=probabilities)\n",
    "                    walk.append(next_node)\n",
    "                else:\n",
    "                    break\n",
    "            walks.append([str(node) for node in walk])\n",
    "    model = Word2Vec(walks, vector_size=embed_size, window=5, min_count=0, sg=1, workers=4)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_similarity_matrix(model, user_nodes):\n",
    "    embeddings = np.array([model.wv.get_vector(str(user)) for user in user_nodes])\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    return pd.DataFrame(similarity_matrix, index=user_nodes, columns=user_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 创建图\n",
    "G = create_graph_from_df(data_model_train_matrix)\n",
    "\n",
    "# 执行DeepWalk算法\n",
    "model = generate_weighted_walks(G)\n",
    "\n",
    "# 获取用户相似性矩阵\n",
    "user_nodes = data_model_train_matrix.index.tolist()\n",
    "similarity_matrix = get_similarity_matrix(model, user_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39</th>\n",
       "      <th>7</th>\n",
       "      <th>21</th>\n",
       "      <th>48</th>\n",
       "      <th>12</th>\n",
       "      <th>52</th>\n",
       "      <th>22</th>\n",
       "      <th>51</th>\n",
       "      <th>64</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>40</th>\n",
       "      <th>63</th>\n",
       "      <th>44</th>\n",
       "      <th>57</th>\n",
       "      <th>53</th>\n",
       "      <th>58</th>\n",
       "      <th>60</th>\n",
       "      <th>59</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575757</td>\n",
       "      <td>0.342748</td>\n",
       "      <td>0.415777</td>\n",
       "      <td>0.585654</td>\n",
       "      <td>0.343730</td>\n",
       "      <td>0.451688</td>\n",
       "      <td>0.588606</td>\n",
       "      <td>0.290335</td>\n",
       "      <td>0.599234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349655</td>\n",
       "      <td>0.322706</td>\n",
       "      <td>0.992548</td>\n",
       "      <td>0.307688</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.295017</td>\n",
       "      <td>0.329401</td>\n",
       "      <td>0.418620</td>\n",
       "      <td>0.302627</td>\n",
       "      <td>0.344329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510261</td>\n",
       "      <td>0.507396</td>\n",
       "      <td>0.997298</td>\n",
       "      <td>0.510364</td>\n",
       "      <td>0.499789</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.436113</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581077</td>\n",
       "      <td>0.475505</td>\n",
       "      <td>0.555854</td>\n",
       "      <td>0.507940</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.436628</td>\n",
       "      <td>0.534906</td>\n",
       "      <td>0.464647</td>\n",
       "      <td>0.439537</td>\n",
       "      <td>0.501742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.342748</td>\n",
       "      <td>0.510261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377827</td>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.997410</td>\n",
       "      <td>0.534858</td>\n",
       "      <td>0.535419</td>\n",
       "      <td>0.499209</td>\n",
       "      <td>0.519995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603365</td>\n",
       "      <td>0.540124</td>\n",
       "      <td>0.286549</td>\n",
       "      <td>0.434530</td>\n",
       "      <td>0.327520</td>\n",
       "      <td>0.504616</td>\n",
       "      <td>0.460865</td>\n",
       "      <td>0.386395</td>\n",
       "      <td>0.504764</td>\n",
       "      <td>0.996818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.415777</td>\n",
       "      <td>0.507396</td>\n",
       "      <td>0.377827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496650</td>\n",
       "      <td>0.373316</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.528242</td>\n",
       "      <td>0.323336</td>\n",
       "      <td>0.519866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536524</td>\n",
       "      <td>0.376584</td>\n",
       "      <td>0.412346</td>\n",
       "      <td>0.427901</td>\n",
       "      <td>0.397013</td>\n",
       "      <td>0.329035</td>\n",
       "      <td>0.459331</td>\n",
       "      <td>0.363023</td>\n",
       "      <td>0.311735</td>\n",
       "      <td>0.362134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.585654</td>\n",
       "      <td>0.997298</td>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.496650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497914</td>\n",
       "      <td>0.510867</td>\n",
       "      <td>0.994787</td>\n",
       "      <td>0.437246</td>\n",
       "      <td>0.995579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564882</td>\n",
       "      <td>0.476720</td>\n",
       "      <td>0.566346</td>\n",
       "      <td>0.498663</td>\n",
       "      <td>0.567517</td>\n",
       "      <td>0.438321</td>\n",
       "      <td>0.525469</td>\n",
       "      <td>0.464871</td>\n",
       "      <td>0.440838</td>\n",
       "      <td>0.489411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.295017</td>\n",
       "      <td>0.436628</td>\n",
       "      <td>0.504616</td>\n",
       "      <td>0.329035</td>\n",
       "      <td>0.438321</td>\n",
       "      <td>0.492106</td>\n",
       "      <td>0.511953</td>\n",
       "      <td>0.464935</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.455139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423080</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.253224</td>\n",
       "      <td>0.456673</td>\n",
       "      <td>0.253188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469657</td>\n",
       "      <td>0.500018</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>0.476158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.329401</td>\n",
       "      <td>0.534906</td>\n",
       "      <td>0.460865</td>\n",
       "      <td>0.459331</td>\n",
       "      <td>0.525469</td>\n",
       "      <td>0.444948</td>\n",
       "      <td>0.382076</td>\n",
       "      <td>0.557533</td>\n",
       "      <td>0.472558</td>\n",
       "      <td>0.533957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539222</td>\n",
       "      <td>0.507945</td>\n",
       "      <td>0.271636</td>\n",
       "      <td>0.996607</td>\n",
       "      <td>0.297466</td>\n",
       "      <td>0.469657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359691</td>\n",
       "      <td>0.461289</td>\n",
       "      <td>0.445004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.418620</td>\n",
       "      <td>0.464647</td>\n",
       "      <td>0.386395</td>\n",
       "      <td>0.363023</td>\n",
       "      <td>0.464871</td>\n",
       "      <td>0.383565</td>\n",
       "      <td>0.485193</td>\n",
       "      <td>0.494883</td>\n",
       "      <td>0.498672</td>\n",
       "      <td>0.485615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459333</td>\n",
       "      <td>0.521264</td>\n",
       "      <td>0.406533</td>\n",
       "      <td>0.315015</td>\n",
       "      <td>0.378978</td>\n",
       "      <td>0.500018</td>\n",
       "      <td>0.359691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509483</td>\n",
       "      <td>0.366982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.302627</td>\n",
       "      <td>0.439537</td>\n",
       "      <td>0.504764</td>\n",
       "      <td>0.311735</td>\n",
       "      <td>0.440838</td>\n",
       "      <td>0.491974</td>\n",
       "      <td>0.500462</td>\n",
       "      <td>0.467600</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>0.458050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421742</td>\n",
       "      <td>0.994340</td>\n",
       "      <td>0.262156</td>\n",
       "      <td>0.448970</td>\n",
       "      <td>0.260784</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>0.461289</td>\n",
       "      <td>0.509483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.344329</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>0.996818</td>\n",
       "      <td>0.362134</td>\n",
       "      <td>0.489411</td>\n",
       "      <td>0.997852</td>\n",
       "      <td>0.504101</td>\n",
       "      <td>0.523479</td>\n",
       "      <td>0.470235</td>\n",
       "      <td>0.511621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588207</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.287488</td>\n",
       "      <td>0.420355</td>\n",
       "      <td>0.330363</td>\n",
       "      <td>0.476158</td>\n",
       "      <td>0.445004</td>\n",
       "      <td>0.366982</td>\n",
       "      <td>0.477365</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          39        7         21        48        12        52        22  \\\n",
       "39  1.000000  0.575757  0.342748  0.415777  0.585654  0.343730  0.451688   \n",
       "7   0.575757  1.000000  0.510261  0.507396  0.997298  0.510364  0.499789   \n",
       "21  0.342748  0.510261  1.000000  0.377827  0.499698  0.997410  0.534858   \n",
       "48  0.415777  0.507396  0.377827  1.000000  0.496650  0.373316  0.376800   \n",
       "12  0.585654  0.997298  0.499698  0.496650  1.000000  0.497914  0.510867   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "53  0.295017  0.436628  0.504616  0.329035  0.438321  0.492106  0.511953   \n",
       "58  0.329401  0.534906  0.460865  0.459331  0.525469  0.444948  0.382076   \n",
       "60  0.418620  0.464647  0.386395  0.363023  0.464871  0.383565  0.485193   \n",
       "59  0.302627  0.439537  0.504764  0.311735  0.440838  0.491974  0.500462   \n",
       "17  0.344329  0.501742  0.996818  0.362134  0.489411  0.997852  0.504101   \n",
       "\n",
       "          51        64        1   ...        8         40        63        44  \\\n",
       "39  0.588606  0.290335  0.599234  ...  0.349655  0.322706  0.992548  0.307688   \n",
       "7   0.994664  0.436113  0.996022  ...  0.581077  0.475505  0.555854  0.507940   \n",
       "21  0.535419  0.499209  0.519995  ...  0.603365  0.540124  0.286549  0.434530   \n",
       "48  0.528242  0.323336  0.519866  ...  0.536524  0.376584  0.412346  0.427901   \n",
       "12  0.994787  0.437246  0.995579  ...  0.564882  0.476720  0.566346  0.498663   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "53  0.464935  0.995816  0.455139  ...  0.423080  0.995851  0.253224  0.456673   \n",
       "58  0.557533  0.472558  0.533957  ...  0.539222  0.507945  0.271636  0.996607   \n",
       "60  0.494883  0.498672  0.485615  ...  0.459333  0.521264  0.406533  0.315015   \n",
       "59  0.467600  0.998219  0.458050  ...  0.421742  0.994340  0.262156  0.448970   \n",
       "17  0.523479  0.470235  0.511621  ...  0.588207  0.511905  0.287488  0.420355   \n",
       "\n",
       "          57        53        58        60        59        17  \n",
       "39  0.988845  0.295017  0.329401  0.418620  0.302627  0.344329  \n",
       "7   0.558419  0.436628  0.534906  0.464647  0.439537  0.501742  \n",
       "21  0.327520  0.504616  0.460865  0.386395  0.504764  0.996818  \n",
       "48  0.397013  0.329035  0.459331  0.363023  0.311735  0.362134  \n",
       "12  0.567517  0.438321  0.525469  0.464871  0.440838  0.489411  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "53  0.253188  1.000000  0.469657  0.500018  0.996008  0.476158  \n",
       "58  0.297466  0.469657  1.000000  0.359691  0.461289  0.445004  \n",
       "60  0.378978  0.500018  0.359691  1.000000  0.509483  0.366982  \n",
       "59  0.260784  0.996008  0.461289  0.509483  1.000000  0.477365  \n",
       "17  0.330363  0.476158  0.445004  0.366982  0.477365  1.000000  \n",
       "\n",
       "[72 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train).sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        if similarity_matrix.loc[i][j] > 0:\n",
    "            dataset_similarity.loc[i][j] = similarity_matrix.loc[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.478487</td>\n",
       "      <td>0.413325</td>\n",
       "      <td>0.47226</td>\n",
       "      <td>0.35455</td>\n",
       "      <td>0.57125</td>\n",
       "      <td>0.36967</td>\n",
       "      <td>0.483763</td>\n",
       "      <td>0.441031</td>\n",
       "      <td>0.507267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518065</td>\n",
       "      <td>0.470783</td>\n",
       "      <td>0.426622</td>\n",
       "      <td>0.250832</td>\n",
       "      <td>0.486941</td>\n",
       "      <td>0.366863</td>\n",
       "      <td>0.996846</td>\n",
       "      <td>0.494386</td>\n",
       "      <td>0.388155</td>\n",
       "      <td>0.504565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.478487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.514487</td>\n",
       "      <td>0.470384</td>\n",
       "      <td>0.531416</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.58578</td>\n",
       "      <td>0.996424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996131</td>\n",
       "      <td>0.57793</td>\n",
       "      <td>0.455118</td>\n",
       "      <td>0.550646</td>\n",
       "      <td>0.549448</td>\n",
       "      <td>0.532851</td>\n",
       "      <td>0.50967</td>\n",
       "      <td>0.997526</td>\n",
       "      <td>0.32652</td>\n",
       "      <td>0.533363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413325</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381668</td>\n",
       "      <td>0.505063</td>\n",
       "      <td>0.439722</td>\n",
       "      <td>0.378829</td>\n",
       "      <td>0.549238</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>0.573508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572155</td>\n",
       "      <td>0.280352</td>\n",
       "      <td>0.41223</td>\n",
       "      <td>0.473987</td>\n",
       "      <td>0.371235</td>\n",
       "      <td>0.365636</td>\n",
       "      <td>0.430439</td>\n",
       "      <td>0.552685</td>\n",
       "      <td>0.362104</td>\n",
       "      <td>0.430641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.47226</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.381668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541687</td>\n",
       "      <td>0.535075</td>\n",
       "      <td>0.530818</td>\n",
       "      <td>0.513383</td>\n",
       "      <td>0.443024</td>\n",
       "      <td>0.543571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526048</td>\n",
       "      <td>0.408557</td>\n",
       "      <td>0.422296</td>\n",
       "      <td>0.242159</td>\n",
       "      <td>0.30894</td>\n",
       "      <td>0.530057</td>\n",
       "      <td>0.490134</td>\n",
       "      <td>0.522133</td>\n",
       "      <td>0.581237</td>\n",
       "      <td>0.993826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.35455</td>\n",
       "      <td>0.514487</td>\n",
       "      <td>0.505063</td>\n",
       "      <td>0.541687</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376235</td>\n",
       "      <td>0.378355</td>\n",
       "      <td>0.501935</td>\n",
       "      <td>0.548092</td>\n",
       "      <td>0.523417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522477</td>\n",
       "      <td>0.410693</td>\n",
       "      <td>0.322906</td>\n",
       "      <td>0.45491</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.368052</td>\n",
       "      <td>0.382142</td>\n",
       "      <td>0.525324</td>\n",
       "      <td>0.494494</td>\n",
       "      <td>0.597875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.366863</td>\n",
       "      <td>0.532851</td>\n",
       "      <td>0.365636</td>\n",
       "      <td>0.530057</td>\n",
       "      <td>0.368052</td>\n",
       "      <td>0.562792</td>\n",
       "      <td>0.997132</td>\n",
       "      <td>0.502211</td>\n",
       "      <td>0.418872</td>\n",
       "      <td>0.549299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536688</td>\n",
       "      <td>0.441422</td>\n",
       "      <td>0.508494</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.640648</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392618</td>\n",
       "      <td>0.532037</td>\n",
       "      <td>0.539253</td>\n",
       "      <td>0.548255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.996846</td>\n",
       "      <td>0.50967</td>\n",
       "      <td>0.430439</td>\n",
       "      <td>0.490134</td>\n",
       "      <td>0.382142</td>\n",
       "      <td>0.599259</td>\n",
       "      <td>0.396158</td>\n",
       "      <td>0.515125</td>\n",
       "      <td>0.460397</td>\n",
       "      <td>0.53956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.492457</td>\n",
       "      <td>0.449006</td>\n",
       "      <td>0.26566</td>\n",
       "      <td>0.503971</td>\n",
       "      <td>0.392618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525382</td>\n",
       "      <td>0.409217</td>\n",
       "      <td>0.523284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.494386</td>\n",
       "      <td>0.997526</td>\n",
       "      <td>0.552685</td>\n",
       "      <td>0.522133</td>\n",
       "      <td>0.525324</td>\n",
       "      <td>0.483907</td>\n",
       "      <td>0.530824</td>\n",
       "      <td>0.997132</td>\n",
       "      <td>0.585464</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99715</td>\n",
       "      <td>0.56924</td>\n",
       "      <td>0.459644</td>\n",
       "      <td>0.531396</td>\n",
       "      <td>0.543734</td>\n",
       "      <td>0.532037</td>\n",
       "      <td>0.525382</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32546</td>\n",
       "      <td>0.548897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.388155</td>\n",
       "      <td>0.32652</td>\n",
       "      <td>0.362104</td>\n",
       "      <td>0.581237</td>\n",
       "      <td>0.494494</td>\n",
       "      <td>0.562573</td>\n",
       "      <td>0.547389</td>\n",
       "      <td>0.296499</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.350194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349191</td>\n",
       "      <td>0.528034</td>\n",
       "      <td>0.528816</td>\n",
       "      <td>0.384713</td>\n",
       "      <td>0.390574</td>\n",
       "      <td>0.539253</td>\n",
       "      <td>0.409217</td>\n",
       "      <td>0.32546</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.504565</td>\n",
       "      <td>0.533363</td>\n",
       "      <td>0.430641</td>\n",
       "      <td>0.993826</td>\n",
       "      <td>0.597875</td>\n",
       "      <td>0.561773</td>\n",
       "      <td>0.548761</td>\n",
       "      <td>0.537151</td>\n",
       "      <td>0.491466</td>\n",
       "      <td>0.570169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553623</td>\n",
       "      <td>0.426473</td>\n",
       "      <td>0.459292</td>\n",
       "      <td>0.28225</td>\n",
       "      <td>0.362503</td>\n",
       "      <td>0.548255</td>\n",
       "      <td>0.523284</td>\n",
       "      <td>0.548897</td>\n",
       "      <td>0.607244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0          1  0.478487  0.413325   0.47226   0.35455   0.57125   0.36967   \n",
       "1   0.478487         1  0.553336  0.506456  0.514487  0.470384  0.531416   \n",
       "2   0.413325  0.553336         1  0.381668  0.505063  0.439722  0.378829   \n",
       "3    0.47226  0.506456  0.381668         1  0.541687  0.535075  0.530818   \n",
       "4    0.35455  0.514487  0.505063  0.541687         1  0.376235  0.378355   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "67  0.366863  0.532851  0.365636  0.530057  0.368052  0.562792  0.997132   \n",
       "68  0.996846   0.50967  0.430439  0.490134  0.382142  0.599259  0.396158   \n",
       "69  0.494386  0.997526  0.552685  0.522133  0.525324  0.483907  0.530824   \n",
       "70  0.388155   0.32652  0.362104  0.581237  0.494494  0.562573  0.547389   \n",
       "71  0.504565  0.533363  0.430641  0.993826  0.597875  0.561773  0.548761   \n",
       "\n",
       "          7         8         9   ...        62        63        64        65  \\\n",
       "0   0.483763  0.441031  0.507267  ...  0.518065  0.470783  0.426622  0.250832   \n",
       "1   0.996022   0.58578  0.996424  ...  0.996131   0.57793  0.455118  0.550646   \n",
       "2   0.549238  0.994567  0.573508  ...  0.572155  0.280352   0.41223  0.473987   \n",
       "3   0.513383  0.443024  0.543571  ...  0.526048  0.408557  0.422296  0.242159   \n",
       "4   0.501935  0.548092  0.523417  ...  0.522477  0.410693  0.322906   0.45491   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "67  0.502211  0.418872  0.549299  ...  0.536688  0.441422  0.508494  0.493007   \n",
       "68  0.515125  0.460397   0.53956  ...  0.550059  0.492457  0.449006   0.26566   \n",
       "69  0.997132  0.585464  0.996845  ...   0.99715   0.56924  0.459644  0.531396   \n",
       "70  0.296499  0.397985  0.350194  ...  0.349191  0.528034  0.528816  0.384713   \n",
       "71  0.537151  0.491466  0.570169  ...  0.553623  0.426473  0.459292   0.28225   \n",
       "\n",
       "          66        67        68        69        70        71  \n",
       "0   0.486941  0.366863  0.996846  0.494386  0.388155  0.504565  \n",
       "1   0.549448  0.532851   0.50967  0.997526   0.32652  0.533363  \n",
       "2   0.371235  0.365636  0.430439  0.552685  0.362104  0.430641  \n",
       "3    0.30894  0.530057  0.490134  0.522133  0.581237  0.993826  \n",
       "4     0.4618  0.368052  0.382142  0.525324  0.494494  0.597875  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "67  0.640648         1  0.392618  0.532037  0.539253  0.548255  \n",
       "68  0.503971  0.392618         1  0.525382  0.409217  0.523284  \n",
       "69  0.543734  0.532037  0.525382         1   0.32546  0.548897  \n",
       "70  0.390574  0.539253  0.409217   0.32546         1  0.607244  \n",
       "71  0.362503  0.548255  0.523284  0.548897  0.607244         1  \n",
       "\n",
       "[72 rows x 72 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def positive_similarity_ratio(similarity_matrix):\n",
    "    # Count the number of positive similarities\n",
    "    num_positive_similarities = (similarity_matrix > 0).sum().sum()\n",
    "\n",
    "    # Count the total number of similarities\n",
    "    total_similarities = similarity_matrix.size\n",
    "\n",
    "    # Compute the ratio of positive similarities\n",
    "    ratio = num_positive_similarities / total_similarities\n",
    "\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_similarity_ratio(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05717921257019043"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_train - start_time_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_ref = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def predict(ratings, similarity):\n",
    "    mean_user_rating = ratings.fillna(0).mean(axis=1)\n",
    "    ratings_diff = (ratings - mean_user_rating[:, np.newaxis]).fillna(0)\n",
    "    pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "     # 只替换NaN值\n",
    "    df_nan = ratings.isnull()\n",
    "    pred = pd.DataFrame(pred).where(df_nan, ratings)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yiyang\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Yiyang\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "user_prediction = predict(data_model_train_matrix,dataset_similarity.fillna(0)).sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>...</th>\n",
       "      <th>1862</th>\n",
       "      <th>1863</th>\n",
       "      <th>1864</th>\n",
       "      <th>1865</th>\n",
       "      <th>1866</th>\n",
       "      <th>1867</th>\n",
       "      <th>1868</th>\n",
       "      <th>1869</th>\n",
       "      <th>1870</th>\n",
       "      <th>1871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0188494</td>\n",
       "      <td>0.958961</td>\n",
       "      <td>0.958403</td>\n",
       "      <td>0.0497574</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.997487</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.0320443</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0143107</td>\n",
       "      <td>0.0184219</td>\n",
       "      <td>0.0189132</td>\n",
       "      <td>0.0160616</td>\n",
       "      <td>0.0131706</td>\n",
       "      <td>0.0218312</td>\n",
       "      <td>0.0164532</td>\n",
       "      <td>0.0241106</td>\n",
       "      <td>0.00969823</td>\n",
       "      <td>0.018713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0563963</td>\n",
       "      <td>0.0751751</td>\n",
       "      <td>0.0739159</td>\n",
       "      <td>0.0681205</td>\n",
       "      <td>0.0825219</td>\n",
       "      <td>0.0806837</td>\n",
       "      <td>0.0805824</td>\n",
       "      <td>0.0714793</td>\n",
       "      <td>0.0615975</td>\n",
       "      <td>0.0789845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0572268</td>\n",
       "      <td>0.0605315</td>\n",
       "      <td>0.0609964</td>\n",
       "      <td>0.0586555</td>\n",
       "      <td>0.0563958</td>\n",
       "      <td>0.0633989</td>\n",
       "      <td>0.0589624</td>\n",
       "      <td>0.0654226</td>\n",
       "      <td>0.0535545</td>\n",
       "      <td>0.0607896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0230081</td>\n",
       "      <td>0.0423262</td>\n",
       "      <td>0.0410591</td>\n",
       "      <td>0.035219</td>\n",
       "      <td>0.0499109</td>\n",
       "      <td>0.047973</td>\n",
       "      <td>0.0478795</td>\n",
       "      <td>0.0386229</td>\n",
       "      <td>0.0284832</td>\n",
       "      <td>0.0463665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0234469</td>\n",
       "      <td>0.0265246</td>\n",
       "      <td>0.0269715</td>\n",
       "      <td>0.0247095</td>\n",
       "      <td>0.0227122</td>\n",
       "      <td>0.0292283</td>\n",
       "      <td>0.0250326</td>\n",
       "      <td>0.0311304</td>\n",
       "      <td>0.0199767</td>\n",
       "      <td>0.0267342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0414652</td>\n",
       "      <td>0.0618619</td>\n",
       "      <td>0.0605051</td>\n",
       "      <td>0.0544413</td>\n",
       "      <td>0.0698977</td>\n",
       "      <td>0.0678662</td>\n",
       "      <td>0.0677733</td>\n",
       "      <td>0.0578779</td>\n",
       "      <td>0.0471929</td>\n",
       "      <td>0.0661879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0753692</td>\n",
       "      <td>0.173029</td>\n",
       "      <td>0.0566432</td>\n",
       "      <td>0.234606</td>\n",
       "      <td>0.0462954</td>\n",
       "      <td>0.173447</td>\n",
       "      <td>0.142658</td>\n",
       "      <td>0.145166</td>\n",
       "      <td>0.146002</td>\n",
       "      <td>0.230705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0657271</td>\n",
       "      <td>0.0820723</td>\n",
       "      <td>0.0809763</td>\n",
       "      <td>0.0761542</td>\n",
       "      <td>0.0885626</td>\n",
       "      <td>0.0869143</td>\n",
       "      <td>0.0868295</td>\n",
       "      <td>0.0788542</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.0854856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0687899</td>\n",
       "      <td>0.0731391</td>\n",
       "      <td>0.0737061</td>\n",
       "      <td>0.0705746</td>\n",
       "      <td>0.0676345</td>\n",
       "      <td>0.0768271</td>\n",
       "      <td>0.0710372</td>\n",
       "      <td>0.0793469</td>\n",
       "      <td>0.0638541</td>\n",
       "      <td>0.0734245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0191199</td>\n",
       "      <td>0.0346809</td>\n",
       "      <td>0.0336589</td>\n",
       "      <td>0.028947</td>\n",
       "      <td>0.0408145</td>\n",
       "      <td>0.039238</td>\n",
       "      <td>0.0391542</td>\n",
       "      <td>0.0316988</td>\n",
       "      <td>0.0235867</td>\n",
       "      <td>0.0378813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0215156</td>\n",
       "      <td>0.0253054</td>\n",
       "      <td>0.025748</td>\n",
       "      <td>0.0230838</td>\n",
       "      <td>0.0204795</td>\n",
       "      <td>0.0284878</td>\n",
       "      <td>0.0235023</td>\n",
       "      <td>0.0307394</td>\n",
       "      <td>0.017247</td>\n",
       "      <td>0.0255376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.376876</td>\n",
       "      <td>0.382171</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>0.0568032</td>\n",
       "      <td>0.347749</td>\n",
       "      <td>0.379523</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.311121</td>\n",
       "      <td>0.337158</td>\n",
       "      <td>0.0842323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232132</td>\n",
       "      <td>0.0272641</td>\n",
       "      <td>0.0277528</td>\n",
       "      <td>0.0249453</td>\n",
       "      <td>0.0221029</td>\n",
       "      <td>0.0306323</td>\n",
       "      <td>0.0253268</td>\n",
       "      <td>0.0328926</td>\n",
       "      <td>0.0186797</td>\n",
       "      <td>0.0275522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0245579</td>\n",
       "      <td>0.0438762</td>\n",
       "      <td>0.0425781</td>\n",
       "      <td>0.0366142</td>\n",
       "      <td>0.0514295</td>\n",
       "      <td>0.0495452</td>\n",
       "      <td>0.049442</td>\n",
       "      <td>0.0400635</td>\n",
       "      <td>0.0298876</td>\n",
       "      <td>0.0477988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0254164</td>\n",
       "      <td>0.0288183</td>\n",
       "      <td>0.0292846</td>\n",
       "      <td>0.0268857</td>\n",
       "      <td>0.0245586</td>\n",
       "      <td>0.0317534</td>\n",
       "      <td>0.0272046</td>\n",
       "      <td>0.0338244</td>\n",
       "      <td>0.0216401</td>\n",
       "      <td>0.0290746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0210839</td>\n",
       "      <td>0.039722</td>\n",
       "      <td>0.0384803</td>\n",
       "      <td>0.0332173</td>\n",
       "      <td>0.0471871</td>\n",
       "      <td>0.0452712</td>\n",
       "      <td>0.0451898</td>\n",
       "      <td>0.0360732</td>\n",
       "      <td>0.0264845</td>\n",
       "      <td>0.0437912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0244808</td>\n",
       "      <td>0.0293058</td>\n",
       "      <td>0.0298268</td>\n",
       "      <td>0.0265283</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.0332567</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.0358155</td>\n",
       "      <td>0.0190102</td>\n",
       "      <td>0.0297001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0255933</td>\n",
       "      <td>0.0462435</td>\n",
       "      <td>0.0448712</td>\n",
       "      <td>0.0387365</td>\n",
       "      <td>0.0543803</td>\n",
       "      <td>0.0523213</td>\n",
       "      <td>0.0522277</td>\n",
       "      <td>0.0422147</td>\n",
       "      <td>0.0313983</td>\n",
       "      <td>0.0506277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0320946</td>\n",
       "      <td>0.0392667</td>\n",
       "      <td>0.193841</td>\n",
       "      <td>0.0351071</td>\n",
       "      <td>0.192029</td>\n",
       "      <td>0.186594</td>\n",
       "      <td>0.0358459</td>\n",
       "      <td>0.376812</td>\n",
       "      <td>0.0241389</td>\n",
       "      <td>0.0396191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 1788 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         72         73         74         75         76         77    \\\n",
       "0   0.0188494   0.958961   0.958403  0.0497574   0.999442   0.997487   \n",
       "1   0.0563963  0.0751751  0.0739159  0.0681205  0.0825219  0.0806837   \n",
       "2   0.0230081  0.0423262  0.0410591   0.035219  0.0499109   0.047973   \n",
       "3   0.0414652  0.0618619  0.0605051  0.0544413  0.0698977  0.0678662   \n",
       "4   0.0657271  0.0820723  0.0809763  0.0761542  0.0885626  0.0869143   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "67  0.0191199  0.0346809  0.0336589   0.028947  0.0408145   0.039238   \n",
       "68   0.376876   0.382171   0.356134  0.0568032   0.347749   0.379523   \n",
       "69  0.0245579  0.0438762  0.0425781  0.0366142  0.0514295  0.0495452   \n",
       "70  0.0210839   0.039722  0.0384803  0.0332173  0.0471871  0.0452712   \n",
       "71  0.0255933  0.0462435  0.0448712  0.0387365  0.0543803  0.0523213   \n",
       "\n",
       "         78         79         80         81    ...       1862       1863  \\\n",
       "0    0.999442   0.999721  0.0320443   0.999442  ...  0.0143107  0.0184219   \n",
       "1   0.0805824  0.0714793  0.0615975  0.0789845  ...  0.0572268  0.0605315   \n",
       "2   0.0478795  0.0386229  0.0284832  0.0463665  ...  0.0234469  0.0265246   \n",
       "3   0.0677733  0.0578779  0.0471929  0.0661879  ...  0.0753692   0.173029   \n",
       "4   0.0868295  0.0788542   0.070389  0.0854856  ...  0.0687899  0.0731391   \n",
       "..        ...        ...        ...        ...  ...        ...        ...   \n",
       "67  0.0391542  0.0316988  0.0235867  0.0378813  ...  0.0215156  0.0253054   \n",
       "68   0.339806   0.311121   0.337158  0.0842323  ...  0.0232132  0.0272641   \n",
       "69   0.049442  0.0400635  0.0298876  0.0477988  ...  0.0254164  0.0288183   \n",
       "70  0.0451898  0.0360732  0.0264845  0.0437912  ...  0.0244808  0.0293058   \n",
       "71  0.0522277  0.0422147  0.0313983  0.0506277  ...  0.0320946  0.0392667   \n",
       "\n",
       "         1864       1865       1866       1867       1868       1869  \\\n",
       "0   0.0189132  0.0160616  0.0131706  0.0218312  0.0164532  0.0241106   \n",
       "1   0.0609964  0.0586555  0.0563958  0.0633989  0.0589624  0.0654226   \n",
       "2   0.0269715  0.0247095  0.0227122  0.0292283  0.0250326  0.0311304   \n",
       "3   0.0566432   0.234606  0.0462954   0.173447   0.142658   0.145166   \n",
       "4   0.0737061  0.0705746  0.0676345  0.0768271  0.0710372  0.0793469   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "67   0.025748  0.0230838  0.0204795  0.0284878  0.0235023  0.0307394   \n",
       "68  0.0277528  0.0249453  0.0221029  0.0306323  0.0253268  0.0328926   \n",
       "69  0.0292846  0.0268857  0.0245586  0.0317534  0.0272046  0.0338244   \n",
       "70  0.0298268  0.0265283      0.023  0.0332567   0.026978  0.0358155   \n",
       "71   0.193841  0.0351071   0.192029   0.186594  0.0358459   0.376812   \n",
       "\n",
       "          1870       1871  \n",
       "0   0.00969823   0.018713  \n",
       "1    0.0535545  0.0607896  \n",
       "2    0.0199767  0.0267342  \n",
       "3     0.146002   0.230705  \n",
       "4    0.0638541  0.0734245  \n",
       "..         ...        ...  \n",
       "67    0.017247  0.0255376  \n",
       "68   0.0186797  0.0275522  \n",
       "69   0.0216401  0.0290746  \n",
       "70   0.0190102  0.0297001  \n",
       "71   0.0241389  0.0396191  \n",
       "\n",
       "[72 rows x 1788 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time_ref = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4616684913635254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_ref - start_time_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask = (data_model_test_matrix.fillna(0) != 0) & (user_prediction != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 只选择那些在预测评分和实际评分中都不是 0 的评分\n",
    "prediction = user_prediction[mask].values.flatten()\n",
    "prediction = pd.to_numeric(prediction, errors='coerce')\n",
    "prediction = prediction[~np.isnan(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "actual = data_model_test_matrix.fillna(0)[mask].values.flatten()\n",
    "actual = pd.to_numeric(actual, errors='coerce')\n",
    "actual = actual[~np.isnan(actual)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rmse(prediction, actual):\n",
    "    # 计算 RMSE\n",
    "    return sqrt(mean_squared_error(prediction, actual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_rmse = calculate_rmse(prediction, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44089113702143873"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ndcg(y_true, y_pred, k):\n",
    "    \"\"\"计算 NDCG @k\n",
    "    y_true: 真实的 relevancy 分数（通常为 0 或 1）\n",
    "    y_pred: 预测的 relevancy 分数\n",
    "    k: 截断位置\n",
    "    \"\"\"\n",
    "    # 计算 DCG @k\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    dcg = np.sum(gains / discounts)\n",
    "\n",
    "    # 计算 IDCG @k\n",
    "    ideal_order = np.argsort(y_true)[::-1]\n",
    "    ideal_gains = 2 ** np.take(y_true, ideal_order[:k]) - 1\n",
    "    ideal_discounts = np.log2(np.arange(len(ideal_gains)) + 2)\n",
    "    idcg = np.sum(ideal_gains / ideal_discounts)\n",
    "\n",
    "    # 防止0除问题\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "\n",
    "    # 计算 NDCG @k\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851116734123847"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(actual, prediction,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
