{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"../Data_preprocess/Kaggle/ratios/edge_80.csv\",low_memory=False)\n",
    "ratings_test = pd.read_csv(\"rate_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.dataset_id.unique()\n",
    "model_train = ratings_train.model_id.unique()\n",
    "datasets_test = ratings_test.dataset_id.unique()\n",
    "model_test = ratings_test.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=model_train)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix[row[2]][row[1]] = row[3]\n",
    "data_model_train_matrix = data_model_train_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix[row[2]][row[1]] = row[3]\n",
    "data_model_test_matrix = data_model_test_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = cosine_similarity(data_model_train_matrix)\n",
    "model_similarity = cosine_similarity(data_model_train_matrix.T)\n",
    "dataset_similarity_csv = pd.DataFrame(dataset_similarity,index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48</th>\n",
       "      <th>50</th>\n",
       "      <th>57</th>\n",
       "      <th>33</th>\n",
       "      <th>8</th>\n",
       "      <th>56</th>\n",
       "      <th>12</th>\n",
       "      <th>37</th>\n",
       "      <th>51</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>58</th>\n",
       "      <th>3</th>\n",
       "      <th>66</th>\n",
       "      <th>24</th>\n",
       "      <th>59</th>\n",
       "      <th>42</th>\n",
       "      <th>44</th>\n",
       "      <th>46</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     48        50   57   33   8    56   12   37   51   23  ...   25        58  \\\n",
       "48  1.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "50  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "57  0.0  0.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "33  0.0  0.000000  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "8   0.0  0.000000  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "..  ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "59  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "42  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "44  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.766378   \n",
       "46  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "41  0.0  0.732976  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "\n",
       "          3         66        24   59   42   44   46        41  \n",
       "48  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "50  0.000000  0.696271  0.000000  0.0  0.0  0.0  0.0  0.732976  \n",
       "57  0.000000  0.000000  0.241288  0.0  0.0  0.0  0.0  0.000000  \n",
       "33  0.832734  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "..       ...       ...       ...  ...  ...  ...  ...       ...  \n",
       "59  0.000000  0.000000  0.000000  1.0  0.0  0.0  0.0  0.000000  \n",
       "42  0.000000  0.000000  0.000000  0.0  1.0  0.0  0.0  0.000000  \n",
       "44  0.000000  0.000000  0.000000  0.0  0.0  1.0  0.0  0.000000  \n",
       "46  0.000000  0.000000  0.000000  0.0  0.0  0.0  1.0  0.000000  \n",
       "41  0.000000  0.742590  0.000000  0.0  0.0  0.0  0.0  1.000000  \n",
       "\n",
       "[62 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity):\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = ratings - np.array(mean_user_rating)[:,np.newaxis]\n",
    "        pred = np.array(mean_user_rating)[:,np.newaxis] + np.dot(similarity,ratings_diff) / np.array([np.abs(similarity).sum(axis = 1)]).T\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_prediction = predict(data_model_train_matrix,dataset_similarity_csv)\n",
    "model_prediction_train = pd.DataFrame(train_prediction,index=datasets_train,columns=model_train).sort_index().sort_index(axis=1)\n",
    "model_prediction_test = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>...</th>\n",
       "      <th>1862</th>\n",
       "      <th>1863</th>\n",
       "      <th>1864</th>\n",
       "      <th>1865</th>\n",
       "      <th>1866</th>\n",
       "      <th>1867</th>\n",
       "      <th>1868</th>\n",
       "      <th>1869</th>\n",
       "      <th>1870</th>\n",
       "      <th>1871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482122</td>\n",
       "      <td>0.556812</td>\n",
       "      <td>0.463015</td>\n",
       "      <td>0.726297</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.661620</td>\n",
       "      <td>0.337892</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>0.441616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105809</td>\n",
       "      <td>0.129497</td>\n",
       "      <td>0.115202</td>\n",
       "      <td>0.096343</td>\n",
       "      <td>0.101779</td>\n",
       "      <td>0.155240</td>\n",
       "      <td>0.083820</td>\n",
       "      <td>0.186908</td>\n",
       "      <td>0.230492</td>\n",
       "      <td>0.122938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.374067</td>\n",
       "      <td>0.476277</td>\n",
       "      <td>0.374647</td>\n",
       "      <td>0.654693</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>0.583948</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.394586</td>\n",
       "      <td>0.527765</td>\n",
       "      <td>0.323594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118302</td>\n",
       "      <td>0.148596</td>\n",
       "      <td>0.131453</td>\n",
       "      <td>0.086749</td>\n",
       "      <td>0.095454</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>0.224458</td>\n",
       "      <td>0.253992</td>\n",
       "      <td>0.121328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        72        73        74        75        76        77        78    \\\n",
       "0   0.482122  0.556812  0.463015  0.726297  0.592800  0.661620  0.337892   \n",
       "2   0.002394  0.002394  0.002394  0.002394  0.002394  0.002394  0.002394   \n",
       "3  -0.000797 -0.000797 -0.000797 -0.000797 -0.000797 -0.000797 -0.000797   \n",
       "4  -0.001813 -0.001813 -0.001813 -0.001813 -0.001813 -0.001813 -0.001813   \n",
       "5  -0.000920 -0.000920 -0.000920 -0.000920 -0.000920 -0.000920 -0.000920   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "66 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250   \n",
       "68  0.374067  0.476277  0.374647  0.654693  0.506144  0.583948  0.210180   \n",
       "69 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426   \n",
       "70 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752   \n",
       "71 -0.002187 -0.002187 -0.002187 -0.002187 -0.002187 -0.002187 -0.002187   \n",
       "\n",
       "        79        80        81    ...      1862      1863      1864      1865  \\\n",
       "0   0.490400  0.612022  0.441616  ...  0.003876  0.003876  0.003876  0.003876   \n",
       "2   0.002394  0.002394  0.002394  ...  0.002394  0.002394  0.002394  0.002394   \n",
       "3  -0.000797 -0.000797 -0.000797  ...  0.105809  0.129497  0.115202  0.096343   \n",
       "4  -0.001813 -0.001813 -0.001813  ... -0.001813 -0.001813 -0.001813 -0.001813   \n",
       "5  -0.000920 -0.000920 -0.000920  ... -0.000920 -0.000920 -0.000920 -0.000920   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "66 -0.000250 -0.000250 -0.000250  ... -0.000250 -0.000250 -0.000250 -0.000250   \n",
       "68  0.394586  0.527765  0.323594  ... -0.003030 -0.003030 -0.003030 -0.003030   \n",
       "69 -0.001426 -0.001426 -0.001426  ... -0.001426 -0.001426 -0.001426 -0.001426   \n",
       "70 -0.000752 -0.000752 -0.000752  ... -0.000752 -0.000752 -0.000752 -0.000752   \n",
       "71 -0.002187 -0.002187 -0.002187  ...  0.118302  0.148596  0.131453  0.086749   \n",
       "\n",
       "        1866      1867      1868      1869      1870      1871  \n",
       "0   0.003876  0.003876  0.003876  0.003876  0.003876  0.003876  \n",
       "2   0.002394  0.002394  0.002394  0.002394  0.002394  0.002394  \n",
       "3   0.101779  0.155240  0.083820  0.186908  0.230492  0.122938  \n",
       "4  -0.001813 -0.001813 -0.001813 -0.001813 -0.001813 -0.001813  \n",
       "5  -0.000920 -0.000920 -0.000920 -0.000920 -0.000920 -0.000920  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "66 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250  \n",
       "68 -0.003030 -0.003030 -0.003030 -0.003030 -0.003030 -0.003030  \n",
       "69 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426  \n",
       "70 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752  \n",
       "71  0.095454  0.157100  0.096212  0.224458  0.253992  0.121328  \n",
       "\n",
       "[62 rows x 1789 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Metadata Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"datasets_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.data_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,('v1','v2','v3','v4','v5','v6','v7','v8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_dataset_similarity = cosine_similarity(meta_datasets.values.tolist())\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "while i < len(datasets):\n",
    "    while j < len(datasets):\n",
    "        meta_dataset_similarity[i][j] = None\n",
    "        i += 1\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix,k):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index\n",
    "    index_row = index_row.values.tolist()\n",
    "    return index_row[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 15, 65, 61, 19]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Find_Top_k(1,meta_dataset_similarity,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_sim_index(index):\n",
    "    row1 = meta_dataset_similarity.loc[index]\n",
    "    row1_max_index = row1[row1 == row1.max()].index[0]\n",
    "    return row1_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>...</th>\n",
       "      <th>1862</th>\n",
       "      <th>1863</th>\n",
       "      <th>1864</th>\n",
       "      <th>1865</th>\n",
       "      <th>1866</th>\n",
       "      <th>1867</th>\n",
       "      <th>1868</th>\n",
       "      <th>1869</th>\n",
       "      <th>1870</th>\n",
       "      <th>1871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482122</td>\n",
       "      <td>0.556812</td>\n",
       "      <td>0.463015</td>\n",
       "      <td>0.726297</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.661620</td>\n",
       "      <td>0.337892</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>0.441616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105809</td>\n",
       "      <td>0.129497</td>\n",
       "      <td>0.115202</td>\n",
       "      <td>0.096343</td>\n",
       "      <td>0.101779</td>\n",
       "      <td>0.155240</td>\n",
       "      <td>0.083820</td>\n",
       "      <td>0.186908</td>\n",
       "      <td>0.230492</td>\n",
       "      <td>0.122938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.374067</td>\n",
       "      <td>0.476277</td>\n",
       "      <td>0.374647</td>\n",
       "      <td>0.654693</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>0.583948</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.394586</td>\n",
       "      <td>0.527765</td>\n",
       "      <td>0.323594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118302</td>\n",
       "      <td>0.148596</td>\n",
       "      <td>0.131453</td>\n",
       "      <td>0.086749</td>\n",
       "      <td>0.095454</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>0.224458</td>\n",
       "      <td>0.253992</td>\n",
       "      <td>0.121328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        72        73        74        75        76        77        78    \\\n",
       "0   0.482122  0.556812  0.463015  0.726297  0.592800  0.661620  0.337892   \n",
       "2   0.002394  0.002394  0.002394  0.002394  0.002394  0.002394  0.002394   \n",
       "3  -0.000797 -0.000797 -0.000797 -0.000797 -0.000797 -0.000797 -0.000797   \n",
       "4  -0.001813 -0.001813 -0.001813 -0.001813 -0.001813 -0.001813 -0.001813   \n",
       "5  -0.000920 -0.000920 -0.000920 -0.000920 -0.000920 -0.000920 -0.000920   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "66 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250   \n",
       "68  0.374067  0.476277  0.374647  0.654693  0.506144  0.583948  0.210180   \n",
       "69 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426   \n",
       "70 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752   \n",
       "71 -0.002187 -0.002187 -0.002187 -0.002187 -0.002187 -0.002187 -0.002187   \n",
       "\n",
       "        79        80        81    ...      1862      1863      1864      1865  \\\n",
       "0   0.490400  0.612022  0.441616  ...  0.003876  0.003876  0.003876  0.003876   \n",
       "2   0.002394  0.002394  0.002394  ...  0.002394  0.002394  0.002394  0.002394   \n",
       "3  -0.000797 -0.000797 -0.000797  ...  0.105809  0.129497  0.115202  0.096343   \n",
       "4  -0.001813 -0.001813 -0.001813  ... -0.001813 -0.001813 -0.001813 -0.001813   \n",
       "5  -0.000920 -0.000920 -0.000920  ... -0.000920 -0.000920 -0.000920 -0.000920   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "66 -0.000250 -0.000250 -0.000250  ... -0.000250 -0.000250 -0.000250 -0.000250   \n",
       "68  0.394586  0.527765  0.323594  ... -0.003030 -0.003030 -0.003030 -0.003030   \n",
       "69 -0.001426 -0.001426 -0.001426  ... -0.001426 -0.001426 -0.001426 -0.001426   \n",
       "70 -0.000752 -0.000752 -0.000752  ... -0.000752 -0.000752 -0.000752 -0.000752   \n",
       "71 -0.002187 -0.002187 -0.002187  ...  0.118302  0.148596  0.131453  0.086749   \n",
       "\n",
       "        1866      1867      1868      1869      1870      1871  \n",
       "0   0.003876  0.003876  0.003876  0.003876  0.003876  0.003876  \n",
       "2   0.002394  0.002394  0.002394  0.002394  0.002394  0.002394  \n",
       "3   0.101779  0.155240  0.083820  0.186908  0.230492  0.122938  \n",
       "4  -0.001813 -0.001813 -0.001813 -0.001813 -0.001813 -0.001813  \n",
       "5  -0.000920 -0.000920 -0.000920 -0.000920 -0.000920 -0.000920  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "66 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250 -0.000250  \n",
       "68 -0.003030 -0.003030 -0.003030 -0.003030 -0.003030 -0.003030  \n",
       "69 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426 -0.001426  \n",
       "70 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752 -0.000752  \n",
       "71  0.095454  0.157100  0.096212  0.224458  0.253992  0.121328  \n",
       "\n",
       "[62 rows x 1789 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22584\\3727235532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mmax_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_sim_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mmodel_prediction_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_prediction_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel_prediction_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_prediction_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3774\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3775\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3776\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3778\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Model_Recommendation\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "for i in datasets_test:\n",
    "        max_index = find_sim_index(i)\n",
    "        model_prediction_test.loc[i] = model_prediction_train.loc[max_index]\n",
    "model_prediction_test = model_prediction_test.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_test_matrix.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test.tolist():\n",
    "    for j in model_test.tolist():\n",
    "        if data_model_test_matrix.loc[i][j] == 0:\n",
    "            model_prediction_test.loc[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_test.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_result = pd.DataFrame(columns={\"dataset\",\"model\",\"predict_balance_accuracy\",\"groundtruth_balance_accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if model_prediction_test.loc[i][j] is not None:\n",
    "            predict_balance_accuracy = model_prediction_test.loc[i][j]\n",
    "            groundtruth_balance_accuracy = data_model_test_matrix.loc[i][j]\n",
    "            new_result = new_result.append([{'dataset':i,'model':j,'predict_balance_accuracy':predict_balance_accuracy,'groundtruth_balance_accuracy':groundtruth_balance_accuracy}],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# new_result.to_csv(\"Kaggle_result\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
