{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"./Data/rate_train.csv\", low_memory=False)\n",
    "ratings_test = pd.read_csv(\"./Data/rate_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.dataset_id.unique()\n",
    "model_train = ratings_train.model_id.unique()\n",
    "datasets_test = ratings_test.dataset_id.unique()\n",
    "model_test = ratings_test.model_id.unique()\n",
    "meta_models = pd.read_csv(\"./Data/models_num.csv\",low_memory=False)\n",
    "models = meta_models.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=models)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]\n",
    "data_model_test_matrix = data_model_test_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"./Data/datasets_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.data_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,(\"v1\",\"v2\",\"v3\",\"v4\",\"v5\",\"v6\",\"v7\",\"v8\")]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对dataframe的数据进行标准化\n",
    "scaled_data = scaler.fit_transform(meta_datasets)\n",
    "# 将标准化后的数据转换为dataframe，并保留原始索引\n",
    "scaled_df = pd.DataFrame(scaled_data, index=meta_datasets.index, columns=meta_datasets.columns)\n",
    "meta_dataset_similarity = cosine_similarity(scaled_df.values.tolist())\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity,index=datasets,columns=datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "KNN sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_func(ratings, user1, user2):\n",
    "    # 找到两个用户共同评分的物品，并将这些评分放入一个向量中\n",
    "    u1_ratings = ratings.loc[user1].dropna()\n",
    "    u2_ratings = ratings.loc[user2].dropna()\n",
    "\n",
    "    common_items = np.intersect1d(u1_ratings.index, u2_ratings.index).tolist()\n",
    "    u1_common_ratings = u1_ratings.loc[common_items]\n",
    "    u2_common_ratings = u2_ratings.loc[common_items]\n",
    "\n",
    "    # 计算两个向量之间的余弦相似度\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cos_sim = np.dot(u1_common_ratings, u2_common_ratings) / (np.linalg.norm(u1_common_ratings) * np.linalg.norm(u2_common_ratings))\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_bipartite_adjacency_matrix(rating_matrix):\n",
    "    n_users, n_items = rating_matrix.shape\n",
    "    adjacency_matrix = np.zeros((n_users + n_items, n_users + n_items))\n",
    "    adjacency_matrix[:n_users, n_users:] = rating_matrix\n",
    "    adjacency_matrix[n_users:, :n_users] = rating_matrix.T\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix(adjacency, lambda_):\n",
    "    n = adjacency.shape[0]\n",
    "    I = np.eye(n)\n",
    "    # 将 NaN 视为 0\n",
    "    adjacency = np.nan_to_num(adjacency)\n",
    "    try:\n",
    "        P = np.linalg.inv(I - lambda_ * adjacency)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"矩阵不可逆，无法计算传播矩阵\")\n",
    "        return None\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix_withWalkLength(adjacency_matrix, max_walk_length):\n",
    "    adjacency_matrix = np.nan_to_num(adjacency_matrix)\n",
    "    propagation_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "    sum_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "\n",
    "    for _ in range(max_walk_length):\n",
    "        propagation_matrix = propagation_matrix @ adjacency_matrix\n",
    "        sum_matrix += propagation_matrix\n",
    "\n",
    "    return sum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算二分图邻接矩阵\n",
    "bipartite_adjacency_matrix = create_bipartite_adjacency_matrix(data_model_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "propagation_maxLength = propagation_matrix_withWalkLength(bipartite_adjacency_matrix, 4)\n",
    "lambda_p = 0.8 # 超参数 λ，用于调整传播矩阵的强度\n",
    "propagation_lambda = propagation_matrix(bipartite_adjacency_matrix, lambda_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取用户-商品传播矩阵和商品-用户传播矩阵\n",
    "n_users = data_model_train_matrix.shape[0]\n",
    "user_item_propagation = propagation_maxLength[:n_users, n_users:]\n",
    "item_user_propagation = propagation_maxLength[n_users:, :n_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算 Random Walk Kernel\n",
    "random_walk_kernel = np.dot(user_item_propagation, item_user_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel_matrix):\n",
    "    # 计算矩阵的最小值和最大值\n",
    "    min_val = np.min(kernel_matrix)\n",
    "    max_val = np.max(kernel_matrix)\n",
    "\n",
    "    # 防止除数为零的情况\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(kernel_matrix)\n",
    "\n",
    "    # 将矩阵的值缩放到0和1之间\n",
    "    normalized_kernel_matrix = (kernel_matrix - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = normalize_kernel(random_walk_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = pd.DataFrame(normalized_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0        1         2         3         4    5         6         7   \\\n0   0.003250  0.00000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n1   0.000000  1.00000  0.000000  0.000000  0.000000  0.0  0.000000  0.992847   \n2   0.000000  0.00000  0.000268  0.000000  0.000000  0.0  0.000000  0.000000   \n3   0.000000  0.00000  0.000000  0.000571  0.000000  0.0  0.000000  0.000000   \n4   0.000000  0.00000  0.000000  0.000000  0.046471  0.0  0.000000  0.000000   \n..       ...      ...       ...       ...       ...  ...       ...       ...   \n67  0.000000  0.00000  0.000000  0.000000  0.000000  0.0  0.063893  0.000000   \n68  0.002027  0.00000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n69  0.000000  0.86214  0.000000  0.000000  0.000000  0.0  0.000000  0.855974   \n70  0.000000  0.00000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n71  0.000000  0.00000  0.000000  0.000573  0.000000  0.0  0.000000  0.000000   \n\n          8         9   ...        62   63   64   65   66        67        68  \\\n0   0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.002027   \n1   0.000000  0.839609  ...  0.992723  0.0  0.0  0.0  0.0  0.000000  0.000000   \n2   0.000106  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n3   0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n4   0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n..       ...       ...  ...       ...  ...  ...  ...  ...       ...       ...   \n67  0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.064772  0.000000   \n68  0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.001265   \n69  0.000000  0.723917  ...  0.855867  0.0  0.0  0.0  0.0  0.000000  0.000000   \n70  0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n71  0.000000  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n\n          69       70        71  \n0   0.000000  0.00000  0.000000  \n1   0.862140  0.00000  0.000000  \n2   0.000000  0.00000  0.000000  \n3   0.000000  0.00000  0.000573  \n4   0.000000  0.00000  0.000000  \n..       ...      ...       ...  \n67  0.000000  0.00000  0.000000  \n68  0.000000  0.00000  0.000000  \n69  0.743345  0.00000  0.000000  \n70  0.000000  0.00012  0.000000  \n71  0.000000  0.00000  0.000577  \n\n[72 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.003250</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.002027</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>1.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.992847</td>\n      <td>0.000000</td>\n      <td>0.839609</td>\n      <td>...</td>\n      <td>0.992723</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.862140</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000268</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000106</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000571</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000573</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.046471</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.063893</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.064772</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.002027</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.001265</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.000000</td>\n      <td>0.86214</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.855974</td>\n      <td>0.000000</td>\n      <td>0.723917</td>\n      <td>...</td>\n      <td>0.855867</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.743345</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00012</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000573</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000577</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.5\n",
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        if normalized_kernel.loc[i][j] != 0:\n",
    "            dataset_similarity.loc[i][j] = normalized_kernel.loc[i][j]\n",
    "        else:\n",
    "            dataset_similarity.loc[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0        1         2         3         4  5         6         7   \\\n0    0.00325        0         0         0         0  0         0         0   \n1          0      1.0         0         0         0  0         0  0.992847   \n2          0        0  0.000268         0         0  0         0         0   \n3          0        0         0  0.000571         0  0         0         0   \n4          0        0         0         0  0.046471  0         0         0   \n..       ...      ...       ...       ...       ... ..       ...       ...   \n67         0        0         0         0         0  0  0.063893         0   \n68  0.002027        0         0         0         0  0         0         0   \n69         0  0.86214         0         0         0  0         0  0.855974   \n70         0        0         0         0         0  0         0         0   \n71         0        0         0  0.000573         0  0         0         0   \n\n          8         9   ...        62 63 64 65 66        67        68  \\\n0          0         0  ...         0  0  0  0  0         0  0.002027   \n1          0  0.839609  ...  0.992723  0  0  0  0         0         0   \n2   0.000106         0  ...         0  0  0  0  0         0         0   \n3          0         0  ...         0  0  0  0  0         0         0   \n4          0         0  ...         0  0  0  0  0         0         0   \n..       ...       ...  ...       ... .. .. .. ..       ...       ...   \n67         0         0  ...         0  0  0  0  0  0.064772         0   \n68         0         0  ...         0  0  0  0  0         0  0.001265   \n69         0  0.723917  ...  0.855867  0  0  0  0         0         0   \n70         0         0  ...         0  0  0  0  0         0         0   \n71         0         0  ...         0  0  0  0  0         0         0   \n\n          69       70        71  \n0          0        0         0  \n1    0.86214        0         0  \n2          0        0         0  \n3          0        0  0.000573  \n4          0        0         0  \n..       ...      ...       ...  \n67         0        0         0  \n68         0        0         0  \n69  0.743345        0         0  \n70         0  0.00012         0  \n71         0        0  0.000577  \n\n[72 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00325</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.002027</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.992847</td>\n      <td>0</td>\n      <td>0.839609</td>\n      <td>...</td>\n      <td>0.992723</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.86214</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000268</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000106</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000571</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000573</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.046471</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.063893</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.064772</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.002027</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.001265</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0</td>\n      <td>0.86214</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.855974</td>\n      <td>0</td>\n      <td>0.723917</td>\n      <td>...</td>\n      <td>0.855867</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.743345</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00012</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000573</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000577</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ratings(rating_matrix, user_similarity_matrix):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "    rating_matrix - 评分矩阵，DataFrame格式，其中NaN表示未评分\n",
    "    user_similarity_matrix - 用户相似度矩阵，DataFrame格式\n",
    "    k - 最近邻的数量，默认为5\n",
    "\n",
    "    输出：\n",
    "    prediction_matrix - 预测矩阵，DataFrame格式\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化预测矩阵\n",
    "    prediction_matrix = rating_matrix.copy()\n",
    "\n",
    "    # 对于评分矩阵中的每个NaN值，使用K最近邻的方法预测评分\n",
    "    for i in range(rating_matrix.shape[0]):\n",
    "        for j in range(rating_matrix.shape[1]):\n",
    "            if np.isnan(rating_matrix.iloc[i, j]):\n",
    "                # 获取第i个用户的相似度值，并在相似度矩阵中找到K个最相似的用户\n",
    "                similarity_values = user_similarity_matrix.iloc[i].sort_values(ascending=False)[1:]\n",
    "\n",
    "                # 计算加权平均评分\n",
    "                weighted_sum = 0\n",
    "                similarity_sum = 0\n",
    "                for index, value in similarity_values.items():\n",
    "                    user_rating = rating_matrix.iloc[index, j]\n",
    "                    if not np.isnan(user_rating):\n",
    "                        weighted_sum += value * user_rating\n",
    "                        similarity_sum += value\n",
    "\n",
    "                # 如果存在至少一个相似用户对该物品进行了评分，则计算预测评分\n",
    "                if similarity_sum != 0:\n",
    "                    prediction_matrix.iloc[i, j] = weighted_sum / similarity_sum\n",
    "                else:\n",
    "                    # 如果没有相似用户评分，则使用当前用户的平均评分作为预测值\n",
    "                    prediction_matrix.iloc[i, j] = rating_matrix.iloc[i].mean()\n",
    "\n",
    "    return prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def predict(rating_matrix, similarity_matrix):\n",
    "    \"\"\"\n",
    "    根据评分矩阵和相似度矩阵预测评分。\n",
    "\n",
    "    参数：\n",
    "    rating_matrix (pd.DataFrame)：评分矩阵，包含NaN值\n",
    "    similarity_matrix (numpy.array)：相似度矩阵\n",
    "\n",
    "    返回：\n",
    "    pd.DataFrame：预测评分矩阵\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取评分矩阵的均值（忽略NaN值）\n",
    "    mean_rating = rating_matrix.mean(axis=1).values\n",
    "\n",
    "    # 将评分矩阵中的NaN值替换为0\n",
    "    rating_matrix_nan_to_zero = rating_matrix.fillna(0).values\n",
    "\n",
    "    # 减去均值，得到归一化的评分矩阵\n",
    "    normalized_rating_matrix = rating_matrix_nan_to_zero - mean_rating[:, np.newaxis]\n",
    "\n",
    "    # 计算预测评分\n",
    "    predicted_ratings = mean_rating[:, np.newaxis] + np.dot(similarity_matrix, normalized_rating_matrix) / np.abs(similarity_matrix).sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 将预测评分数组转换为DataFrame\n",
    "    predicted_ratings_df = pd.DataFrame(predicted_ratings, index=rating_matrix.index, columns=rating_matrix.columns)\n",
    "\n",
    "    return predicted_ratings_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\byy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "model_prediction_train = predict(data_model_train_matrix,dataset_similarity)\n",
    "model_prediction_train = pd.DataFrame(model_prediction_train,index=datasets_train,columns=models).sort_index().sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        72        73        74        75        76        77        78    \\\n0     0.6117  0.587688  0.556949  0.786475  0.757494  0.724982  0.726397   \n1   0.020827  0.020827  0.020827  0.020827  0.020827  0.020827  0.020827   \n2   -0.10415  -0.10415  -0.10415  -0.10415  -0.10415  -0.10415  -0.10415   \n3  -0.090424 -0.090424 -0.090424 -0.090424 -0.090424 -0.090424 -0.090424   \n4  -0.033299 -0.033299 -0.033299 -0.033299 -0.033299 -0.033299 -0.033299   \n..       ...       ...       ...       ...       ...       ...       ...   \n67  0.025903  0.025903  0.025903  0.025903  0.025903  0.025903  0.025903   \n68  0.480995  0.456979  0.426236   0.65581  0.626817  0.594292  0.595705   \n69 -0.028359 -0.028359 -0.028359 -0.028359 -0.028359 -0.028359 -0.028359   \n70 -0.010546 -0.010546 -0.010546 -0.010546 -0.010546 -0.010546 -0.010546   \n71 -0.109282 -0.109282 -0.109282 -0.109282 -0.109282 -0.109282 -0.109282   \n\n        79        80        81    ...      1862      1863      1864      1865  \\\n0   0.744265  0.790785  0.768843  ...  0.038728  0.038728  0.038728  0.038728   \n1   0.020827  0.020827  0.020827  ...  0.020827  0.020827  0.020827  0.020827   \n2   -0.10415  -0.10415  -0.10415  ...  -0.10415  -0.10415  -0.10415  -0.10415   \n3  -0.090424 -0.090424 -0.090424  ...  0.040805   0.13622  0.071826  0.070316   \n4  -0.033299 -0.033299 -0.033299  ... -0.033299 -0.033299 -0.033299 -0.033299   \n..       ...       ...       ...  ...       ...       ...       ...       ...   \n67  0.025903  0.025903  0.025903  ...  0.025903  0.025903  0.025903  0.025903   \n68  0.613579  0.660117  0.638167  ...  -0.09183  -0.09183  -0.09183  -0.09183   \n69 -0.028359 -0.028359 -0.028359  ... -0.028359 -0.028359 -0.028359 -0.028359   \n70 -0.010546 -0.010546 -0.010546  ... -0.010546 -0.010546 -0.010546 -0.010546   \n71 -0.109282 -0.109282 -0.109282  ...  0.021831  0.117676  0.053009  0.051421   \n\n        1866      1867      1868      1869      1870      1871  \n0   0.038728  0.038728  0.038728  0.038728  0.038728  0.038728  \n1   0.020827  0.020827  0.020827  0.020827  0.020827  0.020827  \n2   -0.10415  -0.10415  -0.10415  -0.10415  -0.10415  -0.10415  \n3    0.07137  0.073026   0.07137   0.15315  0.135254  0.073357  \n4  -0.033299 -0.033299 -0.033299 -0.033299 -0.033299 -0.033299  \n..       ...       ...       ...       ...       ...       ...  \n67  0.025903  0.025903  0.025903  0.025903  0.025903  0.025903  \n68  -0.09183  -0.09183  -0.09183  -0.09183  -0.09183  -0.09183  \n69 -0.028359 -0.028359 -0.028359 -0.028359 -0.028359 -0.028359  \n70 -0.010546 -0.010546 -0.010546 -0.010546 -0.010546 -0.010546  \n71  0.052555  0.054212  0.052555  0.134423  0.116392  0.054556  \n\n[72 rows x 1800 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>...</th>\n      <th>1862</th>\n      <th>1863</th>\n      <th>1864</th>\n      <th>1865</th>\n      <th>1866</th>\n      <th>1867</th>\n      <th>1868</th>\n      <th>1869</th>\n      <th>1870</th>\n      <th>1871</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.6117</td>\n      <td>0.587688</td>\n      <td>0.556949</td>\n      <td>0.786475</td>\n      <td>0.757494</td>\n      <td>0.724982</td>\n      <td>0.726397</td>\n      <td>0.744265</td>\n      <td>0.790785</td>\n      <td>0.768843</td>\n      <td>...</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n      <td>0.038728</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>...</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n      <td>0.020827</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>...</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n      <td>-0.10415</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>-0.090424</td>\n      <td>...</td>\n      <td>0.040805</td>\n      <td>0.13622</td>\n      <td>0.071826</td>\n      <td>0.070316</td>\n      <td>0.07137</td>\n      <td>0.073026</td>\n      <td>0.07137</td>\n      <td>0.15315</td>\n      <td>0.135254</td>\n      <td>0.073357</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>...</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n      <td>-0.033299</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>...</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n      <td>0.025903</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.480995</td>\n      <td>0.456979</td>\n      <td>0.426236</td>\n      <td>0.65581</td>\n      <td>0.626817</td>\n      <td>0.594292</td>\n      <td>0.595705</td>\n      <td>0.613579</td>\n      <td>0.660117</td>\n      <td>0.638167</td>\n      <td>...</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n      <td>-0.09183</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>...</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n      <td>-0.028359</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>...</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n      <td>-0.010546</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>-0.109282</td>\n      <td>...</td>\n      <td>0.021831</td>\n      <td>0.117676</td>\n      <td>0.053009</td>\n      <td>0.051421</td>\n      <td>0.052555</td>\n      <td>0.054212</td>\n      <td>0.052555</td>\n      <td>0.134423</td>\n      <td>0.116392</td>\n      <td>0.054556</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 1800 columns</p>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_test = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.7665512561798096"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_train = time.time()\n",
    "Training_time = end_time_train - start_time_train\n",
    "Training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_sim_index(index):\n",
    "    row1 = meta_dataset_similarity.loc[index]\n",
    "    row1_max_index = row1[row1 == row1.max()].index[0]\n",
    "    return row1_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index\n",
    "    index_row = index_row.values.tolist()\n",
    "    return index_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in datasets_test:\n",
    "    for model in model_test:\n",
    "        dataset_sim_list = Find_Top_k(dataset,meta_dataset_similarity)[1:]\n",
    "        # 仅保留存在于 model_prediction_train 的索引\n",
    "        valid_indices = [idx for idx in dataset_sim_list if idx in model_prediction_train.index][:15]\n",
    "        model_prediction_test.loc[dataset][model] = model_prediction_train.loc[valid_indices][model].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.880357503890991"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if data_model_test_matrix.loc[i][j] == 0:\n",
    "            model_prediction_test.loc[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns={\"dataset\",\"model\",\"balanced_accuracy\",\"groundtruth_balanced_accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if model_prediction_test.loc[i][j] is not None:\n",
    "            balanced_accuracy = model_prediction_test.loc[i][j]\n",
    "            groundtruth_balanced_accuracy = data_model_test_matrix.loc[i][j]\n",
    "            result = result.append([{'dataset':i,'model':j,'balanced_accuracy':balanced_accuracy,'groundtruth_balanced_accuracy':groundtruth_balanced_accuracy}],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     model  balanced_accuracy  groundtruth_balanced_accuracy dataset\n0       97           0.168344                       0.672734       1\n1       98           0.174071                       0.748037       1\n2       99           0.179798                       0.755532       1\n3      100           0.219836                       0.995360       1\n4      101           0.214112                       0.994290       1\n...    ...                ...                            ...     ...\n1370  1767           0.112667                       0.500000      67\n1371  1768           0.112716                       0.500000      67\n1372  1769           0.120068                       0.577401      67\n1373  1770           0.113074                       0.500000      67\n1374  1771           0.112455                       0.497780      67\n\n[1375 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>balanced_accuracy</th>\n      <th>groundtruth_balanced_accuracy</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>0.168344</td>\n      <td>0.672734</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>98</td>\n      <td>0.174071</td>\n      <td>0.748037</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99</td>\n      <td>0.179798</td>\n      <td>0.755532</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>0.219836</td>\n      <td>0.995360</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>101</td>\n      <td>0.214112</td>\n      <td>0.994290</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1370</th>\n      <td>1767</td>\n      <td>0.112667</td>\n      <td>0.500000</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>1371</th>\n      <td>1768</td>\n      <td>0.112716</td>\n      <td>0.500000</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>1372</th>\n      <td>1769</td>\n      <td>0.120068</td>\n      <td>0.577401</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>1770</td>\n      <td>0.113074</td>\n      <td>0.500000</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>1771</td>\n      <td>0.112455</td>\n      <td>0.497780</td>\n      <td>67</td>\n    </tr>\n  </tbody>\n</table>\n<p>1375 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"../Kaggle/Output/RandomWalk_only/Full_RandomWalk_only@4@15.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}