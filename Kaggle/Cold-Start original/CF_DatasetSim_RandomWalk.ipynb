{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"./Data/rate_train.csv\", low_memory=False)\n",
    "ratings_test = pd.read_csv(\"./Data/rate_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.dataset_id.unique()\n",
    "model_train = ratings_train.model_id.unique()\n",
    "datasets_test = ratings_test.dataset_id.unique()\n",
    "model_test = ratings_test.model_id.unique()\n",
    "meta_models = pd.read_csv(\"./Data/models_num.csv\",low_memory=False)\n",
    "models = meta_models.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=models)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]\n",
    "data_model_test_matrix = data_model_test_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"./Data/datasets_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.data_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,(\"v1\",\"v2\",\"v3\",\"v4\",\"v5\",\"v6\",\"v7\",\"v8\")]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对dataframe的数据进行标准化\n",
    "scaled_data = scaler.fit_transform(meta_datasets)\n",
    "# 将标准化后的数据转换为dataframe，并保留原始索引\n",
    "scaled_df = pd.DataFrame(scaled_data, index=meta_datasets.index, columns=meta_datasets.columns)\n",
    "meta_dataset_similarity = cosine_similarity(scaled_df.values.tolist())\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity,index=datasets,columns=datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "KNN sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          v1        v2        v3        v4        v5        v6        v7  \\\n0   0.454312  0.241966 -0.178474  0.078718 -0.343706  0.150178  0.103396   \n1   0.527839  0.284245 -0.201757  0.116918 -0.394861  0.168884  0.137184   \n2   0.421102  0.234788 -0.172241  0.081514 -0.348054  0.138399  0.100450   \n3   0.358012  0.198786 -0.129784  0.068405 -0.275457  0.119678  0.093582   \n4   0.298305  0.167896 -0.120117  0.052906 -0.242469  0.107290  0.072812   \n..       ...       ...       ...       ...       ...       ...       ...   \n67  0.446627  0.241174 -0.179276  0.092747 -0.355247  0.140657  0.110482   \n68  0.411207  0.244925 -0.156990  0.084651 -0.319750  0.147412  0.104277   \n69  0.495822  0.270633 -0.181879  0.100016 -0.387360  0.150677  0.108678   \n70  0.406016  0.214886 -0.155250  0.082475 -0.315015  0.126135  0.087693   \n71  0.177364  0.075348 -0.091034  0.006257 -0.083623  0.051864  0.039216   \n\n          v8  \n0  -0.474233  \n1  -0.536491  \n2  -0.447096  \n3  -0.378495  \n4  -0.322821  \n..       ...  \n67 -0.472832  \n68 -0.440762  \n69 -0.507951  \n70 -0.414519  \n71 -0.090296  \n\n[72 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>v3</th>\n      <th>v4</th>\n      <th>v5</th>\n      <th>v6</th>\n      <th>v7</th>\n      <th>v8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.454312</td>\n      <td>0.241966</td>\n      <td>-0.178474</td>\n      <td>0.078718</td>\n      <td>-0.343706</td>\n      <td>0.150178</td>\n      <td>0.103396</td>\n      <td>-0.474233</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.527839</td>\n      <td>0.284245</td>\n      <td>-0.201757</td>\n      <td>0.116918</td>\n      <td>-0.394861</td>\n      <td>0.168884</td>\n      <td>0.137184</td>\n      <td>-0.536491</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.421102</td>\n      <td>0.234788</td>\n      <td>-0.172241</td>\n      <td>0.081514</td>\n      <td>-0.348054</td>\n      <td>0.138399</td>\n      <td>0.100450</td>\n      <td>-0.447096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.358012</td>\n      <td>0.198786</td>\n      <td>-0.129784</td>\n      <td>0.068405</td>\n      <td>-0.275457</td>\n      <td>0.119678</td>\n      <td>0.093582</td>\n      <td>-0.378495</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.298305</td>\n      <td>0.167896</td>\n      <td>-0.120117</td>\n      <td>0.052906</td>\n      <td>-0.242469</td>\n      <td>0.107290</td>\n      <td>0.072812</td>\n      <td>-0.322821</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.446627</td>\n      <td>0.241174</td>\n      <td>-0.179276</td>\n      <td>0.092747</td>\n      <td>-0.355247</td>\n      <td>0.140657</td>\n      <td>0.110482</td>\n      <td>-0.472832</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.411207</td>\n      <td>0.244925</td>\n      <td>-0.156990</td>\n      <td>0.084651</td>\n      <td>-0.319750</td>\n      <td>0.147412</td>\n      <td>0.104277</td>\n      <td>-0.440762</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.495822</td>\n      <td>0.270633</td>\n      <td>-0.181879</td>\n      <td>0.100016</td>\n      <td>-0.387360</td>\n      <td>0.150677</td>\n      <td>0.108678</td>\n      <td>-0.507951</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.406016</td>\n      <td>0.214886</td>\n      <td>-0.155250</td>\n      <td>0.082475</td>\n      <td>-0.315015</td>\n      <td>0.126135</td>\n      <td>0.087693</td>\n      <td>-0.414519</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.177364</td>\n      <td>0.075348</td>\n      <td>-0.091034</td>\n      <td>0.006257</td>\n      <td>-0.083623</td>\n      <td>0.051864</td>\n      <td>0.039216</td>\n      <td>-0.090296</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_func(ratings, user1, user2):\n",
    "    # 找到两个用户共同评分的物品，并将这些评分放入一个向量中\n",
    "    u1_ratings = ratings.loc[user1].dropna()\n",
    "    u2_ratings = ratings.loc[user2].dropna()\n",
    "\n",
    "    common_items = np.intersect1d(u1_ratings.index, u2_ratings.index).tolist()\n",
    "    u1_common_ratings = u1_ratings.loc[common_items]\n",
    "    u2_common_ratings = u2_ratings.loc[common_items]\n",
    "\n",
    "    # 计算两个向量之间的余弦相似度\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cos_sim = np.dot(u1_common_ratings, u2_common_ratings) / (np.linalg.norm(u1_common_ratings) * np.linalg.norm(u2_common_ratings))\n",
    "        return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(index=datasets_train,columns=datasets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_bipartite_adjacency_matrix(rating_matrix):\n",
    "    n_users, n_items = rating_matrix.shape\n",
    "    adjacency_matrix = np.zeros((n_users + n_items, n_users + n_items))\n",
    "    adjacency_matrix[:n_users, n_users:] = rating_matrix\n",
    "    adjacency_matrix[n_users:, :n_users] = rating_matrix.T\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix(adjacency, lambda_):\n",
    "    n = adjacency.shape[0]\n",
    "    I = np.eye(n)\n",
    "    # 将 NaN 视为 0\n",
    "    adjacency = np.nan_to_num(adjacency)\n",
    "    try:\n",
    "        P = np.linalg.inv(I - lambda_ * adjacency)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"矩阵不可逆，无法计算传播矩阵\")\n",
    "        return None\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def propagation_matrix_withWalkLength(adjacency_matrix, max_walk_length):\n",
    "    adjacency_matrix = np.nan_to_num(adjacency_matrix)\n",
    "    propagation_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "    sum_matrix = np.eye(adjacency_matrix.shape[0])\n",
    "\n",
    "    for _ in range(max_walk_length):\n",
    "        propagation_matrix = propagation_matrix @ adjacency_matrix\n",
    "        sum_matrix += propagation_matrix\n",
    "\n",
    "    return sum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time_train = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算二分图邻接矩阵\n",
    "bipartite_adjacency_matrix = create_bipartite_adjacency_matrix(data_model_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "propagation_maxLength = propagation_matrix_withWalkLength(bipartite_adjacency_matrix, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 提取用户-商品传播矩阵和商品-用户传播矩阵\n",
    "n_users = data_model_train_matrix.shape[0]\n",
    "user_item_propagation = propagation_maxLength[:n_users, n_users:]\n",
    "item_user_propagation = propagation_maxLength[n_users:, :n_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算 Random Walk Kernel\n",
    "random_walk_kernel = np.dot(user_item_propagation, item_user_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel_matrix):\n",
    "    diagonal_elements = np.diag(kernel_matrix)\n",
    "    normalized_kernel_matrix = np.divide(kernel_matrix, np.sqrt(np.outer(diagonal_elements, diagonal_elements)))\n",
    "    return normalized_kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = normalize_kernel(random_walk_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalized_kernel = pd.DataFrame(normalized_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0        1    2         3    4    5         6         7         8   \\\n0   1.000000  0.00000  0.0  0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n1   0.000000  1.00000  0.0  0.000000  0.0  0.0  0.000000  1.000000  0.000000   \n2   0.000000  0.00000  1.0  0.000000  0.0  0.0  0.000000  0.000000  0.999115   \n3   0.000000  0.00000  0.0  1.000000  0.0  0.0  0.000000  0.000000  0.000000   \n4   0.000000  0.00000  0.0  0.000000  1.0  0.0  0.000000  0.000000  0.000000   \n..       ...      ...  ...       ...  ...  ...       ...       ...       ...   \n67  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.999998  0.000000  0.000000   \n68  0.999381  0.00000  0.0  0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n69  0.000000  0.99996  0.0  0.000000  0.0  0.0  0.000000  0.999961  0.000000   \n70  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.000000  0.000000  0.000000   \n71  0.000000  0.00000  0.0  0.997179  0.0  0.0  0.000000  0.000000  0.000000   \n\n          9   ...        62   63   64   65   66   67        68       69   70  \\\n0   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.999381  0.00000  0.0   \n1   0.999962  ...  1.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.99996  0.0   \n2   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.00000  0.0   \n3   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.00000  0.0   \n4   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.00000  0.0   \n..       ...  ...       ...  ...  ...  ...  ...  ...       ...      ...  ...   \n67  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  1.0  0.000000  0.00000  0.0   \n68  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  1.000000  0.00000  0.0   \n69  1.000000  ...  0.999961  0.0  0.0  0.0  0.0  0.0  0.000000  1.00000  0.0   \n70  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.00000  1.0   \n71  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.00000  0.0   \n\n          71  \n0   0.000000  \n1   0.000000  \n2   0.000000  \n3   0.997179  \n4   0.000000  \n..       ...  \n67  0.000000  \n68  0.000000  \n69  0.000000  \n70  0.000000  \n71  1.000000  \n\n[72 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.999381</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>1.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.999962</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.99996</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.999115</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.997179</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.999998</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.999381</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.000000</td>\n      <td>0.99996</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.999961</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.999961</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.997179</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lambda_ = 0.5\n",
    "for i in datasets_train:\n",
    "    for j in datasets_train:\n",
    "        # rating_based_sim = cosine_similarity_func(data_model_train_matrix,i,j)\n",
    "        if normalized_kernel.loc[i][j] != 0 and meta_dataset_similarity.loc[i][j] != 0:\n",
    "            dataset_similarity.loc[i][j] = lambda_ * normalized_kernel.loc[i][j] + (1-lambda_) * meta_dataset_similarity.loc[i][j]\n",
    "            continue\n",
    "        dataset_similarity.loc[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1    2         3    4  5         6         7         8   \\\n0        1.0         0    0         0    0  0         0         0         0   \n1          0       1.0    0         0    0  0         0  0.966721         0   \n2          0         0  1.0         0    0  0         0         0  0.496074   \n3          0         0    0       1.0    0  0         0         0         0   \n4          0         0    0         0  1.0  0         0         0         0   \n..       ...       ...  ...       ...  ... ..       ...       ...       ...   \n67         0         0    0         0    0  0  0.964098         0         0   \n68  0.712598         0    0         0    0  0         0         0         0   \n69         0  0.953382    0         0    0  0         0  0.924301         0   \n70         0         0    0         0    0  0         0         0         0   \n71         0         0    0  0.974817    0  0         0         0         0   \n\n          9   ...        62 63 64 65 66   67        68        69   70  \\\n0          0  ...         0  0  0  0  0    0  0.712598         0    0   \n1   0.025001  ...  0.880545  0  0  0  0    0         0  0.953382    0   \n2          0  ...         0  0  0  0  0    0         0         0    0   \n3          0  ...         0  0  0  0  0    0         0         0    0   \n4          0  ...         0  0  0  0  0    0         0         0    0   \n..       ...  ...       ... .. .. .. ..  ...       ...       ...  ...   \n67         0  ...         0  0  0  0  0  1.0         0         0    0   \n68         0  ...         0  0  0  0  0    0       1.0         0    0   \n69  0.109346  ...  0.740674  0  0  0  0    0         0       1.0    0   \n70         0  ...         0  0  0  0  0    0         0         0  1.0   \n71         0  ...         0  0  0  0  0    0         0         0    0   \n\n          71  \n0          0  \n1          0  \n2          0  \n3   0.974817  \n4          0  \n..       ...  \n67         0  \n68         0  \n69         0  \n70         0  \n71       1.0  \n\n[72 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.712598</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.966721</td>\n      <td>0</td>\n      <td>0.025001</td>\n      <td>...</td>\n      <td>0.880545</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.953382</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.496074</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.974817</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.964098</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.712598</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0</td>\n      <td>0.953382</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.924301</td>\n      <td>0</td>\n      <td>0.109346</td>\n      <td>...</td>\n      <td>0.740674</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.974817</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_ratings(rating_matrix, user_similarity_matrix, k=5):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "    rating_matrix - 评分矩阵，DataFrame格式，其中NaN表示未评分\n",
    "    user_similarity_matrix - 用户相似度矩阵，DataFrame格式\n",
    "    k - 最近邻的数量，默认为5\n",
    "\n",
    "    输出：\n",
    "    prediction_matrix - 预测矩阵，DataFrame格式\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化预测矩阵\n",
    "    prediction_matrix = rating_matrix.copy()\n",
    "\n",
    "    # 对于评分矩阵中的每个NaN值，使用K最近邻的方法预测评分\n",
    "    for i in range(rating_matrix.shape[0]):\n",
    "        for j in range(rating_matrix.shape[1]):\n",
    "            if np.isnan(rating_matrix.iloc[i, j]):\n",
    "                # 获取第i个用户的相似度值，并在相似度矩阵中找到K个最相似的用户\n",
    "                similarity_values = user_similarity_matrix.iloc[i].sort_values(ascending=False)[1:k+1]\n",
    "\n",
    "                # 计算加权平均评分\n",
    "                weighted_sum = 0\n",
    "                similarity_sum = 0\n",
    "                for index, value in similarity_values.items():\n",
    "                    user_rating = rating_matrix.iloc[index, j]\n",
    "                    if not np.isnan(user_rating):\n",
    "                        weighted_sum += value * user_rating\n",
    "                        similarity_sum += value\n",
    "\n",
    "                # 如果存在至少一个相似用户对该物品进行了评分，则计算预测评分\n",
    "                if similarity_sum != 0:\n",
    "                    prediction_matrix.iloc[i, j] = weighted_sum / similarity_sum\n",
    "                else:\n",
    "                    # 如果没有相似用户评分，则使用当前用户的平均评分作为预测值\n",
    "                    prediction_matrix.iloc[i, j] = rating_matrix.iloc[i].mean()\n",
    "\n",
    "    return prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def predict(rating_matrix, similarity_matrix):\n",
    "    \"\"\"\n",
    "    根据评分矩阵和相似度矩阵预测评分。\n",
    "\n",
    "    参数：\n",
    "    rating_matrix (pd.DataFrame)：评分矩阵，包含NaN值\n",
    "    similarity_matrix (numpy.array)：相似度矩阵\n",
    "\n",
    "    返回：\n",
    "    pd.DataFrame：预测评分矩阵\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取评分矩阵的均值（忽略NaN值）\n",
    "    mean_rating = rating_matrix.mean(axis=1).values\n",
    "\n",
    "    # 将评分矩阵中的NaN值替换为0\n",
    "    rating_matrix_nan_to_zero = rating_matrix.fillna(0).values\n",
    "\n",
    "    # 减去均值，得到归一化的评分矩阵\n",
    "    normalized_rating_matrix = rating_matrix_nan_to_zero - mean_rating[:, np.newaxis]\n",
    "\n",
    "    # 计算预测评分\n",
    "    predicted_ratings = mean_rating[:, np.newaxis] + np.dot(similarity_matrix, normalized_rating_matrix) / np.abs(similarity_matrix).sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 将预测评分数组转换为DataFrame\n",
    "    predicted_ratings_df = pd.DataFrame(predicted_ratings, index=rating_matrix.index, columns=rating_matrix.columns)\n",
    "\n",
    "    return predicted_ratings_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\byy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "model_prediction_train = predict(data_model_train_matrix,dataset_similarity)\n",
    "model_prediction_train = pd.DataFrame(model_prediction_train,index=datasets_train,columns=models).sort_index().sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        72        73        74        75        76        77        78    \\\n0   0.940459  0.958896  0.958319   0.99972  0.999439  0.997482  0.999439   \n1   0.014812  0.014812  0.014812  0.014812  0.014812  0.014812  0.014812   \n2  -0.030882 -0.030882 -0.030882 -0.030882 -0.030882 -0.030882 -0.030882   \n3  -0.005004 -0.005004 -0.005004 -0.005004 -0.005004 -0.005004 -0.005004   \n4  -0.036939 -0.036939 -0.036939 -0.036939 -0.036939 -0.036939 -0.036939   \n..       ...       ...       ...       ...       ...       ...       ...   \n67  0.013501  0.013501  0.013501  0.013501  0.013501  0.013501  0.013501   \n68  0.350863  0.358772  0.339103  0.376309  0.333301   0.36778  0.325719   \n69 -0.032124 -0.032124 -0.032124 -0.032124 -0.032124 -0.032124 -0.032124   \n70 -0.010128 -0.010128 -0.010128 -0.010128 -0.010128 -0.010128 -0.010128   \n71 -0.022319 -0.022319 -0.022319 -0.022319 -0.022319 -0.022319 -0.022319   \n\n        79        80        81    ...      1862      1863      1864      1865  \\\n0    0.99972  0.998881  0.999439  ...  0.052126  0.052126  0.052126  0.052126   \n1   0.014812  0.014812  0.014812  ...  0.014812  0.014812  0.014812  0.014812   \n2  -0.030882 -0.030882 -0.030882  ... -0.030882 -0.030882 -0.030882 -0.030882   \n3  -0.005004 -0.005004 -0.005004  ...  0.165514  0.144654  0.142857  0.162836   \n4  -0.036939 -0.036939 -0.036939  ... -0.036939 -0.036939 -0.036939 -0.036939   \n..       ...       ...       ...  ...       ...       ...       ...       ...   \n67  0.013501  0.013501  0.013501  ...  0.013501  0.013501  0.013501  0.013501   \n68  0.280354   0.34698  0.308344  ... -0.071981 -0.071981 -0.071981 -0.071981   \n69 -0.032124 -0.032124 -0.032124  ... -0.032124 -0.032124 -0.032124 -0.032124   \n70 -0.010128 -0.010128 -0.010128  ... -0.010128 -0.010128 -0.010128 -0.010128   \n71 -0.022319 -0.022319 -0.022319  ...  0.152381  0.168254  0.168831  0.176792   \n\n        1866      1867      1868      1869      1870      1871  \n0   0.052126  0.052126  0.052126  0.052126  0.052126  0.052126  \n1   0.014812  0.014812  0.014812  0.014812  0.014812  0.014812  \n2  -0.030882 -0.030882 -0.030882 -0.030882 -0.030882 -0.030882  \n3   0.142857  0.143773  0.142857  0.133342  0.144218  0.140705  \n4  -0.036939 -0.036939 -0.036939 -0.036939 -0.036939 -0.036939  \n..       ...       ...       ...       ...       ...       ...  \n67  0.013501  0.013501  0.013501  0.013501  0.013501  0.013501  \n68 -0.071981 -0.071981 -0.071981 -0.071981 -0.071981 -0.071981  \n69 -0.032124 -0.032124 -0.032124 -0.032124 -0.032124 -0.032124  \n70 -0.010128 -0.010128 -0.010128 -0.010128 -0.010128 -0.010128  \n71  0.166667  0.168099  0.166667  0.343778  0.360811  0.165255  \n\n[72 rows x 1800 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>...</th>\n      <th>1862</th>\n      <th>1863</th>\n      <th>1864</th>\n      <th>1865</th>\n      <th>1866</th>\n      <th>1867</th>\n      <th>1868</th>\n      <th>1869</th>\n      <th>1870</th>\n      <th>1871</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.940459</td>\n      <td>0.958896</td>\n      <td>0.958319</td>\n      <td>0.99972</td>\n      <td>0.999439</td>\n      <td>0.997482</td>\n      <td>0.999439</td>\n      <td>0.99972</td>\n      <td>0.998881</td>\n      <td>0.999439</td>\n      <td>...</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n      <td>0.052126</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>...</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n      <td>0.014812</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>...</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n      <td>-0.030882</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>-0.005004</td>\n      <td>...</td>\n      <td>0.165514</td>\n      <td>0.144654</td>\n      <td>0.142857</td>\n      <td>0.162836</td>\n      <td>0.142857</td>\n      <td>0.143773</td>\n      <td>0.142857</td>\n      <td>0.133342</td>\n      <td>0.144218</td>\n      <td>0.140705</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>...</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n      <td>-0.036939</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>...</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n      <td>0.013501</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.350863</td>\n      <td>0.358772</td>\n      <td>0.339103</td>\n      <td>0.376309</td>\n      <td>0.333301</td>\n      <td>0.36778</td>\n      <td>0.325719</td>\n      <td>0.280354</td>\n      <td>0.34698</td>\n      <td>0.308344</td>\n      <td>...</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n      <td>-0.071981</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>...</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n      <td>-0.032124</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>...</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n      <td>-0.010128</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>-0.022319</td>\n      <td>...</td>\n      <td>0.152381</td>\n      <td>0.168254</td>\n      <td>0.168831</td>\n      <td>0.176792</td>\n      <td>0.166667</td>\n      <td>0.168099</td>\n      <td>0.166667</td>\n      <td>0.343778</td>\n      <td>0.360811</td>\n      <td>0.165255</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 1800 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction_test = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.7108173370361328"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time_train = time.time()\n",
    "Training_time = end_time_train - start_time_train\n",
    "Training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_sim_index(index):\n",
    "    row1 = meta_dataset_similarity.loc[index]\n",
    "    row1_max_index = row1[row1 == row1.max()].index[0]\n",
    "    return row1_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index\n",
    "    index_row = index_row.values.tolist()\n",
    "    return index_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in datasets_test:\n",
    "    for model in model_test:\n",
    "        dataset_sim_list = Find_Top_k(dataset,meta_dataset_similarity)[1:]\n",
    "        # 仅保留存在于 model_prediction_train 的索引\n",
    "        valid_indices = [idx for idx in dataset_sim_list if idx in model_prediction_train.index][:15]\n",
    "        model_prediction_test.loc[dataset][model] = model_prediction_train.loc[valid_indices][model].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.886613130569458"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if data_model_test_matrix.loc[i][j] == 0:\n",
    "            model_prediction_test.loc[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns={\"dataset\",\"model\",\"balanced_accuracy\",\"groundtruth_balanced_accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in datasets_test:\n",
    "    for j in model_test:\n",
    "        if model_prediction_test.loc[i][j] is not None:\n",
    "            balanced_accuracy = model_prediction_test.loc[i][j]\n",
    "            groundtruth_balanced_accuracy = data_model_test_matrix.loc[i][j]\n",
    "            result = result.append([{'dataset':i,'model':j,'balanced_accuracy':balanced_accuracy,'groundtruth_balanced_accuracy':groundtruth_balanced_accuracy}],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset  groundtruth_balanced_accuracy model  balanced_accuracy\n0          1                       0.672734    97           0.390627\n1          1                       0.748037    98           0.426927\n2          1                       0.755532    99           0.418527\n3          1                       0.995360   100           0.592627\n4          1                       0.994290   101           0.593127\n...      ...                            ...   ...                ...\n1370      67                       0.500000  1767           0.193562\n1371      67                       0.500000  1768           0.193844\n1372      67                       0.577401  1769           0.212610\n1373      67                       0.500000  1770           0.195642\n1374      67                       0.497780  1771           0.192429\n\n[1375 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>groundtruth_balanced_accuracy</th>\n      <th>model</th>\n      <th>balanced_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.672734</td>\n      <td>97</td>\n      <td>0.390627</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.748037</td>\n      <td>98</td>\n      <td>0.426927</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.755532</td>\n      <td>99</td>\n      <td>0.418527</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.995360</td>\n      <td>100</td>\n      <td>0.592627</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0.994290</td>\n      <td>101</td>\n      <td>0.593127</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1370</th>\n      <td>67</td>\n      <td>0.500000</td>\n      <td>1767</td>\n      <td>0.193562</td>\n    </tr>\n    <tr>\n      <th>1371</th>\n      <td>67</td>\n      <td>0.500000</td>\n      <td>1768</td>\n      <td>0.193844</td>\n    </tr>\n    <tr>\n      <th>1372</th>\n      <td>67</td>\n      <td>0.577401</td>\n      <td>1769</td>\n      <td>0.212610</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>67</td>\n      <td>0.500000</td>\n      <td>1770</td>\n      <td>0.195642</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>67</td>\n      <td>0.497780</td>\n      <td>1771</td>\n      <td>0.192429</td>\n    </tr>\n  </tbody>\n</table>\n<p>1375 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"../Kaggle/Output/Dataset_RandomWalk/Full_Dataset_RandomWalk@6@15.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}