{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"./Data/ratings_train.csv\", low_memory=False)\n",
    "ratings_test = pd.read_csv(\"./Data/ratings_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.dataset_id.unique()\n",
    "model_train = ratings_train.model_id.unique()\n",
    "datasets_test = ratings_test.dataset_id.unique()\n",
    "model_test = ratings_test.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Embedded Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"./Data/datasets_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.data_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,(\"v1\",\"v2\",\"v3\",\"v4\",\"v5\",\"v6\",\"v7\",\"v8\")]\n",
    "meta_dataset_similarity = cosine_similarity(meta_datasets)\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity,index=datasets,columns=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_models= pd.read_csv(\"./Data/models_v.csv\",low_memory=False)\n",
    "models = meta_models.model_id.unique()\n",
    "meta_models = meta_models.loc[:,(\"training_data\",\"base_model\",\"gpu_type\",\"para_num\",\"size(MB)\",\"depth\",\"flops\")]\n",
    "meta_model_similarity = cosine_similarity(meta_models)\n",
    "meta_model_similarity = pd.DataFrame(meta_model_similarity,index=models,columns=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=model_train)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]\n",
    "data_model_test_matrix = data_model_test_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(cosine_similarity(data_model_train_matrix.fillna(0)),index=data_model_train_matrix.index,columns=data_model_train_matrix.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_specific_user_item_rating(ratings, similarity, user_id, item_id):\n",
    "    # 求指定用户的评分平均值\n",
    "    mean_rating = ratings.replace(0,np.nan).mean(axis=1)\n",
    "    # 计算所有用户对特定商品的评分偏差\n",
    "    item_ratings_diff = (ratings.loc[:, item_id] - mean_rating).fillna(0)\n",
    "\n",
    "    # 利用用户相似度和评分差异计算预测的评分差异\n",
    "    user_similarity = similarity.loc[user_id, :]\n",
    "    # 计算预测的评分偏差，该操作实际上是一个加权平均，权重是用户之间的相似度\n",
    "    pred_diff = user_similarity.dot(item_ratings_diff) / np.abs(user_similarity).sum()\n",
    "\n",
    "    # 将预测的评分差异加上用户的平均评分，得到预测评分\n",
    "    pred_rating = mean_rating.loc[user_id] + pred_diff\n",
    "    # 返回用户对指定商品的预测评分\n",
    "    return pred_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i in data_model_train_matrix.index:\n",
    "#     for j in data_model_train_matrix.columns:\n",
    "#         if pd.isna(data_model_train_matrix.loc[i][j]):\n",
    "#             data_model_train_matrix.loc[i][j] = predict_specific_user_item_rating(data_model_train_matrix, dataset_similarity, i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data_model_train_matrix.to_csv(\"Experiment2_result_ratingOnly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.read_csv(\"Experiment2_result_ratingOnly.csv\",low_memory=False,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>...</th>\n",
       "      <th>1612</th>\n",
       "      <th>1613</th>\n",
       "      <th>1614</th>\n",
       "      <th>1615</th>\n",
       "      <th>1616</th>\n",
       "      <th>1617</th>\n",
       "      <th>1618</th>\n",
       "      <th>1619</th>\n",
       "      <th>1620</th>\n",
       "      <th>1621</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.940536</td>\n",
       "      <td>0.958961</td>\n",
       "      <td>0.958403</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.997487</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "      <td>0.472778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.253397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.251417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>0.502325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "      <td>0.260131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "      <td>0.201509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.376876</td>\n",
       "      <td>0.382171</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>0.412180</td>\n",
       "      <td>0.347749</td>\n",
       "      <td>0.379523</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.311121</td>\n",
       "      <td>0.337158</td>\n",
       "      <td>0.314651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "      <td>0.346408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.522440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.256281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "      <td>0.199336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 1800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          72        73        74        75        76        77        78  \\\n",
       "0   0.940536  0.958961  0.958403  0.999721  0.999442  0.997487  0.999442   \n",
       "2   0.253397  0.253397  0.253397  0.253397  0.253397  0.253397  0.253397   \n",
       "3   0.251417  0.251417  0.251417  0.251417  0.251417  0.251417  0.251417   \n",
       "4   0.502325  0.502325  0.502325  0.502325  0.502325  0.502325  0.502325   \n",
       "5   0.260131  0.260131  0.260131  0.260131  0.260131  0.260131  0.260131   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "66  0.201509  0.201509  0.201509  0.201509  0.201509  0.201509  0.201509   \n",
       "68  0.376876  0.382171  0.356134  0.412180  0.347749  0.379523  0.339806   \n",
       "69  0.522440  0.522440  0.522440  0.522440  0.522440  0.522440  0.522440   \n",
       "70  0.256281  0.256281  0.256281  0.256281  0.256281  0.256281  0.256281   \n",
       "71  0.199336  0.199336  0.199336  0.199336  0.199336  0.199336  0.199336   \n",
       "\n",
       "          79        80        81  ...      1612      1613      1614      1615  \\\n",
       "0   0.999721  0.998883  0.999442  ...  0.472778  0.472778  0.472778  0.472778   \n",
       "2   0.253397  0.253397  0.253397  ...  0.253397  0.253397  0.253397  0.253397   \n",
       "3   0.251417  0.251417  0.251417  ...  0.251417  0.251417  0.251417  0.251417   \n",
       "4   0.502325  0.502325  0.502325  ...  0.502325  0.502325  0.502325  0.502325   \n",
       "5   0.260131  0.260131  0.260131  ...  0.260131  0.260131  0.260131  0.260131   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "66  0.201509  0.201509  0.201509  ...  0.201509  0.201509  0.201509  0.201509   \n",
       "68  0.311121  0.337158  0.314651  ...  0.346408  0.346408  0.346408  0.346408   \n",
       "69  0.522440  0.522440  0.522440  ...  0.522440  0.522440  0.522440  0.522440   \n",
       "70  0.256281  0.256281  0.256281  ...  0.256281  0.256281  0.256281  0.256281   \n",
       "71  0.199336  0.199336  0.199336  ...  0.199336  0.199336  0.199336  0.199336   \n",
       "\n",
       "        1616      1617      1618      1619      1620      1621  \n",
       "0   0.472778  0.472778  0.472778  0.472778  0.472778  0.472778  \n",
       "2   0.253397  0.253397  0.253397  0.253397  0.253397  0.253397  \n",
       "3   0.251417  0.251417  0.251417  0.251417  0.251417  0.251417  \n",
       "4   0.502325  0.502325  0.502325  0.502325  0.502325  0.502325  \n",
       "5   0.260131  0.260131  0.260131  0.260131  0.260131  0.260131  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "66  0.201509  0.201509  0.201509  0.201509  0.201509  0.201509  \n",
       "68  0.346408  0.346408  0.346408  0.346408  0.346408  0.346408  \n",
       "69  0.522440  0.522440  0.522440  0.522440  0.522440  0.522440  \n",
       "70  0.256281  0.256281  0.256281  0.256281  0.256281  0.256281  \n",
       "71  0.199336  0.199336  0.199336  0.199336  0.199336  0.199336  \n",
       "\n",
       "[62 rows x 1800 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Interaction Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Interaction_similarity(user_id_1, model_id_1, user_id_2, model_id_2, alpha,gamma):\n",
    "    # 假设以下两个函数可以返回用户之间和商品之间的相似度\n",
    "    rating_1 = data_model_train_matrix.loc[user_id_1][model_id_1]\n",
    "    rating_2 = data_model_train_matrix.loc[user_id_2][model_id_2]\n",
    "    user_similarity = meta_dataset_similarity.loc[user_id_1][user_id_2]\n",
    "    model_similarity = meta_model_similarity.loc[model_id_1][model_id_2]\n",
    "\n",
    "    # 计算混合相似度\n",
    "    interaction_similarity = (alpha * user_similarity + (1-alpha) * model_similarity) * np.exp(-gamma * np.abs(rating_1 - rating_2) ** 2)\n",
    "    print(interaction_similarity)\n",
    "    return interaction_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index.values.tolist()\n",
    "    return index_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top_b1 = 1\n",
    "top_b2 = 2\n",
    "# 计算所有用户商品组合的相似度\n",
    "inter_similarity_results = []\n",
    "for i in data_model_test_matrix.index:\n",
    "    most_similar_datasets = Find_Top_k(i,meta_dataset_similarity)[1:1+top_b1]\n",
    "    for user_id_1 in most_similar_datasets:\n",
    "        if user_id_1 not in data_model_train_matrix.index:\n",
    "            continue\n",
    "        for item_id_1 in data_model_test_matrix.columns:\n",
    "            if item_id_1 not in data_model_train_matrix.columns:\n",
    "                continue\n",
    "            for user_id_2 in most_similar_datasets:\n",
    "                if user_id_2 not in data_model_train_matrix.index:\n",
    "                    continue\n",
    "                for item_id_2 in data_model_test_matrix.columns:\n",
    "                    if item_id_2 not in data_model_train_matrix.columns:\n",
    "                        continue\n",
    "                    similarity = Interaction_similarity(user_id_1, item_id_1,user_id_2, item_id_2, alpha=0.5,gamma=0.01)\n",
    "                    inter_similarity_results.append((user_id_1, item_id_1, user_id_2, item_id_2, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_similarity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
