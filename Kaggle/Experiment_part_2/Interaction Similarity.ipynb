{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings_train = pd.read_csv(\"./Data/ratings_train.csv\", low_memory=False)\n",
    "ratings_test = pd.read_csv(\"./Data/ratings_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_train = ratings_train.dataset_id.unique()\n",
    "model_train = ratings_train.model_id.unique()\n",
    "datasets_test = ratings_test.dataset_id.unique()\n",
    "model_test = ratings_test.model_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Embedded Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_datasets = pd.read_csv(\"./Data/datasets_v.csv\",low_memory=False)\n",
    "datasets = meta_datasets.data_id.unique()\n",
    "meta_datasets = meta_datasets.loc[:,(\"v1\",\"v2\",\"v3\",\"v4\",\"v5\",\"v6\",\"v7\",\"v8\")]\n",
    "meta_dataset_similarity = cosine_similarity(meta_datasets.values)\n",
    "meta_dataset_similarity = pd.DataFrame(meta_dataset_similarity,index=datasets,columns=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "outputs": [
    {
     "data": {
      "text/plain": "          v1        v2        v3        v4        v5        v6        v7  \\\n0   0.454312  0.241966 -0.178474  0.078718 -0.343706  0.150178  0.103396   \n1   0.527839  0.284245 -0.201757  0.116918 -0.394861  0.168884  0.137184   \n2   0.421102  0.234788 -0.172241  0.081514 -0.348054  0.138399  0.100450   \n3   0.358012  0.198786 -0.129784  0.068405 -0.275457  0.119678  0.093582   \n4   0.298305  0.167896 -0.120117  0.052906 -0.242469  0.107290  0.072812   \n..       ...       ...       ...       ...       ...       ...       ...   \n67  0.446627  0.241174 -0.179276  0.092747 -0.355247  0.140657  0.110482   \n68  0.411207  0.244925 -0.156990  0.084651 -0.319750  0.147412  0.104277   \n69  0.495822  0.270633 -0.181879  0.100016 -0.387360  0.150677  0.108678   \n70  0.406016  0.214886 -0.155250  0.082475 -0.315015  0.126135  0.087693   \n71  0.177364  0.075348 -0.091034  0.006257 -0.083623  0.051864  0.039216   \n\n          v8  \n0  -0.474233  \n1  -0.536491  \n2  -0.447096  \n3  -0.378495  \n4  -0.322821  \n..       ...  \n67 -0.472832  \n68 -0.440762  \n69 -0.507951  \n70 -0.414519  \n71 -0.090296  \n\n[72 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>v3</th>\n      <th>v4</th>\n      <th>v5</th>\n      <th>v6</th>\n      <th>v7</th>\n      <th>v8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.454312</td>\n      <td>0.241966</td>\n      <td>-0.178474</td>\n      <td>0.078718</td>\n      <td>-0.343706</td>\n      <td>0.150178</td>\n      <td>0.103396</td>\n      <td>-0.474233</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.527839</td>\n      <td>0.284245</td>\n      <td>-0.201757</td>\n      <td>0.116918</td>\n      <td>-0.394861</td>\n      <td>0.168884</td>\n      <td>0.137184</td>\n      <td>-0.536491</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.421102</td>\n      <td>0.234788</td>\n      <td>-0.172241</td>\n      <td>0.081514</td>\n      <td>-0.348054</td>\n      <td>0.138399</td>\n      <td>0.100450</td>\n      <td>-0.447096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.358012</td>\n      <td>0.198786</td>\n      <td>-0.129784</td>\n      <td>0.068405</td>\n      <td>-0.275457</td>\n      <td>0.119678</td>\n      <td>0.093582</td>\n      <td>-0.378495</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.298305</td>\n      <td>0.167896</td>\n      <td>-0.120117</td>\n      <td>0.052906</td>\n      <td>-0.242469</td>\n      <td>0.107290</td>\n      <td>0.072812</td>\n      <td>-0.322821</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.446627</td>\n      <td>0.241174</td>\n      <td>-0.179276</td>\n      <td>0.092747</td>\n      <td>-0.355247</td>\n      <td>0.140657</td>\n      <td>0.110482</td>\n      <td>-0.472832</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.411207</td>\n      <td>0.244925</td>\n      <td>-0.156990</td>\n      <td>0.084651</td>\n      <td>-0.319750</td>\n      <td>0.147412</td>\n      <td>0.104277</td>\n      <td>-0.440762</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.495822</td>\n      <td>0.270633</td>\n      <td>-0.181879</td>\n      <td>0.100016</td>\n      <td>-0.387360</td>\n      <td>0.150677</td>\n      <td>0.108678</td>\n      <td>-0.507951</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.406016</td>\n      <td>0.214886</td>\n      <td>-0.155250</td>\n      <td>0.082475</td>\n      <td>-0.315015</td>\n      <td>0.126135</td>\n      <td>0.087693</td>\n      <td>-0.414519</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.177364</td>\n      <td>0.075348</td>\n      <td>-0.091034</td>\n      <td>0.006257</td>\n      <td>-0.083623</td>\n      <td>0.051864</td>\n      <td>0.039216</td>\n      <td>-0.090296</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6   \\\n0   1.000000  0.999340  0.999456  0.999575  0.999625  0.999396  0.999243   \n1   0.999340  1.000000  0.999077  0.999566  0.998910  0.999598  0.999372   \n2   0.999456  0.999077  1.000000  0.999289  0.999741  0.999340  0.999700   \n3   0.999575  0.999566  0.999289  1.000000  0.999517  0.999611  0.999329   \n4   0.999625  0.998910  0.999741  0.999517  1.000000  0.999077  0.999478   \n..       ...       ...       ...       ...       ...       ...       ...   \n67  0.999608  0.999579  0.999807  0.999538  0.999532  0.999761  0.999806   \n68  0.999271  0.999309  0.999147  0.999702  0.999482  0.999029  0.999009   \n69  0.999481  0.999431  0.999569  0.999474  0.999214  0.999483  0.999351   \n70  0.999642  0.999504  0.999624  0.999356  0.999278  0.999441  0.999515   \n71  0.948047  0.948487  0.944207  0.943553  0.943514  0.944974  0.942782   \n\n          7         8         9   ...        62        63        64        65  \\\n0   0.997841  0.999250  0.999323  ...  0.997632  0.999130  0.999007  0.999539   \n1   0.999247  0.999423  0.999505  ...  0.999322  0.999076  0.999649  0.999737   \n2   0.998044  0.999652  0.999843  ...  0.997227  0.999587  0.999390  0.999515   \n3   0.998057  0.999114  0.999539  ...  0.998123  0.999335  0.999438  0.999833   \n4   0.997369  0.999099  0.999491  ...  0.996876  0.999359  0.998899  0.999494   \n..       ...       ...       ...  ...       ...       ...       ...       ...   \n67  0.998538  0.999865  0.999877  ...  0.998236  0.999621  0.999757  0.999848   \n68  0.998374  0.998567  0.999303  ...  0.997998  0.998751  0.998966  0.999500   \n69  0.998503  0.999489  0.999736  ...  0.997748  0.999103  0.999577  0.999528   \n70  0.998538  0.999645  0.999690  ...  0.997892  0.999110  0.999507  0.999552   \n71  0.950478  0.946296  0.943668  ...  0.949808  0.944855  0.943180  0.943011   \n\n          66        67        68        69        70        71  \n0   0.998801  0.999608  0.999271  0.999481  0.999642  0.948047  \n1   0.999076  0.999579  0.999309  0.999431  0.999504  0.948487  \n2   0.999457  0.999807  0.999147  0.999569  0.999624  0.944207  \n3   0.999392  0.999538  0.999702  0.999474  0.999356  0.943553  \n4   0.999082  0.999532  0.999482  0.999214  0.999278  0.943514  \n..       ...       ...       ...       ...       ...       ...  \n67  0.999370  1.000000  0.999210  0.999676  0.999773  0.944395  \n68  0.999027  0.999210  1.000000  0.999157  0.999015  0.943228  \n69  0.999523  0.999676  0.999157  1.000000  0.999910  0.944969  \n70  0.999232  0.999773  0.999015  0.999910  1.000000  0.946840  \n71  0.943247  0.944395  0.943228  0.944969  0.946840  1.000000  \n\n[72 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.999340</td>\n      <td>0.999456</td>\n      <td>0.999575</td>\n      <td>0.999625</td>\n      <td>0.999396</td>\n      <td>0.999243</td>\n      <td>0.997841</td>\n      <td>0.999250</td>\n      <td>0.999323</td>\n      <td>...</td>\n      <td>0.997632</td>\n      <td>0.999130</td>\n      <td>0.999007</td>\n      <td>0.999539</td>\n      <td>0.998801</td>\n      <td>0.999608</td>\n      <td>0.999271</td>\n      <td>0.999481</td>\n      <td>0.999642</td>\n      <td>0.948047</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999340</td>\n      <td>1.000000</td>\n      <td>0.999077</td>\n      <td>0.999566</td>\n      <td>0.998910</td>\n      <td>0.999598</td>\n      <td>0.999372</td>\n      <td>0.999247</td>\n      <td>0.999423</td>\n      <td>0.999505</td>\n      <td>...</td>\n      <td>0.999322</td>\n      <td>0.999076</td>\n      <td>0.999649</td>\n      <td>0.999737</td>\n      <td>0.999076</td>\n      <td>0.999579</td>\n      <td>0.999309</td>\n      <td>0.999431</td>\n      <td>0.999504</td>\n      <td>0.948487</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.999456</td>\n      <td>0.999077</td>\n      <td>1.000000</td>\n      <td>0.999289</td>\n      <td>0.999741</td>\n      <td>0.999340</td>\n      <td>0.999700</td>\n      <td>0.998044</td>\n      <td>0.999652</td>\n      <td>0.999843</td>\n      <td>...</td>\n      <td>0.997227</td>\n      <td>0.999587</td>\n      <td>0.999390</td>\n      <td>0.999515</td>\n      <td>0.999457</td>\n      <td>0.999807</td>\n      <td>0.999147</td>\n      <td>0.999569</td>\n      <td>0.999624</td>\n      <td>0.944207</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.999575</td>\n      <td>0.999566</td>\n      <td>0.999289</td>\n      <td>1.000000</td>\n      <td>0.999517</td>\n      <td>0.999611</td>\n      <td>0.999329</td>\n      <td>0.998057</td>\n      <td>0.999114</td>\n      <td>0.999539</td>\n      <td>...</td>\n      <td>0.998123</td>\n      <td>0.999335</td>\n      <td>0.999438</td>\n      <td>0.999833</td>\n      <td>0.999392</td>\n      <td>0.999538</td>\n      <td>0.999702</td>\n      <td>0.999474</td>\n      <td>0.999356</td>\n      <td>0.943553</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999625</td>\n      <td>0.998910</td>\n      <td>0.999741</td>\n      <td>0.999517</td>\n      <td>1.000000</td>\n      <td>0.999077</td>\n      <td>0.999478</td>\n      <td>0.997369</td>\n      <td>0.999099</td>\n      <td>0.999491</td>\n      <td>...</td>\n      <td>0.996876</td>\n      <td>0.999359</td>\n      <td>0.998899</td>\n      <td>0.999494</td>\n      <td>0.999082</td>\n      <td>0.999532</td>\n      <td>0.999482</td>\n      <td>0.999214</td>\n      <td>0.999278</td>\n      <td>0.943514</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.999608</td>\n      <td>0.999579</td>\n      <td>0.999807</td>\n      <td>0.999538</td>\n      <td>0.999532</td>\n      <td>0.999761</td>\n      <td>0.999806</td>\n      <td>0.998538</td>\n      <td>0.999865</td>\n      <td>0.999877</td>\n      <td>...</td>\n      <td>0.998236</td>\n      <td>0.999621</td>\n      <td>0.999757</td>\n      <td>0.999848</td>\n      <td>0.999370</td>\n      <td>1.000000</td>\n      <td>0.999210</td>\n      <td>0.999676</td>\n      <td>0.999773</td>\n      <td>0.944395</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.999271</td>\n      <td>0.999309</td>\n      <td>0.999147</td>\n      <td>0.999702</td>\n      <td>0.999482</td>\n      <td>0.999029</td>\n      <td>0.999009</td>\n      <td>0.998374</td>\n      <td>0.998567</td>\n      <td>0.999303</td>\n      <td>...</td>\n      <td>0.997998</td>\n      <td>0.998751</td>\n      <td>0.998966</td>\n      <td>0.999500</td>\n      <td>0.999027</td>\n      <td>0.999210</td>\n      <td>1.000000</td>\n      <td>0.999157</td>\n      <td>0.999015</td>\n      <td>0.943228</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.999481</td>\n      <td>0.999431</td>\n      <td>0.999569</td>\n      <td>0.999474</td>\n      <td>0.999214</td>\n      <td>0.999483</td>\n      <td>0.999351</td>\n      <td>0.998503</td>\n      <td>0.999489</td>\n      <td>0.999736</td>\n      <td>...</td>\n      <td>0.997748</td>\n      <td>0.999103</td>\n      <td>0.999577</td>\n      <td>0.999528</td>\n      <td>0.999523</td>\n      <td>0.999676</td>\n      <td>0.999157</td>\n      <td>1.000000</td>\n      <td>0.999910</td>\n      <td>0.944969</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.999642</td>\n      <td>0.999504</td>\n      <td>0.999624</td>\n      <td>0.999356</td>\n      <td>0.999278</td>\n      <td>0.999441</td>\n      <td>0.999515</td>\n      <td>0.998538</td>\n      <td>0.999645</td>\n      <td>0.999690</td>\n      <td>...</td>\n      <td>0.997892</td>\n      <td>0.999110</td>\n      <td>0.999507</td>\n      <td>0.999552</td>\n      <td>0.999232</td>\n      <td>0.999773</td>\n      <td>0.999015</td>\n      <td>0.999910</td>\n      <td>1.000000</td>\n      <td>0.946840</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.948047</td>\n      <td>0.948487</td>\n      <td>0.944207</td>\n      <td>0.943553</td>\n      <td>0.943514</td>\n      <td>0.944974</td>\n      <td>0.942782</td>\n      <td>0.950478</td>\n      <td>0.946296</td>\n      <td>0.943668</td>\n      <td>...</td>\n      <td>0.949808</td>\n      <td>0.944855</td>\n      <td>0.943180</td>\n      <td>0.943011</td>\n      <td>0.943247</td>\n      <td>0.944395</td>\n      <td>0.943228</td>\n      <td>0.944969</td>\n      <td>0.946840</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_models= pd.read_csv(\"./Data/models_v.csv\",low_memory=False)\n",
    "models = meta_models.model_id.unique()\n",
    "meta_models = meta_models.loc[:,(\"training_data\",\"base_model\",\"gpu_type\",\"para_num\",\"size(MB)\",\"depth\",\"flops\")]\n",
    "meta_model_similarity = cosine_similarity(meta_models.values)\n",
    "meta_model_similarity = pd.DataFrame(meta_model_similarity,index=models,columns=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "outputs": [
    {
     "data": {
      "text/plain": "      training_data  base_model  gpu_type  para_num  size(MB)  depth    flops\n0                 0           0         1   7302474     27.86    304   529724\n1                 0           1         1  13071690     49.86    424   857404\n2                 0           2         1  18816330     71.78    504   988476\n3                 0           3         1   4380077     16.71    158  1925299\n4                 0           4         1   6905745     26.34    222  2893071\n...             ...         ...       ...       ...       ...    ...      ...\n1795             71          20         0  24114826     91.99    161  1054012\n1796             71          21         0  24091914     91.90    137  1054012\n1797             71          22         0  14848586     56.64     15   267580\n1798             71          23         0  20158282     76.90     18   267580\n1799             71          24         0  21388594     81.59    119  1054012\n\n[1800 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>training_data</th>\n      <th>base_model</th>\n      <th>gpu_type</th>\n      <th>para_num</th>\n      <th>size(MB)</th>\n      <th>depth</th>\n      <th>flops</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7302474</td>\n      <td>27.86</td>\n      <td>304</td>\n      <td>529724</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13071690</td>\n      <td>49.86</td>\n      <td>424</td>\n      <td>857404</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>18816330</td>\n      <td>71.78</td>\n      <td>504</td>\n      <td>988476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4380077</td>\n      <td>16.71</td>\n      <td>158</td>\n      <td>1925299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>6905745</td>\n      <td>26.34</td>\n      <td>222</td>\n      <td>2893071</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1795</th>\n      <td>71</td>\n      <td>20</td>\n      <td>0</td>\n      <td>24114826</td>\n      <td>91.99</td>\n      <td>161</td>\n      <td>1054012</td>\n    </tr>\n    <tr>\n      <th>1796</th>\n      <td>71</td>\n      <td>21</td>\n      <td>0</td>\n      <td>24091914</td>\n      <td>91.90</td>\n      <td>137</td>\n      <td>1054012</td>\n    </tr>\n    <tr>\n      <th>1797</th>\n      <td>71</td>\n      <td>22</td>\n      <td>0</td>\n      <td>14848586</td>\n      <td>56.64</td>\n      <td>15</td>\n      <td>267580</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>71</td>\n      <td>23</td>\n      <td>0</td>\n      <td>20158282</td>\n      <td>76.90</td>\n      <td>18</td>\n      <td>267580</td>\n    </tr>\n    <tr>\n      <th>1799</th>\n      <td>71</td>\n      <td>24</td>\n      <td>0</td>\n      <td>21388594</td>\n      <td>81.59</td>\n      <td>119</td>\n      <td>1054012</td>\n    </tr>\n  </tbody>\n</table>\n<p>1800 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_model_train_matrix = pd.DataFrame(index=datasets_train,columns=model_train)\n",
    "data_model_test_matrix = pd.DataFrame(index=datasets_test,columns=model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_train.itertuples():\n",
    "    data_model_train_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for row in ratings_test.itertuples():\n",
    "    data_model_test_matrix.loc[row[1]][row[2]] = row[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_similarity = pd.DataFrame(cosine_similarity(data_model_train_matrix.fillna(0)),index=data_model_train_matrix.index,columns=data_model_train_matrix.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def predict(ratings, similarity):\n",
    "    mean_user_rating = ratings.fillna(0).mean(axis=1)\n",
    "    ratings_diff = (ratings - mean_user_rating[:, np.newaxis]).fillna(0)\n",
    "    pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "     # 只替换NaN值\n",
    "    df_nan = ratings.isnull()\n",
    "    pred = pd.DataFrame(pred).where(df_nan, ratings)\n",
    "    return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\byy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\byy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prediction_train = predict(data_model_train_matrix,dataset_similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "outputs": [],
   "source": [
    "def Find_Top_k(i,sim_matrix):\n",
    "    row = sim_matrix.loc[i]\n",
    "    row = row.sort_values(ascending=False)\n",
    "    index_row = row.index.values.tolist()\n",
    "    return index_row"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "outputs": [],
   "source": [
    "prediction_test = pd.DataFrame(index=datasets_test,columns=model_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "outputs": [
    {
     "data": {
      "text/plain": "      training_data  base_model  gpu_type  para_num  size(MB)  depth    flops\n0                 0           0         1   7302474     27.86    304   529724\n1                 0           1         1  13071690     49.86    424   857404\n2                 0           2         1  18816330     71.78    504   988476\n3                 0           3         1   4380077     16.71    158  1925299\n4                 0           4         1   6905745     26.34    222  2893071\n...             ...         ...       ...       ...       ...    ...      ...\n1795             71          20         0  24114826     91.99    161  1054012\n1796             71          21         0  24091914     91.90    137  1054012\n1797             71          22         0  14848586     56.64     15   267580\n1798             71          23         0  20158282     76.90     18   267580\n1799             71          24         0  21388594     81.59    119  1054012\n\n[1800 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>training_data</th>\n      <th>base_model</th>\n      <th>gpu_type</th>\n      <th>para_num</th>\n      <th>size(MB)</th>\n      <th>depth</th>\n      <th>flops</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7302474</td>\n      <td>27.86</td>\n      <td>304</td>\n      <td>529724</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13071690</td>\n      <td>49.86</td>\n      <td>424</td>\n      <td>857404</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>18816330</td>\n      <td>71.78</td>\n      <td>504</td>\n      <td>988476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4380077</td>\n      <td>16.71</td>\n      <td>158</td>\n      <td>1925299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>6905745</td>\n      <td>26.34</td>\n      <td>222</td>\n      <td>2893071</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1795</th>\n      <td>71</td>\n      <td>20</td>\n      <td>0</td>\n      <td>24114826</td>\n      <td>91.99</td>\n      <td>161</td>\n      <td>1054012</td>\n    </tr>\n    <tr>\n      <th>1796</th>\n      <td>71</td>\n      <td>21</td>\n      <td>0</td>\n      <td>24091914</td>\n      <td>91.90</td>\n      <td>137</td>\n      <td>1054012</td>\n    </tr>\n    <tr>\n      <th>1797</th>\n      <td>71</td>\n      <td>22</td>\n      <td>0</td>\n      <td>14848586</td>\n      <td>56.64</td>\n      <td>15</td>\n      <td>267580</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>71</td>\n      <td>23</td>\n      <td>0</td>\n      <td>20158282</td>\n      <td>76.90</td>\n      <td>18</td>\n      <td>267580</td>\n    </tr>\n    <tr>\n      <th>1799</th>\n      <td>71</td>\n      <td>24</td>\n      <td>0</td>\n      <td>21388594</td>\n      <td>81.59</td>\n      <td>119</td>\n      <td>1054012</td>\n    </tr>\n  </tbody>\n</table>\n<p>1800 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "outputs": [],
   "source": [
    "from CKA import feature_space_linear_cka as cka\n",
    "def interaction_correlation(interaction1, interaction2, a, model_cka):\n",
    "    # Get dataset and model form interactions\n",
    "    d1, m1 = interaction1\n",
    "    d2, m2 = interaction2\n",
    "    # Compute interaction correlation\n",
    "    dataset_similarity = meta_dataset_similarity.loc[d1,d2]\n",
    "    if model_cka:\n",
    "        model_feature1 = np.load(\"../features/\" + str(int(m1) - 72) + \".npy\")\n",
    "        model_feature2 = np.load(\"../features/\" + str(int(m2) - 72) + \".npy\")\n",
    "        model_similarity = cka(model_feature1, model_feature2)\n",
    "        if math.isinf(model_similarity):\n",
    "            model_similarity = 1\n",
    "        if math.isnan(model_similarity):\n",
    "            model_similarity = meta_model_similarity.loc[m1,m2]\n",
    "    else:\n",
    "        model_similarity = meta_model_similarity.loc[m1,m2]\n",
    "    # print(dataset_similarity,model_similarity)\n",
    "    interaction_corr = (dataset_similarity * a + model_similarity * (1-a))\n",
    "    return interaction_corr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "outputs": [],
   "source": [
    "def select_elements(lst, num_elements):\n",
    "    # Calculate the step length\n",
    "    step = math.floor(len(lst) / num_elements)\n",
    "\n",
    "    # Select elements\n",
    "    selected_elements = lst[::step]\n",
    "\n",
    "    # If more elements are selected, cut off the extra ones\n",
    "    if len(selected_elements) > num_elements:\n",
    "        selected_elements = selected_elements[:num_elements]\n",
    "\n",
    "    return selected_elements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BYY\\Model_Recommendation\\Kaggle\\Experiment_part_2\\CKA.py:151: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return dot_product_similarity / (normalization_x * normalization_y)\n",
      "C:\\Users\\BYY\\Model_Recommendation\\Kaggle\\Experiment_part_2\\CKA.py:151: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return dot_product_similarity / (normalization_x * normalization_y)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for dataset_id in prediction_test.index:\n",
    "    model_test = data_model_test_matrix.loc[dataset_id]\n",
    "    non_nan_models = model_test[model_test.notnull()].index.tolist()\n",
    "    for model_id in non_nan_models:\n",
    "        model_scores = 0\n",
    "        score = 0\n",
    "        connection = 0\n",
    "        most_sim_datasets = Find_Top_k(dataset_id,meta_dataset_similarity)[1:30]\n",
    "        most_sim_datasets = list(set(most_sim_datasets) & set(datasets_train))[:3]\n",
    "        # print(most_sim_datasets)\n",
    "        # most_sim_datasets = select_elements(most_sim_datasets, 3)\n",
    "        interaction_corr_list = []\n",
    "        for sim_datasets in most_sim_datasets:\n",
    "            series = data_model_train_matrix.loc[sim_datasets]\n",
    "            sorted_series = series.sort_values(ascending=False)  # 从大到小排序\n",
    "            non_nan_models = sorted_series[sorted_series.notnull()].index.tolist()\n",
    "            for near_model in non_nan_models:\n",
    "                performance = data_model_train_matrix.loc[sim_datasets,near_model]\n",
    "                connection += 1\n",
    "                interaction1 = [dataset_id,model_id]\n",
    "                interaction2 = [sim_datasets, near_model]\n",
    "                interaction_corr = interaction_correlation(interaction1, interaction2, 0.2, True)\n",
    "                interaction_corr_list.append([sim_datasets,near_model,interaction_corr,performance])\n",
    "\n",
    "        # 我们可以使用以下代码进行排序：\n",
    "        sorted_interaction_corr= sorted(interaction_corr_list, key=lambda x: x[2], reverse=True)\n",
    "                # print(interaction_corr,performance,interaction_corr * performance)\n",
    "                # model_scores += interaction_corr * performance\n",
    "        # score = model_scores / connection\n",
    "        # # print(connection)\n",
    "        # print(sorted_interaction_corr)\n",
    "        b = 10\n",
    "        top_k_interaction_corr= sorted_interaction_corr[:b]\n",
    "        top_k_performance = sorted(top_k_interaction_corr, key=lambda x: x[3], reverse=True)\n",
    "        k = 3\n",
    "        top_k = [item[3] for item in top_k_performance[:k]]\n",
    "        # 计算平均值\n",
    "        average_interaction_corr = np.mean(top_k)\n",
    "        # print(average_rating)\n",
    "        prediction_test.loc[dataset_id,model_id] = average_interaction_corr\n",
    "        # print(dataset_id,model_id,score)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "outputs": [
    {
     "data": {
      "text/plain": "        97        98        99        100       101       102       103   \\\n1   0.601662  0.583886  0.628905  0.515936  0.557168  0.577259  0.583465   \n10       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n15       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n17       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n32       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n35       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n47       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n61       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n62     0.709  0.574333     0.597    0.8305  0.833024  0.707833    0.8525   \n67       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n\n        104       105       106   ...      1762      1763      1764      1765  \\\n1   0.598717  0.530136  0.534659  ...       NaN       NaN       NaN       NaN   \n10       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n15       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n17       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n32       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n35       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n47       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n61       NaN       NaN       NaN  ...       NaN       NaN       NaN       NaN   \n62  0.833167     0.869  0.836167  ...       NaN       NaN       NaN       NaN   \n67       NaN       NaN       NaN  ...  0.647171  0.353224  0.571071  0.434583   \n\n        1766      1767      1768      1769      1770      1771  \n1        NaN       NaN       NaN       NaN       NaN       NaN  \n10       NaN       NaN       NaN       NaN       NaN       NaN  \n15       NaN       NaN       NaN       NaN       NaN       NaN  \n17       NaN       NaN       NaN       NaN       NaN       NaN  \n32       NaN       NaN       NaN       NaN       NaN       NaN  \n35       NaN       NaN       NaN       NaN       NaN       NaN  \n47       NaN       NaN       NaN       NaN       NaN       NaN  \n61       NaN       NaN       NaN       NaN       NaN       NaN  \n62       NaN       NaN       NaN       NaN       NaN       NaN  \n67  0.545854  0.441424  0.604427  0.671556  0.522237  0.939219  \n\n[10 rows x 1125 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n      <th>103</th>\n      <th>104</th>\n      <th>105</th>\n      <th>106</th>\n      <th>...</th>\n      <th>1762</th>\n      <th>1763</th>\n      <th>1764</th>\n      <th>1765</th>\n      <th>1766</th>\n      <th>1767</th>\n      <th>1768</th>\n      <th>1769</th>\n      <th>1770</th>\n      <th>1771</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.601662</td>\n      <td>0.583886</td>\n      <td>0.628905</td>\n      <td>0.515936</td>\n      <td>0.557168</td>\n      <td>0.577259</td>\n      <td>0.583465</td>\n      <td>0.598717</td>\n      <td>0.530136</td>\n      <td>0.534659</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>0.709</td>\n      <td>0.574333</td>\n      <td>0.597</td>\n      <td>0.8305</td>\n      <td>0.833024</td>\n      <td>0.707833</td>\n      <td>0.8525</td>\n      <td>0.833167</td>\n      <td>0.869</td>\n      <td>0.836167</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.647171</td>\n      <td>0.353224</td>\n      <td>0.571071</td>\n      <td>0.434583</td>\n      <td>0.545854</td>\n      <td>0.441424</td>\n      <td>0.604427</td>\n      <td>0.671556</td>\n      <td>0.522237</td>\n      <td>0.939219</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 1125 columns</p>\n</div>"
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "outputs": [
    {
     "data": {
      "text/plain": "        97        98        99        100       101       102       103   \\\n1   0.672734  0.748037  0.755532   0.99536   0.99429   0.98965  0.996074   \n10       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n15       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n17       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n32       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n35       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n47       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n61       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n62  0.653979  0.714286  0.700445  0.989125  0.989619  0.974296  0.989125   \n67       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n\n        104       105       106   ...     1762      1763      1764      1765  \\\n1   0.998572  0.996788  0.995004  ...      NaN       NaN       NaN       NaN   \n10       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n15       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n17       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n32       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n35       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n47       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n61       NaN       NaN       NaN  ...      NaN       NaN       NaN       NaN   \n62  0.990114  0.990114  0.989619  ...      NaN       NaN       NaN       NaN   \n67       NaN       NaN       NaN  ...  0.50112  0.504479  0.504479  0.504479   \n\n        1766      1767      1768      1769      1770     1771  \n1        NaN       NaN       NaN       NaN       NaN      NaN  \n10       NaN       NaN       NaN       NaN       NaN      NaN  \n15       NaN       NaN       NaN       NaN       NaN      NaN  \n17       NaN       NaN       NaN       NaN       NaN      NaN  \n32       NaN       NaN       NaN       NaN       NaN      NaN  \n35       NaN       NaN       NaN       NaN       NaN      NaN  \n47       NaN       NaN       NaN       NaN       NaN      NaN  \n61       NaN       NaN       NaN       NaN       NaN      NaN  \n62       NaN       NaN       NaN       NaN       NaN      NaN  \n67  0.504479  0.504479  0.504479  0.581187  0.504479  0.50224  \n\n[10 rows x 1125 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n      <th>103</th>\n      <th>104</th>\n      <th>105</th>\n      <th>106</th>\n      <th>...</th>\n      <th>1762</th>\n      <th>1763</th>\n      <th>1764</th>\n      <th>1765</th>\n      <th>1766</th>\n      <th>1767</th>\n      <th>1768</th>\n      <th>1769</th>\n      <th>1770</th>\n      <th>1771</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.672734</td>\n      <td>0.748037</td>\n      <td>0.755532</td>\n      <td>0.99536</td>\n      <td>0.99429</td>\n      <td>0.98965</td>\n      <td>0.996074</td>\n      <td>0.998572</td>\n      <td>0.996788</td>\n      <td>0.995004</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>0.653979</td>\n      <td>0.714286</td>\n      <td>0.700445</td>\n      <td>0.989125</td>\n      <td>0.989619</td>\n      <td>0.974296</td>\n      <td>0.989125</td>\n      <td>0.990114</td>\n      <td>0.990114</td>\n      <td>0.989619</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.50112</td>\n      <td>0.504479</td>\n      <td>0.504479</td>\n      <td>0.504479</td>\n      <td>0.504479</td>\n      <td>0.504479</td>\n      <td>0.504479</td>\n      <td>0.581187</td>\n      <td>0.504479</td>\n      <td>0.50224</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 1125 columns</p>\n</div>"
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_test_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns={\"dataset\",\"model\",\"balanced_accuracy\",\"groundtruth_balanced_accuracy\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "outputs": [],
   "source": [
    "for i in prediction_test.index:\n",
    "    for j in prediction_test.columns:\n",
    "        if prediction_test.fillna(0).loc[i][j] != 0:\n",
    "            balanced_accuracy = prediction_test.loc[i][j]\n",
    "            groundtruth_balanced_accuracy = data_model_test_matrix.loc[i][j]\n",
    "            result = result.append([{'dataset':i,'model':j,'balanced_accuracy':balanced_accuracy,'groundtruth_balanced_accuracy':groundtruth_balanced_accuracy}],ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "outputs": [
    {
     "data": {
      "text/plain": "     model  groundtruth_balanced_accuracy dataset  balanced_accuracy\n0       97                       0.672734       1           0.601662\n1       98                       0.748037       1           0.583886\n2       99                       0.755532       1           0.628905\n3      100                       0.995360       1           0.515936\n4      101                       0.994290       1           0.557168\n...    ...                            ...     ...                ...\n1370  1767                       0.504479      67           0.441424\n1371  1768                       0.504479      67           0.604427\n1372  1769                       0.581187      67           0.671556\n1373  1770                       0.504479      67           0.522237\n1374  1771                       0.502240      67           0.939219\n\n[1375 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>groundtruth_balanced_accuracy</th>\n      <th>dataset</th>\n      <th>balanced_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>0.672734</td>\n      <td>1</td>\n      <td>0.601662</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>98</td>\n      <td>0.748037</td>\n      <td>1</td>\n      <td>0.583886</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>99</td>\n      <td>0.755532</td>\n      <td>1</td>\n      <td>0.628905</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>0.995360</td>\n      <td>1</td>\n      <td>0.515936</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>101</td>\n      <td>0.994290</td>\n      <td>1</td>\n      <td>0.557168</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1370</th>\n      <td>1767</td>\n      <td>0.504479</td>\n      <td>67</td>\n      <td>0.441424</td>\n    </tr>\n    <tr>\n      <th>1371</th>\n      <td>1768</td>\n      <td>0.504479</td>\n      <td>67</td>\n      <td>0.604427</td>\n    </tr>\n    <tr>\n      <th>1372</th>\n      <td>1769</td>\n      <td>0.581187</td>\n      <td>67</td>\n      <td>0.671556</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>1770</td>\n      <td>0.504479</td>\n      <td>67</td>\n      <td>0.522237</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>1771</td>\n      <td>0.502240</td>\n      <td>67</td>\n      <td>0.939219</td>\n    </tr>\n  </tbody>\n</table>\n<p>1375 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "outputs": [],
   "source": [
    "result.to_csv(\"../Experiment_part_2/result.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23fcb16ef9ae263cc1ee2ef7013048b59283f261690a66bd73349f654cd13bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}